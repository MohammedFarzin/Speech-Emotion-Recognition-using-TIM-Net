{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XVQ3Nlfo9CpDlXDbZcpYF3iOhKoUSaFn",
      "authorship_tag": "ABX9TyMIlifB0QAcWtdF+03KD6/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedFarzin/Speech-Emotion-Recognition-using-TIM-Net/blob/main/SER_Using_TIM_NET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8SyhTMTT-yG",
        "outputId": "fab23185-d001-4513-9d09-2bf064d13bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TIM-Net_SER'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 139 (delta 50), reused 106 (delta 35), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (139/139), 2.66 MiB | 15.68 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Jiaxin-Ye/TIM-Net_SER.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TIM-Net_SER/Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0bAoiQwUPEl",
        "outputId": "cd2d4fa8-f9a8-4890-a23d-3f519ffe7ebf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TIM-Net_SER/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install virtualenv\n",
        "# !virtualenv tim-net\n",
        "# !source tim-net/bin/activate\n"
      ],
      "metadata": {
        "id": "6HnzLm9TUTch"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "id": "LUeWFeibrCqS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(file_path: str, mfcc_len: int=39, mean_signal_length: int = 100000):\n",
        "  \"\"\"\n",
        "  file_path : Speech signal folder\n",
        "  mfcc_len : MFCC coefficient length\n",
        "  mean_signal_length : MFCC feature average length\n",
        "  \"\"\"\n",
        "\n",
        "  signal, fs = librosa.load(file_path)\n",
        "  s_len = len(signal)\n",
        "\n",
        "  if s_len < mean_signal_length:\n",
        "    pad_length = mean_signal_length - s_len\n",
        "    pad_reminder = pad_length % 2\n",
        "    pad_length //= 2\n",
        "  else:\n",
        "    pad_length = s_len - mean_signal_length\n",
        "    pad_reminder = pad_length % 2\n",
        "    pad_length //= 2\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=39)\n",
        "  mfcc = mfcc.T\n",
        "  feature = mfcc\n",
        "  return feature\n",
        ""
      ],
      "metadata": {
        "id": "t3QHBkLfUduC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode train --data EMODB --split_fold 10 --random_seed 46 --epoch 300 --gpu 0"
      ],
      "metadata": {
        "id": "nVBJXHtNUi3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f0d9c7-54f6-466d-be66-01af6cf3b06a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 285: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 904ms/step - loss: 1.3478 - accuracy: 1.0000 - val_loss: 1.4117 - val_accuracy: 0.9245\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3491 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.3491 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.9057\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3483 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 903ms/step - loss: 1.3483 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.9057\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3486 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.3486 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.9057\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3499 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 945ms/step - loss: 1.3499 - accuracy: 1.0000 - val_loss: 1.4063 - val_accuracy: 0.9245\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3500 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.3500 - accuracy: 1.0000 - val_loss: 1.4113 - val_accuracy: 0.9245\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3474 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 984ms/step - loss: 1.3474 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.9434\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3472 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.3472 - accuracy: 1.0000 - val_loss: 1.4177 - val_accuracy: 0.9057\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3485 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 977ms/step - loss: 1.3485 - accuracy: 1.0000 - val_loss: 1.4098 - val_accuracy: 0.9245\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3480 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.3480 - accuracy: 1.0000 - val_loss: 1.4123 - val_accuracy: 0.9057\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3459 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 918ms/step - loss: 1.3459 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.9245\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3468 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.3468 - accuracy: 1.0000 - val_loss: 1.4101 - val_accuracy: 0.9057\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3469 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 895ms/step - loss: 1.3469 - accuracy: 1.0000 - val_loss: 1.4038 - val_accuracy: 0.9057\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3478 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.3478 - accuracy: 1.0000 - val_loss: 1.4136 - val_accuracy: 0.9057\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3488 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 953ms/step - loss: 1.3488 - accuracy: 1.0000 - val_loss: 1.4064 - val_accuracy: 0.9057\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3454 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.3454 - accuracy: 1.0000 - val_loss: 1.4208 - val_accuracy: 0.9057\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.4209 - accuracy: 0.9623\n",
            "6_Model evaluation:  [1.4208569526672363, 0.9622641801834106]    Now ACC: 93.815\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f74300a1990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f74300a1990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      1.00      0.96        12\n",
            "     boredom       1.00      0.80      0.89         5\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         9\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.96        53\n",
            "   macro avg       0.98      0.95      0.96        53\n",
            "weighted avg       0.97      0.96      0.96        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.1129 - accuracy: 0.2324\n",
            "Epoch 1: val_accuracy improved from -inf to 0.22642, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 38s 1s/step - loss: 4.1129 - accuracy: 0.2324 - val_loss: 3.4928 - val_accuracy: 0.2264\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.3700 - accuracy: 0.2676\n",
            "Epoch 2: val_accuracy did not improve from 0.22642\n",
            "8/8 [==============================] - 10s 1s/step - loss: 2.3700 - accuracy: 0.2676 - val_loss: 2.5062 - val_accuracy: 0.2075\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9933 - accuracy: 0.2946\n",
            "Epoch 3: val_accuracy did not improve from 0.22642\n",
            "8/8 [==============================] - 7s 921ms/step - loss: 1.9933 - accuracy: 0.2946 - val_loss: 2.2607 - val_accuracy: 0.1321\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9006 - accuracy: 0.2490\n",
            "Epoch 4: val_accuracy did not improve from 0.22642\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.9006 - accuracy: 0.2490 - val_loss: 3.0884 - val_accuracy: 0.1698\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8801 - accuracy: 0.3278\n",
            "Epoch 5: val_accuracy improved from 0.22642 to 0.24528, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 911ms/step - loss: 1.8801 - accuracy: 0.3278 - val_loss: 3.0776 - val_accuracy: 0.2453\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8666 - accuracy: 0.4066\n",
            "Epoch 6: val_accuracy improved from 0.24528 to 0.26415, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.8666 - accuracy: 0.4066 - val_loss: 2.6413 - val_accuracy: 0.2642\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8337 - accuracy: 0.4544\n",
            "Epoch 7: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.8337 - accuracy: 0.4544 - val_loss: 2.3298 - val_accuracy: 0.2075\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8207 - accuracy: 0.4751\n",
            "Epoch 8: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8207 - accuracy: 0.4751 - val_loss: 2.1485 - val_accuracy: 0.2075\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8047 - accuracy: 0.4917\n",
            "Epoch 9: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.8047 - accuracy: 0.4917 - val_loss: 2.0412 - val_accuracy: 0.2453\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7927 - accuracy: 0.5041\n",
            "Epoch 10: val_accuracy improved from 0.26415 to 0.30189, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.7927 - accuracy: 0.5041 - val_loss: 1.9644 - val_accuracy: 0.3019\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7859 - accuracy: 0.5062\n",
            "Epoch 11: val_accuracy improved from 0.30189 to 0.33962, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 921ms/step - loss: 1.7859 - accuracy: 0.5062 - val_loss: 1.9224 - val_accuracy: 0.3396\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7686 - accuracy: 0.5498\n",
            "Epoch 12: val_accuracy improved from 0.33962 to 0.37736, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7686 - accuracy: 0.5498 - val_loss: 1.9119 - val_accuracy: 0.3774\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7585 - accuracy: 0.5581\n",
            "Epoch 13: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.7585 - accuracy: 0.5581 - val_loss: 1.9280 - val_accuracy: 0.3774\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7539 - accuracy: 0.5913\n",
            "Epoch 14: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7539 - accuracy: 0.5913 - val_loss: 1.9482 - val_accuracy: 0.3208\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7457 - accuracy: 0.5851\n",
            "Epoch 15: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.7457 - accuracy: 0.5851 - val_loss: 1.9651 - val_accuracy: 0.3019\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7316 - accuracy: 0.6100\n",
            "Epoch 16: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7316 - accuracy: 0.6100 - val_loss: 1.9437 - val_accuracy: 0.3019\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7188 - accuracy: 0.6058\n",
            "Epoch 17: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.7188 - accuracy: 0.6058 - val_loss: 1.9293 - val_accuracy: 0.3019\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7221 - accuracy: 0.6286\n",
            "Epoch 18: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7221 - accuracy: 0.6286 - val_loss: 1.8801 - val_accuracy: 0.3585\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7094 - accuracy: 0.6805\n",
            "Epoch 19: val_accuracy improved from 0.37736 to 0.39623, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.7094 - accuracy: 0.6805 - val_loss: 1.9012 - val_accuracy: 0.3962\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6999 - accuracy: 0.6826\n",
            "Epoch 20: val_accuracy improved from 0.39623 to 0.41509, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6999 - accuracy: 0.6826 - val_loss: 1.8877 - val_accuracy: 0.4151\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6903 - accuracy: 0.6971\n",
            "Epoch 21: val_accuracy improved from 0.41509 to 0.45283, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 1.6903 - accuracy: 0.6971 - val_loss: 1.8487 - val_accuracy: 0.4528\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6807 - accuracy: 0.7116\n",
            "Epoch 22: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6807 - accuracy: 0.7116 - val_loss: 1.8459 - val_accuracy: 0.4528\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6801 - accuracy: 0.7261\n",
            "Epoch 23: val_accuracy improved from 0.45283 to 0.47170, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 1.6801 - accuracy: 0.7261 - val_loss: 1.8707 - val_accuracy: 0.4717\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6633 - accuracy: 0.7324\n",
            "Epoch 24: val_accuracy did not improve from 0.47170\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6633 - accuracy: 0.7324 - val_loss: 1.8704 - val_accuracy: 0.4528\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6641 - accuracy: 0.7386\n",
            "Epoch 25: val_accuracy did not improve from 0.47170\n",
            "8/8 [==============================] - 7s 873ms/step - loss: 1.6641 - accuracy: 0.7386 - val_loss: 1.8542 - val_accuracy: 0.4717\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6610 - accuracy: 0.7469\n",
            "Epoch 26: val_accuracy improved from 0.47170 to 0.52830, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6610 - accuracy: 0.7469 - val_loss: 1.8206 - val_accuracy: 0.5283\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6484 - accuracy: 0.7573\n",
            "Epoch 27: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.6484 - accuracy: 0.7573 - val_loss: 1.8372 - val_accuracy: 0.5094\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6441 - accuracy: 0.7822\n",
            "Epoch 28: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6441 - accuracy: 0.7822 - val_loss: 1.8128 - val_accuracy: 0.5283\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6404 - accuracy: 0.7967\n",
            "Epoch 29: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 7s 860ms/step - loss: 1.6404 - accuracy: 0.7967 - val_loss: 1.7958 - val_accuracy: 0.5283\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6381 - accuracy: 0.7967\n",
            "Epoch 30: val_accuracy improved from 0.52830 to 0.56604, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6381 - accuracy: 0.7967 - val_loss: 1.8024 - val_accuracy: 0.5660\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6246 - accuracy: 0.8029\n",
            "Epoch 31: val_accuracy improved from 0.56604 to 0.58491, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 939ms/step - loss: 1.6246 - accuracy: 0.8029 - val_loss: 1.8204 - val_accuracy: 0.5849\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6186 - accuracy: 0.8174\n",
            "Epoch 32: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6186 - accuracy: 0.8174 - val_loss: 1.7993 - val_accuracy: 0.5472\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6240 - accuracy: 0.8050\n",
            "Epoch 33: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 7s 855ms/step - loss: 1.6240 - accuracy: 0.8050 - val_loss: 1.7800 - val_accuracy: 0.5472\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6153 - accuracy: 0.8029\n",
            "Epoch 34: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6153 - accuracy: 0.8029 - val_loss: 1.8143 - val_accuracy: 0.5472\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6146 - accuracy: 0.8071\n",
            "Epoch 35: val_accuracy improved from 0.58491 to 0.64151, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 1.6146 - accuracy: 0.8071 - val_loss: 1.7569 - val_accuracy: 0.6415\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6024 - accuracy: 0.8423\n",
            "Epoch 36: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6024 - accuracy: 0.8423 - val_loss: 1.7716 - val_accuracy: 0.5660\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5940 - accuracy: 0.8527\n",
            "Epoch 37: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.5940 - accuracy: 0.8527 - val_loss: 1.8475 - val_accuracy: 0.5283\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6013 - accuracy: 0.8506\n",
            "Epoch 38: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6013 - accuracy: 0.8506 - val_loss: 1.7770 - val_accuracy: 0.5472\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5924 - accuracy: 0.8900\n",
            "Epoch 39: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 870ms/step - loss: 1.5924 - accuracy: 0.8900 - val_loss: 1.7816 - val_accuracy: 0.5849\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 0.8506\n",
            "Epoch 40: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5898 - accuracy: 0.8506 - val_loss: 1.7752 - val_accuracy: 0.5283\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5864 - accuracy: 0.8672\n",
            "Epoch 41: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.5864 - accuracy: 0.8672 - val_loss: 1.7599 - val_accuracy: 0.6038\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5722 - accuracy: 0.9025\n",
            "Epoch 42: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5722 - accuracy: 0.9025 - val_loss: 1.7248 - val_accuracy: 0.6226\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5768 - accuracy: 0.8880\n",
            "Epoch 43: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 1.5768 - accuracy: 0.8880 - val_loss: 1.7659 - val_accuracy: 0.5849\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.8900\n",
            "Epoch 44: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5732 - accuracy: 0.8900 - val_loss: 1.7184 - val_accuracy: 0.6415\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5696 - accuracy: 0.8859\n",
            "Epoch 45: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.5696 - accuracy: 0.8859 - val_loss: 1.7316 - val_accuracy: 0.6415\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5683 - accuracy: 0.8963\n",
            "Epoch 46: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5683 - accuracy: 0.8963 - val_loss: 1.7514 - val_accuracy: 0.6226\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5683 - accuracy: 0.8880\n",
            "Epoch 47: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 874ms/step - loss: 1.5683 - accuracy: 0.8880 - val_loss: 1.7332 - val_accuracy: 0.6226\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5581 - accuracy: 0.9149\n",
            "Epoch 48: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5581 - accuracy: 0.9149 - val_loss: 1.6964 - val_accuracy: 0.6226\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5589 - accuracy: 0.9046\n",
            "Epoch 49: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 1.5589 - accuracy: 0.9046 - val_loss: 1.6959 - val_accuracy: 0.6226\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5514 - accuracy: 0.9170\n",
            "Epoch 50: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5514 - accuracy: 0.9170 - val_loss: 1.7352 - val_accuracy: 0.6226\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5568 - accuracy: 0.9149\n",
            "Epoch 51: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 918ms/step - loss: 1.5568 - accuracy: 0.9149 - val_loss: 1.7055 - val_accuracy: 0.6415\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5549 - accuracy: 0.9149\n",
            "Epoch 52: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5549 - accuracy: 0.9149 - val_loss: 1.7130 - val_accuracy: 0.6415\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5452 - accuracy: 0.9212\n",
            "Epoch 53: val_accuracy did not improve from 0.64151\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.5452 - accuracy: 0.9212 - val_loss: 1.6589 - val_accuracy: 0.6415\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5448 - accuracy: 0.9336\n",
            "Epoch 54: val_accuracy improved from 0.64151 to 0.67925, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5448 - accuracy: 0.9336 - val_loss: 1.6501 - val_accuracy: 0.6792\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5510 - accuracy: 0.9253\n",
            "Epoch 55: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.5510 - accuracy: 0.9253 - val_loss: 1.6686 - val_accuracy: 0.6226\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5399 - accuracy: 0.9461\n",
            "Epoch 56: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5399 - accuracy: 0.9461 - val_loss: 1.6666 - val_accuracy: 0.6415\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5399 - accuracy: 0.9232\n",
            "Epoch 57: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 1.5399 - accuracy: 0.9232 - val_loss: 1.6418 - val_accuracy: 0.6792\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5364 - accuracy: 0.9357\n",
            "Epoch 58: val_accuracy improved from 0.67925 to 0.73585, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5364 - accuracy: 0.9357 - val_loss: 1.6240 - val_accuracy: 0.7358\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.9523\n",
            "Epoch 59: val_accuracy did not improve from 0.73585\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.5328 - accuracy: 0.9523 - val_loss: 1.6417 - val_accuracy: 0.6604\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5314 - accuracy: 0.9378\n",
            "Epoch 60: val_accuracy did not improve from 0.73585\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5314 - accuracy: 0.9378 - val_loss: 1.6206 - val_accuracy: 0.7170\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5286 - accuracy: 0.9585\n",
            "Epoch 61: val_accuracy improved from 0.73585 to 0.75472, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 7s 934ms/step - loss: 1.5286 - accuracy: 0.9585 - val_loss: 1.6068 - val_accuracy: 0.7547\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5311 - accuracy: 0.9398\n",
            "Epoch 62: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5311 - accuracy: 0.9398 - val_loss: 1.6174 - val_accuracy: 0.7547\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5327 - accuracy: 0.9378\n",
            "Epoch 63: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 8s 948ms/step - loss: 1.5327 - accuracy: 0.9378 - val_loss: 1.6050 - val_accuracy: 0.7547\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5272 - accuracy: 0.9481\n",
            "Epoch 64: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5272 - accuracy: 0.9481 - val_loss: 1.6050 - val_accuracy: 0.7547\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5204 - accuracy: 0.9647\n",
            "Epoch 65: val_accuracy improved from 0.75472 to 0.79245, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 8s 960ms/step - loss: 1.5204 - accuracy: 0.9647 - val_loss: 1.6036 - val_accuracy: 0.7925\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5210 - accuracy: 0.9606\n",
            "Epoch 66: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5210 - accuracy: 0.9606 - val_loss: 1.6097 - val_accuracy: 0.7925\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5219 - accuracy: 0.9606\n",
            "Epoch 67: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 8s 950ms/step - loss: 1.5219 - accuracy: 0.9606 - val_loss: 1.6034 - val_accuracy: 0.7736\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5173 - accuracy: 0.9710\n",
            "Epoch 68: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5173 - accuracy: 0.9710 - val_loss: 1.6077 - val_accuracy: 0.7547\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5173 - accuracy: 0.9627\n",
            "Epoch 69: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 8s 954ms/step - loss: 1.5173 - accuracy: 0.9627 - val_loss: 1.6238 - val_accuracy: 0.7170\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5148 - accuracy: 0.9606\n",
            "Epoch 70: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5148 - accuracy: 0.9606 - val_loss: 1.6098 - val_accuracy: 0.7358\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5147 - accuracy: 0.9627\n",
            "Epoch 71: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 8s 984ms/step - loss: 1.5147 - accuracy: 0.9627 - val_loss: 1.5938 - val_accuracy: 0.7736\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5120 - accuracy: 0.9689\n",
            "Epoch 72: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5120 - accuracy: 0.9689 - val_loss: 1.5924 - val_accuracy: 0.7925\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5120 - accuracy: 0.9751\n",
            "Epoch 73: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 8s 950ms/step - loss: 1.5120 - accuracy: 0.9751 - val_loss: 1.5930 - val_accuracy: 0.7736\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5145 - accuracy: 0.9627\n",
            "Epoch 74: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5145 - accuracy: 0.9627 - val_loss: 1.6013 - val_accuracy: 0.7547\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5113 - accuracy: 0.9647\n",
            "Epoch 75: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 7s 940ms/step - loss: 1.5113 - accuracy: 0.9647 - val_loss: 1.5992 - val_accuracy: 0.7736\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5125 - accuracy: 0.9751\n",
            "Epoch 76: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5125 - accuracy: 0.9751 - val_loss: 1.6000 - val_accuracy: 0.7736\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5051 - accuracy: 0.9751\n",
            "Epoch 77: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 1.5051 - accuracy: 0.9751 - val_loss: 1.5956 - val_accuracy: 0.7547\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5074 - accuracy: 0.9689\n",
            "Epoch 78: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5074 - accuracy: 0.9689 - val_loss: 1.5888 - val_accuracy: 0.7925\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5089 - accuracy: 0.9689\n",
            "Epoch 79: val_accuracy improved from 0.79245 to 0.86792, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5089 - accuracy: 0.9689 - val_loss: 1.5789 - val_accuracy: 0.8679\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5068 - accuracy: 0.9793\n",
            "Epoch 80: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5068 - accuracy: 0.9793 - val_loss: 1.5854 - val_accuracy: 0.8302\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5067 - accuracy: 0.9772\n",
            "Epoch 81: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 8s 945ms/step - loss: 1.5067 - accuracy: 0.9772 - val_loss: 1.5866 - val_accuracy: 0.8302\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5060 - accuracy: 0.9710\n",
            "Epoch 82: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5060 - accuracy: 0.9710 - val_loss: 1.5815 - val_accuracy: 0.7925\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5007 - accuracy: 0.9813\n",
            "Epoch 83: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 871ms/step - loss: 1.5007 - accuracy: 0.9813 - val_loss: 1.5964 - val_accuracy: 0.8302\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4948 - accuracy: 0.9917\n",
            "Epoch 84: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4948 - accuracy: 0.9917 - val_loss: 1.5833 - val_accuracy: 0.8113\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5063 - accuracy: 0.9751\n",
            "Epoch 85: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 859ms/step - loss: 1.5063 - accuracy: 0.9751 - val_loss: 1.5742 - val_accuracy: 0.8302\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5003 - accuracy: 0.9855\n",
            "Epoch 86: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5003 - accuracy: 0.9855 - val_loss: 1.5726 - val_accuracy: 0.8302\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4979 - accuracy: 0.9834\n",
            "Epoch 87: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.4979 - accuracy: 0.9834 - val_loss: 1.5905 - val_accuracy: 0.7925\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4946 - accuracy: 0.9917\n",
            "Epoch 88: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4946 - accuracy: 0.9917 - val_loss: 1.5930 - val_accuracy: 0.7925\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4963 - accuracy: 0.9730\n",
            "Epoch 89: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 1.4963 - accuracy: 0.9730 - val_loss: 1.5995 - val_accuracy: 0.7925\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4978 - accuracy: 0.9730\n",
            "Epoch 90: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4978 - accuracy: 0.9730 - val_loss: 1.6086 - val_accuracy: 0.7547\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4911 - accuracy: 0.9896\n",
            "Epoch 91: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 1.4911 - accuracy: 0.9896 - val_loss: 1.5856 - val_accuracy: 0.8302\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4945 - accuracy: 0.9834\n",
            "Epoch 92: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4945 - accuracy: 0.9834 - val_loss: 1.6074 - val_accuracy: 0.7925\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4922 - accuracy: 0.9917\n",
            "Epoch 93: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 923ms/step - loss: 1.4922 - accuracy: 0.9917 - val_loss: 1.5879 - val_accuracy: 0.8113\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4929 - accuracy: 0.9813\n",
            "Epoch 94: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4929 - accuracy: 0.9813 - val_loss: 1.5836 - val_accuracy: 0.8113\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4916 - accuracy: 0.9855\n",
            "Epoch 95: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 869ms/step - loss: 1.4916 - accuracy: 0.9855 - val_loss: 1.5776 - val_accuracy: 0.8302\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4896 - accuracy: 0.9876\n",
            "Epoch 96: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4896 - accuracy: 0.9876 - val_loss: 1.5755 - val_accuracy: 0.8679\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4950 - accuracy: 0.9876\n",
            "Epoch 97: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 1.4950 - accuracy: 0.9876 - val_loss: 1.5668 - val_accuracy: 0.8679\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4877 - accuracy: 0.9855\n",
            "Epoch 98: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4877 - accuracy: 0.9855 - val_loss: 1.5752 - val_accuracy: 0.8113\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4865 - accuracy: 0.9876\n",
            "Epoch 99: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.4865 - accuracy: 0.9876 - val_loss: 1.5718 - val_accuracy: 0.8679\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4888 - accuracy: 0.9896\n",
            "Epoch 100: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4888 - accuracy: 0.9896 - val_loss: 1.5652 - val_accuracy: 0.8679\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4851 - accuracy: 0.9917\n",
            "Epoch 101: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.4851 - accuracy: 0.9917 - val_loss: 1.5715 - val_accuracy: 0.8679\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4845 - accuracy: 0.9896\n",
            "Epoch 102: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4845 - accuracy: 0.9896 - val_loss: 1.5738 - val_accuracy: 0.8491\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4841 - accuracy: 0.9896\n",
            "Epoch 103: val_accuracy improved from 0.86792 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 8s 985ms/step - loss: 1.4841 - accuracy: 0.9896 - val_loss: 1.5726 - val_accuracy: 0.8868\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4798 - accuracy: 0.9938\n",
            "Epoch 104: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4798 - accuracy: 0.9938 - val_loss: 1.5676 - val_accuracy: 0.8302\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4840 - accuracy: 0.9896\n",
            "Epoch 105: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 986ms/step - loss: 1.4840 - accuracy: 0.9896 - val_loss: 1.5634 - val_accuracy: 0.8302\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4856 - accuracy: 0.9979\n",
            "Epoch 106: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4856 - accuracy: 0.9979 - val_loss: 1.5714 - val_accuracy: 0.8491\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4834 - accuracy: 0.9876\n",
            "Epoch 107: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.4834 - accuracy: 0.9876 - val_loss: 1.5606 - val_accuracy: 0.8302\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4807 - accuracy: 0.9959\n",
            "Epoch 108: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4807 - accuracy: 0.9959 - val_loss: 1.5647 - val_accuracy: 0.8679\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.9979\n",
            "Epoch 109: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 956ms/step - loss: 1.4756 - accuracy: 0.9979 - val_loss: 1.5703 - val_accuracy: 0.8491\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4765 - accuracy: 0.9979\n",
            "Epoch 110: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4765 - accuracy: 0.9979 - val_loss: 1.5660 - val_accuracy: 0.8302\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4775 - accuracy: 0.9959\n",
            "Epoch 111: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 971ms/step - loss: 1.4775 - accuracy: 0.9959 - val_loss: 1.5568 - val_accuracy: 0.8491\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4780 - accuracy: 0.9959\n",
            "Epoch 112: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4780 - accuracy: 0.9959 - val_loss: 1.5635 - val_accuracy: 0.8679\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.9959\n",
            "Epoch 113: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 938ms/step - loss: 1.4805 - accuracy: 0.9959 - val_loss: 1.5613 - val_accuracy: 0.8679\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4777 - accuracy: 0.9917\n",
            "Epoch 114: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4777 - accuracy: 0.9917 - val_loss: 1.5586 - val_accuracy: 0.8302\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4789 - accuracy: 0.9959\n",
            "Epoch 115: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 1.4789 - accuracy: 0.9959 - val_loss: 1.5626 - val_accuracy: 0.8868\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4757 - accuracy: 1.0000\n",
            "Epoch 116: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4757 - accuracy: 1.0000 - val_loss: 1.5663 - val_accuracy: 0.8302\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4724 - accuracy: 0.9979\n",
            "Epoch 117: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 1.4724 - accuracy: 0.9979 - val_loss: 1.5602 - val_accuracy: 0.8679\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4753 - accuracy: 0.9938\n",
            "Epoch 118: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4753 - accuracy: 0.9938 - val_loss: 1.5638 - val_accuracy: 0.8679\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4752 - accuracy: 0.9959\n",
            "Epoch 119: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 933ms/step - loss: 1.4752 - accuracy: 0.9959 - val_loss: 1.5663 - val_accuracy: 0.8302\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4798 - accuracy: 0.9917\n",
            "Epoch 120: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4798 - accuracy: 0.9917 - val_loss: 1.5743 - val_accuracy: 0.8491\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.9938\n",
            "Epoch 121: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 925ms/step - loss: 1.4709 - accuracy: 0.9938 - val_loss: 1.5610 - val_accuracy: 0.8679\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4724 - accuracy: 1.0000\n",
            "Epoch 122: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4724 - accuracy: 1.0000 - val_loss: 1.5640 - val_accuracy: 0.8302\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4710 - accuracy: 0.9979\n",
            "Epoch 123: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 964ms/step - loss: 1.4710 - accuracy: 0.9979 - val_loss: 1.5677 - val_accuracy: 0.8491\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4701 - accuracy: 0.9959\n",
            "Epoch 124: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4701 - accuracy: 0.9959 - val_loss: 1.5694 - val_accuracy: 0.8113\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4708 - accuracy: 0.9959\n",
            "Epoch 125: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 1.4708 - accuracy: 0.9959 - val_loss: 1.5692 - val_accuracy: 0.8113\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4713 - accuracy: 0.9896\n",
            "Epoch 126: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4713 - accuracy: 0.9896 - val_loss: 1.5686 - val_accuracy: 0.7925\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 0.9979\n",
            "Epoch 127: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 867ms/step - loss: 1.4707 - accuracy: 0.9979 - val_loss: 1.5913 - val_accuracy: 0.7736\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4729 - accuracy: 0.9917\n",
            "Epoch 128: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4729 - accuracy: 0.9917 - val_loss: 1.5603 - val_accuracy: 0.8491\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4688 - accuracy: 1.0000\n",
            "Epoch 129: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 863ms/step - loss: 1.4688 - accuracy: 1.0000 - val_loss: 1.5661 - val_accuracy: 0.8491\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4719 - accuracy: 0.9917\n",
            "Epoch 130: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4719 - accuracy: 0.9917 - val_loss: 1.5614 - val_accuracy: 0.8491\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4680 - accuracy: 0.9979\n",
            "Epoch 131: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 952ms/step - loss: 1.4680 - accuracy: 0.9979 - val_loss: 1.5543 - val_accuracy: 0.8302\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4697 - accuracy: 0.9959\n",
            "Epoch 132: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4697 - accuracy: 0.9959 - val_loss: 1.5547 - val_accuracy: 0.8679\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4682 - accuracy: 0.9959\n",
            "Epoch 133: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.4682 - accuracy: 0.9959 - val_loss: 1.5547 - val_accuracy: 0.8491\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.9979\n",
            "Epoch 134: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4670 - accuracy: 0.9979 - val_loss: 1.5621 - val_accuracy: 0.8302\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 1.4662 - accuracy: 0.9979 - val_loss: 1.5580 - val_accuracy: 0.8302\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4694 - accuracy: 1.0000\n",
            "Epoch 136: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4694 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.8491\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4668 - accuracy: 1.0000\n",
            "Epoch 137: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 872ms/step - loss: 1.4668 - accuracy: 1.0000 - val_loss: 1.5859 - val_accuracy: 0.8113\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4657 - accuracy: 0.9979\n",
            "Epoch 138: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4657 - accuracy: 0.9979 - val_loss: 1.5604 - val_accuracy: 0.8491\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 1.0000\n",
            "Epoch 139: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 1.4648 - accuracy: 1.0000 - val_loss: 1.5490 - val_accuracy: 0.8491\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4674 - accuracy: 1.0000\n",
            "Epoch 140: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4674 - accuracy: 1.0000 - val_loss: 1.5537 - val_accuracy: 0.8302\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 1.0000\n",
            "Epoch 141: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 876ms/step - loss: 1.4623 - accuracy: 1.0000 - val_loss: 1.5605 - val_accuracy: 0.8491\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4664 - accuracy: 0.9959\n",
            "Epoch 142: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4664 - accuracy: 0.9959 - val_loss: 1.5514 - val_accuracy: 0.8302\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.9979\n",
            "Epoch 143: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.4693 - accuracy: 0.9979 - val_loss: 1.5529 - val_accuracy: 0.8868\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4620 - accuracy: 1.0000\n",
            "Epoch 144: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4620 - accuracy: 1.0000 - val_loss: 1.5651 - val_accuracy: 0.8491\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4651 - accuracy: 0.9959\n",
            "Epoch 145: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 877ms/step - loss: 1.4651 - accuracy: 0.9959 - val_loss: 1.5562 - val_accuracy: 0.8491\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4657 - accuracy: 1.0000\n",
            "Epoch 146: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4657 - accuracy: 1.0000 - val_loss: 1.5575 - val_accuracy: 0.8302\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4629 - accuracy: 0.9979\n",
            "Epoch 147: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.4629 - accuracy: 0.9979 - val_loss: 1.5666 - val_accuracy: 0.7925\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4632 - accuracy: 0.9979\n",
            "Epoch 148: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4632 - accuracy: 0.9979 - val_loss: 1.5645 - val_accuracy: 0.7925\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 1.0000\n",
            "Epoch 149: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.4617 - accuracy: 1.0000 - val_loss: 1.5770 - val_accuracy: 0.8113\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4628 - accuracy: 0.9917\n",
            "Epoch 150: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4628 - accuracy: 0.9917 - val_loss: 1.5738 - val_accuracy: 0.7925\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4632 - accuracy: 0.9959\n",
            "Epoch 151: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 917ms/step - loss: 1.4632 - accuracy: 0.9959 - val_loss: 1.5757 - val_accuracy: 0.8113\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 1.0000\n",
            "Epoch 152: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4600 - accuracy: 1.0000 - val_loss: 1.5605 - val_accuracy: 0.8491\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4624 - accuracy: 0.9979\n",
            "Epoch 153: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.4624 - accuracy: 0.9979 - val_loss: 1.5741 - val_accuracy: 0.7925\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4647 - accuracy: 0.9979\n",
            "Epoch 154: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4647 - accuracy: 0.9979 - val_loss: 1.5647 - val_accuracy: 0.8491\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4595 - accuracy: 0.9979\n",
            "Epoch 155: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 918ms/step - loss: 1.4595 - accuracy: 0.9979 - val_loss: 1.5586 - val_accuracy: 0.8302\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4604 - accuracy: 1.0000\n",
            "Epoch 156: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4604 - accuracy: 1.0000 - val_loss: 1.5650 - val_accuracy: 0.8679\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4611 - accuracy: 1.0000\n",
            "Epoch 157: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 1.4611 - accuracy: 1.0000 - val_loss: 1.5591 - val_accuracy: 0.8491\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4588 - accuracy: 1.0000\n",
            "Epoch 158: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4588 - accuracy: 1.0000 - val_loss: 1.5518 - val_accuracy: 0.8679\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4608 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.4608 - accuracy: 1.0000 - val_loss: 1.5540 - val_accuracy: 0.8302\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4577 - accuracy: 1.0000 - val_loss: 1.5758 - val_accuracy: 0.7925\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4573 - accuracy: 0.9979\n",
            "Epoch 161: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.4573 - accuracy: 0.9979 - val_loss: 1.5654 - val_accuracy: 0.7925\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4590 - accuracy: 1.0000\n",
            "Epoch 162: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4590 - accuracy: 1.0000 - val_loss: 1.5697 - val_accuracy: 0.8113\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.9979\n",
            "Epoch 163: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 914ms/step - loss: 1.4600 - accuracy: 0.9979 - val_loss: 1.5554 - val_accuracy: 0.8302\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4577 - accuracy: 1.0000 - val_loss: 1.5531 - val_accuracy: 0.8302\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 1.4577 - accuracy: 1.0000 - val_loss: 1.5553 - val_accuracy: 0.8679\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4588 - accuracy: 0.9979\n",
            "Epoch 166: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4588 - accuracy: 0.9979 - val_loss: 1.5565 - val_accuracy: 0.8679\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4590 - accuracy: 0.9979\n",
            "Epoch 167: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.4590 - accuracy: 0.9979 - val_loss: 1.5617 - val_accuracy: 0.8868\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4580 - accuracy: 0.9979\n",
            "Epoch 168: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4580 - accuracy: 0.9979 - val_loss: 1.5576 - val_accuracy: 0.8491\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 0.9938\n",
            "Epoch 169: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 973ms/step - loss: 1.4577 - accuracy: 0.9938 - val_loss: 1.5615 - val_accuracy: 0.8679\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4587 - accuracy: 0.9959\n",
            "Epoch 170: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4587 - accuracy: 0.9959 - val_loss: 1.5573 - val_accuracy: 0.8302\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4599 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 928ms/step - loss: 1.4599 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.8113\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4571 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4571 - accuracy: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.8302\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4535 - accuracy: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.4535 - accuracy: 1.0000 - val_loss: 1.5655 - val_accuracy: 0.8302\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4601 - accuracy: 0.9979\n",
            "Epoch 174: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4601 - accuracy: 0.9979 - val_loss: 1.5579 - val_accuracy: 0.8302\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 1.4600 - accuracy: 1.0000 - val_loss: 1.5547 - val_accuracy: 0.8491\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4584 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4584 - accuracy: 1.0000 - val_loss: 1.5518 - val_accuracy: 0.8302\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4563 - accuracy: 0.9979\n",
            "Epoch 177: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 1.4563 - accuracy: 0.9979 - val_loss: 1.5555 - val_accuracy: 0.8491\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4555 - accuracy: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4555 - accuracy: 1.0000 - val_loss: 1.5536 - val_accuracy: 0.8491\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4521 - accuracy: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 1.4521 - accuracy: 1.0000 - val_loss: 1.5583 - val_accuracy: 0.8113\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4521 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4521 - accuracy: 1.0000 - val_loss: 1.5621 - val_accuracy: 0.8113\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4559 - accuracy: 0.9979\n",
            "Epoch 181: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.4559 - accuracy: 0.9979 - val_loss: 1.5689 - val_accuracy: 0.7925\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4545 - accuracy: 0.9979\n",
            "Epoch 182: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4545 - accuracy: 0.9979 - val_loss: 1.5710 - val_accuracy: 0.8113\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.4577 - accuracy: 1.0000 - val_loss: 1.5625 - val_accuracy: 0.8113\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4560 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4560 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.7925\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4569 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.4569 - accuracy: 1.0000 - val_loss: 1.5499 - val_accuracy: 0.8679\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4540 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4540 - accuracy: 1.0000 - val_loss: 1.5529 - val_accuracy: 0.8113\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4527 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 874ms/step - loss: 1.4527 - accuracy: 1.0000 - val_loss: 1.5495 - val_accuracy: 0.8679\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4553 - accuracy: 1.0000\n",
            "Epoch 188: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4553 - accuracy: 1.0000 - val_loss: 1.5558 - val_accuracy: 0.8302\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4532 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 1.4532 - accuracy: 1.0000 - val_loss: 1.5567 - val_accuracy: 0.8302\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4520 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4520 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.7925\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4554 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 1.4554 - accuracy: 1.0000 - val_loss: 1.5536 - val_accuracy: 0.8491\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4519 - accuracy: 0.9979\n",
            "Epoch 192: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4519 - accuracy: 0.9979 - val_loss: 1.5550 - val_accuracy: 0.8679\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4542 - accuracy: 0.9979\n",
            "Epoch 193: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 921ms/step - loss: 1.4542 - accuracy: 0.9979 - val_loss: 1.5582 - val_accuracy: 0.8113\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4563 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4563 - accuracy: 1.0000 - val_loss: 1.5723 - val_accuracy: 0.8113\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4533 - accuracy: 0.9979\n",
            "Epoch 195: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 1.4533 - accuracy: 0.9979 - val_loss: 1.5633 - val_accuracy: 0.8679\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4527 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4527 - accuracy: 1.0000 - val_loss: 1.5599 - val_accuracy: 0.8302\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4517 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 915ms/step - loss: 1.4517 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.8491\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4509 - accuracy: 1.0000 - val_loss: 1.5627 - val_accuracy: 0.8302\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4526 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 936ms/step - loss: 1.4526 - accuracy: 1.0000 - val_loss: 1.5526 - val_accuracy: 0.8491\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4532 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4532 - accuracy: 1.0000 - val_loss: 1.5498 - val_accuracy: 0.8302\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4493 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 923ms/step - loss: 1.4493 - accuracy: 1.0000 - val_loss: 1.5560 - val_accuracy: 0.8302\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4521 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4521 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.8302\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4500 - accuracy: 0.9979\n",
            "Epoch 203: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.4500 - accuracy: 0.9979 - val_loss: 1.5649 - val_accuracy: 0.8113\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4499 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4499 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.8491\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4502 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 865ms/step - loss: 1.4502 - accuracy: 1.0000 - val_loss: 1.5696 - val_accuracy: 0.7736\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4506 - accuracy: 0.9979\n",
            "Epoch 206: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4506 - accuracy: 0.9979 - val_loss: 1.5612 - val_accuracy: 0.7925\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4497 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 866ms/step - loss: 1.4497 - accuracy: 1.0000 - val_loss: 1.5649 - val_accuracy: 0.7925\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4496 - accuracy: 1.0000 - val_loss: 1.5553 - val_accuracy: 0.8113\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4510 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.4510 - accuracy: 1.0000 - val_loss: 1.5668 - val_accuracy: 0.7736\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4532 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4532 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.7925\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4485 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.4485 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.8302\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4512 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4512 - accuracy: 1.0000 - val_loss: 1.5872 - val_accuracy: 0.8113\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4501 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.4501 - accuracy: 1.0000 - val_loss: 1.5692 - val_accuracy: 0.8302\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4514 - accuracy: 0.9979\n",
            "Epoch 214: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4514 - accuracy: 0.9979 - val_loss: 1.5798 - val_accuracy: 0.8302\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4486 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.4486 - accuracy: 1.0000 - val_loss: 1.5694 - val_accuracy: 0.8113\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4492 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4492 - accuracy: 1.0000 - val_loss: 1.5697 - val_accuracy: 0.7925\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 864ms/step - loss: 1.4496 - accuracy: 1.0000 - val_loss: 1.5552 - val_accuracy: 0.8302\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4480 - accuracy: 1.0000\n",
            "Epoch 218: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4480 - accuracy: 1.0000 - val_loss: 1.5593 - val_accuracy: 0.8302\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4489 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 1.4489 - accuracy: 1.0000 - val_loss: 1.5594 - val_accuracy: 0.8302\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4489 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4489 - accuracy: 1.0000 - val_loss: 1.5647 - val_accuracy: 0.8491\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4511 - accuracy: 1.0000\n",
            "Epoch 221: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.4511 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.8302\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4503 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4503 - accuracy: 1.0000 - val_loss: 1.5734 - val_accuracy: 0.8302\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4504 - accuracy: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.4504 - accuracy: 1.0000 - val_loss: 1.5579 - val_accuracy: 0.8491\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4471 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4471 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.8491\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4503 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.4503 - accuracy: 1.0000 - val_loss: 1.5509 - val_accuracy: 0.8491\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4472 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4472 - accuracy: 1.0000 - val_loss: 1.5579 - val_accuracy: 0.8491\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4484 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 868ms/step - loss: 1.4484 - accuracy: 1.0000 - val_loss: 1.5620 - val_accuracy: 0.8302\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4477 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4477 - accuracy: 1.0000 - val_loss: 1.5620 - val_accuracy: 0.8491\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4484 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 873ms/step - loss: 1.4484 - accuracy: 1.0000 - val_loss: 1.5499 - val_accuracy: 0.8491\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4487 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4487 - accuracy: 1.0000 - val_loss: 1.5564 - val_accuracy: 0.8302\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4487 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 861ms/step - loss: 1.4487 - accuracy: 1.0000 - val_loss: 1.5500 - val_accuracy: 0.8302\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4490 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4490 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.8491\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4484 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.4484 - accuracy: 1.0000 - val_loss: 1.5640 - val_accuracy: 0.7925\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4482 - accuracy: 0.9979\n",
            "Epoch 234: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4482 - accuracy: 0.9979 - val_loss: 1.5545 - val_accuracy: 0.8491\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4477 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.4477 - accuracy: 1.0000 - val_loss: 1.5573 - val_accuracy: 0.7925\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4457 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4457 - accuracy: 1.0000 - val_loss: 1.5605 - val_accuracy: 0.7925\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4471 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 1.4471 - accuracy: 1.0000 - val_loss: 1.5549 - val_accuracy: 0.8302\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4462 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4462 - accuracy: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.8113\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4474 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 864ms/step - loss: 1.4474 - accuracy: 1.0000 - val_loss: 1.5564 - val_accuracy: 0.8302\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4480 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4480 - accuracy: 1.0000 - val_loss: 1.5635 - val_accuracy: 0.7925\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4462 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 911ms/step - loss: 1.4462 - accuracy: 1.0000 - val_loss: 1.5539 - val_accuracy: 0.8113\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4467 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4467 - accuracy: 1.0000 - val_loss: 1.5464 - val_accuracy: 0.8113\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4463 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.4463 - accuracy: 1.0000 - val_loss: 1.5571 - val_accuracy: 0.7925\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4467 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4467 - accuracy: 1.0000 - val_loss: 1.5542 - val_accuracy: 0.8679\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4475 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.4475 - accuracy: 1.0000 - val_loss: 1.5587 - val_accuracy: 0.8302\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4468 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4468 - accuracy: 1.0000 - val_loss: 1.5498 - val_accuracy: 0.8491\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4470 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 893ms/step - loss: 1.4470 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.8113\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4466 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4466 - accuracy: 1.0000 - val_loss: 1.5626 - val_accuracy: 0.7925\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4445 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.4445 - accuracy: 1.0000 - val_loss: 1.5518 - val_accuracy: 0.8302\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4461 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4461 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.8113\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4450 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 919ms/step - loss: 1.4450 - accuracy: 1.0000 - val_loss: 1.5532 - val_accuracy: 0.8302\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4468 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4468 - accuracy: 1.0000 - val_loss: 1.5675 - val_accuracy: 0.8302\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4455 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 916ms/step - loss: 1.4455 - accuracy: 1.0000 - val_loss: 1.5587 - val_accuracy: 0.8113\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4447 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4447 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.8113\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4439 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 913ms/step - loss: 1.4439 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.8302\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4493 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4493 - accuracy: 1.0000 - val_loss: 1.5460 - val_accuracy: 0.8679\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4456 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 902ms/step - loss: 1.4456 - accuracy: 1.0000 - val_loss: 1.5503 - val_accuracy: 0.8491\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4470 - accuracy: 0.9979\n",
            "Epoch 258: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4470 - accuracy: 0.9979 - val_loss: 1.5545 - val_accuracy: 0.8679\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4455 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 1.4455 - accuracy: 1.0000 - val_loss: 1.5507 - val_accuracy: 0.8679\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4442 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4442 - accuracy: 1.0000 - val_loss: 1.5497 - val_accuracy: 0.8491\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4441 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 914ms/step - loss: 1.4441 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.8491\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4450 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4450 - accuracy: 1.0000 - val_loss: 1.5549 - val_accuracy: 0.8491\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4457 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.4457 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.8491\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4456 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4456 - accuracy: 1.0000 - val_loss: 1.5643 - val_accuracy: 0.8302\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4446 - accuracy: 1.0000\n",
            "Epoch 265: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.4446 - accuracy: 1.0000 - val_loss: 1.5699 - val_accuracy: 0.8491\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4437 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4437 - accuracy: 1.0000 - val_loss: 1.5562 - val_accuracy: 0.8491\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4444 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.4444 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.8491\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4444 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4444 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.8491\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4428 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.4428 - accuracy: 1.0000 - val_loss: 1.5547 - val_accuracy: 0.8302\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4433 - accuracy: 1.0000 - val_loss: 1.5560 - val_accuracy: 0.8679\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4438 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.4438 - accuracy: 1.0000 - val_loss: 1.5611 - val_accuracy: 0.8302\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4458 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4458 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.8113\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 915ms/step - loss: 1.4433 - accuracy: 1.0000 - val_loss: 1.5555 - val_accuracy: 0.8679\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4436 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4436 - accuracy: 1.0000 - val_loss: 1.5553 - val_accuracy: 0.8491\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4421 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.4421 - accuracy: 1.0000 - val_loss: 1.5564 - val_accuracy: 0.8679\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4422 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.5577 - val_accuracy: 0.8679\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4436 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.4436 - accuracy: 1.0000 - val_loss: 1.5536 - val_accuracy: 0.8679\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4421 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4421 - accuracy: 1.0000 - val_loss: 1.5507 - val_accuracy: 0.8491\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4437 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.4437 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.8491\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4437 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4437 - accuracy: 1.0000 - val_loss: 1.5659 - val_accuracy: 0.8302\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4428 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.4428 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.8679\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4434 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4434 - accuracy: 1.0000 - val_loss: 1.5595 - val_accuracy: 0.8491\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4435 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 911ms/step - loss: 1.4435 - accuracy: 1.0000 - val_loss: 1.5605 - val_accuracy: 0.8302\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4432 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4432 - accuracy: 1.0000 - val_loss: 1.5545 - val_accuracy: 0.8302\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.4423 - accuracy: 1.0000 - val_loss: 1.5609 - val_accuracy: 0.8302\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4430 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4430 - accuracy: 1.0000 - val_loss: 1.5525 - val_accuracy: 0.8491\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4443 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 1.4443 - accuracy: 1.0000 - val_loss: 1.5547 - val_accuracy: 0.8491\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4430 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4430 - accuracy: 1.0000 - val_loss: 1.5590 - val_accuracy: 0.8302\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4410 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.4410 - accuracy: 1.0000 - val_loss: 1.5577 - val_accuracy: 0.8113\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4432 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4432 - accuracy: 1.0000 - val_loss: 1.5484 - val_accuracy: 0.8302\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.4440 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.8679\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4433 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.8491\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4424 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 1.4424 - accuracy: 1.0000 - val_loss: 1.5419 - val_accuracy: 0.8868\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4428 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4428 - accuracy: 1.0000 - val_loss: 1.5473 - val_accuracy: 0.8491\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4427 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 944ms/step - loss: 1.4427 - accuracy: 1.0000 - val_loss: 1.5474 - val_accuracy: 0.8491\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4422 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.5526 - val_accuracy: 0.8113\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4431 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.4431 - accuracy: 1.0000 - val_loss: 1.5582 - val_accuracy: 0.8113\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4423 - accuracy: 1.0000 - val_loss: 1.5551 - val_accuracy: 0.8491\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4419 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.4419 - accuracy: 1.0000 - val_loss: 1.5532 - val_accuracy: 0.8679\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4434 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.4434 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.8491\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.5726 - accuracy: 0.8868\n",
            "7_Model evaluation:  [1.5725948810577393, 0.8867924809455872]    Now ACC: 93.08142857142857\n",
            "2/2 [==============================] - 2s 67ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.91      0.91      0.91        11\n",
            "     boredom       0.91      1.00      0.95        10\n",
            "     disgust       1.00      0.67      0.80         3\n",
            "        fear       0.78      1.00      0.88         7\n",
            "       happy       0.75      0.67      0.71         9\n",
            "     neutral       1.00      0.86      0.92         7\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.89        53\n",
            "   macro avg       0.91      0.87      0.88        53\n",
            "weighted avg       0.89      0.89      0.88        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 8.5713 - accuracy: 0.1120\n",
            "Epoch 1: val_accuracy improved from -inf to 0.16981, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 42s 2s/step - loss: 8.5713 - accuracy: 0.1120 - val_loss: 5.3177 - val_accuracy: 0.1698\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.5701 - accuracy: 0.1826\n",
            "Epoch 2: val_accuracy did not improve from 0.16981\n",
            "8/8 [==============================] - 7s 930ms/step - loss: 3.5701 - accuracy: 0.1826 - val_loss: 3.0345 - val_accuracy: 0.1132\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4279 - accuracy: 0.1846\n",
            "Epoch 3: val_accuracy improved from 0.16981 to 0.18868, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 2.4279 - accuracy: 0.1846 - val_loss: 2.9059 - val_accuracy: 0.1887\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.1758 - accuracy: 0.2407\n",
            "Epoch 4: val_accuracy improved from 0.18868 to 0.22642, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 8s 954ms/step - loss: 2.1758 - accuracy: 0.2407 - val_loss: 2.5318 - val_accuracy: 0.2264\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0153 - accuracy: 0.2158\n",
            "Epoch 5: val_accuracy improved from 0.22642 to 0.26415, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 2.0153 - accuracy: 0.2158 - val_loss: 2.1897 - val_accuracy: 0.2642\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9168 - accuracy: 0.2573\n",
            "Epoch 6: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 8s 958ms/step - loss: 1.9168 - accuracy: 0.2573 - val_loss: 2.1857 - val_accuracy: 0.0755\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9016 - accuracy: 0.3299\n",
            "Epoch 7: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.9016 - accuracy: 0.3299 - val_loss: 2.1243 - val_accuracy: 0.0755\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8861 - accuracy: 0.3817\n",
            "Epoch 8: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 7s 922ms/step - loss: 1.8861 - accuracy: 0.3817 - val_loss: 2.0366 - val_accuracy: 0.2642\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8621 - accuracy: 0.4419\n",
            "Epoch 9: val_accuracy improved from 0.26415 to 0.37736, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8621 - accuracy: 0.4419 - val_loss: 2.0146 - val_accuracy: 0.3774\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8542 - accuracy: 0.4295\n",
            "Epoch 10: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.8542 - accuracy: 0.4295 - val_loss: 2.0167 - val_accuracy: 0.3396\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8353 - accuracy: 0.4917\n",
            "Epoch 11: val_accuracy improved from 0.37736 to 0.41509, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8353 - accuracy: 0.4917 - val_loss: 1.9506 - val_accuracy: 0.4151\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8251 - accuracy: 0.5000\n",
            "Epoch 12: val_accuracy improved from 0.41509 to 0.47170, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.8251 - accuracy: 0.5000 - val_loss: 1.8833 - val_accuracy: 0.4717\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8139 - accuracy: 0.5124\n",
            "Epoch 13: val_accuracy improved from 0.47170 to 0.52830, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8139 - accuracy: 0.5124 - val_loss: 1.8322 - val_accuracy: 0.5283\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8044 - accuracy: 0.5187\n",
            "Epoch 14: val_accuracy improved from 0.52830 to 0.58491, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.8044 - accuracy: 0.5187 - val_loss: 1.7995 - val_accuracy: 0.5849\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8004 - accuracy: 0.5228\n",
            "Epoch 15: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.8004 - accuracy: 0.5228 - val_loss: 1.7891 - val_accuracy: 0.5849\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7892 - accuracy: 0.5477\n",
            "Epoch 16: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7892 - accuracy: 0.5477 - val_loss: 1.7969 - val_accuracy: 0.5660\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7858 - accuracy: 0.5726\n",
            "Epoch 17: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7858 - accuracy: 0.5726 - val_loss: 1.8141 - val_accuracy: 0.5472\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7745 - accuracy: 0.5913\n",
            "Epoch 18: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7745 - accuracy: 0.5913 - val_loss: 1.8063 - val_accuracy: 0.5849\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7724 - accuracy: 0.5871\n",
            "Epoch 19: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7724 - accuracy: 0.5871 - val_loss: 1.7953 - val_accuracy: 0.5849\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7656 - accuracy: 0.6369\n",
            "Epoch 20: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7656 - accuracy: 0.6369 - val_loss: 1.7801 - val_accuracy: 0.5660\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7558 - accuracy: 0.6556\n",
            "Epoch 21: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 8s 972ms/step - loss: 1.7558 - accuracy: 0.6556 - val_loss: 1.8000 - val_accuracy: 0.5660\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7545 - accuracy: 0.6390\n",
            "Epoch 22: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7545 - accuracy: 0.6390 - val_loss: 1.8315 - val_accuracy: 0.5660\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7437 - accuracy: 0.6701\n",
            "Epoch 23: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 8s 971ms/step - loss: 1.7437 - accuracy: 0.6701 - val_loss: 1.8611 - val_accuracy: 0.5660\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7425 - accuracy: 0.6432\n",
            "Epoch 24: val_accuracy did not improve from 0.58491\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7425 - accuracy: 0.6432 - val_loss: 1.8295 - val_accuracy: 0.5849\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7363 - accuracy: 0.6680\n",
            "Epoch 25: val_accuracy improved from 0.58491 to 0.60377, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 8s 941ms/step - loss: 1.7363 - accuracy: 0.6680 - val_loss: 1.7717 - val_accuracy: 0.6038\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7310 - accuracy: 0.7095\n",
            "Epoch 26: val_accuracy improved from 0.60377 to 0.66038, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7310 - accuracy: 0.7095 - val_loss: 1.7425 - val_accuracy: 0.6604\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7274 - accuracy: 0.6950\n",
            "Epoch 27: val_accuracy improved from 0.66038 to 0.69811, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 8s 932ms/step - loss: 1.7274 - accuracy: 0.6950 - val_loss: 1.7413 - val_accuracy: 0.6981\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7212 - accuracy: 0.7054\n",
            "Epoch 28: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7212 - accuracy: 0.7054 - val_loss: 1.7445 - val_accuracy: 0.6792\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7130 - accuracy: 0.7303\n",
            "Epoch 29: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 8s 908ms/step - loss: 1.7130 - accuracy: 0.7303 - val_loss: 1.7443 - val_accuracy: 0.6981\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7066 - accuracy: 0.7510\n",
            "Epoch 30: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7066 - accuracy: 0.7510 - val_loss: 1.7427 - val_accuracy: 0.6604\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7008 - accuracy: 0.7365\n",
            "Epoch 31: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 8s 887ms/step - loss: 1.7008 - accuracy: 0.7365 - val_loss: 1.7630 - val_accuracy: 0.6604\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6963 - accuracy: 0.7822\n",
            "Epoch 32: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6963 - accuracy: 0.7822 - val_loss: 1.7758 - val_accuracy: 0.6415\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6946 - accuracy: 0.7780\n",
            "Epoch 33: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 8s 900ms/step - loss: 1.6946 - accuracy: 0.7780 - val_loss: 1.7606 - val_accuracy: 0.6415\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6864 - accuracy: 0.7780\n",
            "Epoch 34: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6864 - accuracy: 0.7780 - val_loss: 1.7407 - val_accuracy: 0.6792\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6808 - accuracy: 0.7946\n",
            "Epoch 35: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 8s 907ms/step - loss: 1.6808 - accuracy: 0.7946 - val_loss: 1.7742 - val_accuracy: 0.6226\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6809 - accuracy: 0.7780\n",
            "Epoch 36: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6809 - accuracy: 0.7780 - val_loss: 1.7585 - val_accuracy: 0.6604\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6738 - accuracy: 0.8133\n",
            "Epoch 37: val_accuracy did not improve from 0.69811\n",
            "8/8 [==============================] - 8s 918ms/step - loss: 1.6738 - accuracy: 0.8133 - val_loss: 1.7410 - val_accuracy: 0.6792\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6725 - accuracy: 0.8029\n",
            "Epoch 38: val_accuracy improved from 0.69811 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6725 - accuracy: 0.8029 - val_loss: 1.7220 - val_accuracy: 0.7170\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6656 - accuracy: 0.8133\n",
            "Epoch 39: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 1.6656 - accuracy: 0.8133 - val_loss: 1.7177 - val_accuracy: 0.7170\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6651 - accuracy: 0.8133\n",
            "Epoch 40: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6651 - accuracy: 0.8133 - val_loss: 1.7222 - val_accuracy: 0.6604\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6594 - accuracy: 0.8299\n",
            "Epoch 41: val_accuracy improved from 0.71698 to 0.73585, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 8s 972ms/step - loss: 1.6594 - accuracy: 0.8299 - val_loss: 1.7075 - val_accuracy: 0.7358\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6593 - accuracy: 0.8216\n",
            "Epoch 42: val_accuracy improved from 0.73585 to 0.77358, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6593 - accuracy: 0.8216 - val_loss: 1.6990 - val_accuracy: 0.7736\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6533 - accuracy: 0.8465\n",
            "Epoch 43: val_accuracy improved from 0.77358 to 0.81132, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 8s 947ms/step - loss: 1.6533 - accuracy: 0.8465 - val_loss: 1.7115 - val_accuracy: 0.8113\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6516 - accuracy: 0.8423\n",
            "Epoch 44: val_accuracy improved from 0.81132 to 0.84906, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6516 - accuracy: 0.8423 - val_loss: 1.6806 - val_accuracy: 0.8491\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6446 - accuracy: 0.8465\n",
            "Epoch 45: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 1.6446 - accuracy: 0.8465 - val_loss: 1.7209 - val_accuracy: 0.7736\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6442 - accuracy: 0.8651\n",
            "Epoch 46: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6442 - accuracy: 0.8651 - val_loss: 1.6956 - val_accuracy: 0.7925\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6359 - accuracy: 0.8589\n",
            "Epoch 47: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.6359 - accuracy: 0.8589 - val_loss: 1.6699 - val_accuracy: 0.8302\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6356 - accuracy: 0.8942\n",
            "Epoch 48: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6356 - accuracy: 0.8942 - val_loss: 1.6879 - val_accuracy: 0.7925\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6357 - accuracy: 0.8714\n",
            "Epoch 49: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.6357 - accuracy: 0.8714 - val_loss: 1.6764 - val_accuracy: 0.7925\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6281 - accuracy: 0.8942\n",
            "Epoch 50: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6281 - accuracy: 0.8942 - val_loss: 1.6714 - val_accuracy: 0.8113\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6283 - accuracy: 0.8963\n",
            "Epoch 51: val_accuracy improved from 0.84906 to 0.86792, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.6283 - accuracy: 0.8963 - val_loss: 1.6461 - val_accuracy: 0.8679\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.9149\n",
            "Epoch 52: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6252 - accuracy: 0.9149 - val_loss: 1.6351 - val_accuracy: 0.8679\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6261 - accuracy: 0.8963\n",
            "Epoch 53: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 915ms/step - loss: 1.6261 - accuracy: 0.8963 - val_loss: 1.6446 - val_accuracy: 0.8113\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6175 - accuracy: 0.9295\n",
            "Epoch 54: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6175 - accuracy: 0.9295 - val_loss: 1.6429 - val_accuracy: 0.8302\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6249 - accuracy: 0.8900\n",
            "Epoch 55: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.6249 - accuracy: 0.8900 - val_loss: 1.6300 - val_accuracy: 0.8679\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6241 - accuracy: 0.8880\n",
            "Epoch 56: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6241 - accuracy: 0.8880 - val_loss: 1.6413 - val_accuracy: 0.8679\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6185 - accuracy: 0.9129\n",
            "Epoch 57: val_accuracy improved from 0.86792 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 7s 927ms/step - loss: 1.6185 - accuracy: 0.9129 - val_loss: 1.6369 - val_accuracy: 0.8868\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6183 - accuracy: 0.8983\n",
            "Epoch 58: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6183 - accuracy: 0.8983 - val_loss: 1.6330 - val_accuracy: 0.8113\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6132 - accuracy: 0.9108\n",
            "Epoch 59: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.6132 - accuracy: 0.9108 - val_loss: 1.6121 - val_accuracy: 0.8868\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6151 - accuracy: 0.8983\n",
            "Epoch 60: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6151 - accuracy: 0.8983 - val_loss: 1.6228 - val_accuracy: 0.8491\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6100 - accuracy: 0.9378\n",
            "Epoch 61: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.6100 - accuracy: 0.9378 - val_loss: 1.6260 - val_accuracy: 0.8868\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6064 - accuracy: 0.9191\n",
            "Epoch 62: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6064 - accuracy: 0.9191 - val_loss: 1.6245 - val_accuracy: 0.8679\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6097 - accuracy: 0.9232\n",
            "Epoch 63: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.6097 - accuracy: 0.9232 - val_loss: 1.6343 - val_accuracy: 0.8679\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6044 - accuracy: 0.9398\n",
            "Epoch 64: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6044 - accuracy: 0.9398 - val_loss: 1.6333 - val_accuracy: 0.8679\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.9398\n",
            "Epoch 65: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.5990 - accuracy: 0.9398 - val_loss: 1.6421 - val_accuracy: 0.8679\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6030 - accuracy: 0.9295\n",
            "Epoch 66: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6030 - accuracy: 0.9295 - val_loss: 1.6342 - val_accuracy: 0.7736\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6026 - accuracy: 0.9295\n",
            "Epoch 67: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.6026 - accuracy: 0.9295 - val_loss: 1.6172 - val_accuracy: 0.8491\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6001 - accuracy: 0.9419\n",
            "Epoch 68: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6001 - accuracy: 0.9419 - val_loss: 1.6227 - val_accuracy: 0.8868\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5950 - accuracy: 0.9419\n",
            "Epoch 69: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 1.5950 - accuracy: 0.9419 - val_loss: 1.6182 - val_accuracy: 0.8679\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5951 - accuracy: 0.9398\n",
            "Epoch 70: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5951 - accuracy: 0.9398 - val_loss: 1.6243 - val_accuracy: 0.8868\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5968 - accuracy: 0.9523\n",
            "Epoch 71: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.5968 - accuracy: 0.9523 - val_loss: 1.6184 - val_accuracy: 0.8868\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5979 - accuracy: 0.9378\n",
            "Epoch 72: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5979 - accuracy: 0.9378 - val_loss: 1.6305 - val_accuracy: 0.8302\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5852 - accuracy: 0.9606\n",
            "Epoch 73: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 1.5852 - accuracy: 0.9606 - val_loss: 1.6119 - val_accuracy: 0.8868\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5974 - accuracy: 0.9398\n",
            "Epoch 74: val_accuracy improved from 0.88679 to 0.90566, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5974 - accuracy: 0.9398 - val_loss: 1.6205 - val_accuracy: 0.9057\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5939 - accuracy: 0.9440\n",
            "Epoch 75: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 1.5939 - accuracy: 0.9440 - val_loss: 1.6325 - val_accuracy: 0.8491\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 0.9585\n",
            "Epoch 76: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5875 - accuracy: 0.9585 - val_loss: 1.6297 - val_accuracy: 0.8679\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5827 - accuracy: 0.9647\n",
            "Epoch 77: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.5827 - accuracy: 0.9647 - val_loss: 1.6357 - val_accuracy: 0.8491\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5859 - accuracy: 0.9627\n",
            "Epoch 78: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5859 - accuracy: 0.9627 - val_loss: 1.6267 - val_accuracy: 0.8868\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5842 - accuracy: 0.9710\n",
            "Epoch 79: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.5842 - accuracy: 0.9710 - val_loss: 1.6135 - val_accuracy: 0.8679\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5842 - accuracy: 0.9585\n",
            "Epoch 80: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5842 - accuracy: 0.9585 - val_loss: 1.6300 - val_accuracy: 0.8302\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5837 - accuracy: 0.9585\n",
            "Epoch 81: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 1.5837 - accuracy: 0.9585 - val_loss: 1.6321 - val_accuracy: 0.8302\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5821 - accuracy: 0.9544\n",
            "Epoch 82: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5821 - accuracy: 0.9544 - val_loss: 1.6291 - val_accuracy: 0.8302\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5766 - accuracy: 0.9730\n",
            "Epoch 83: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 1.5766 - accuracy: 0.9730 - val_loss: 1.6328 - val_accuracy: 0.8491\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5827 - accuracy: 0.9523\n",
            "Epoch 84: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5827 - accuracy: 0.9523 - val_loss: 1.6317 - val_accuracy: 0.8491\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5814 - accuracy: 0.9606\n",
            "Epoch 85: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.5814 - accuracy: 0.9606 - val_loss: 1.6445 - val_accuracy: 0.7925\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5749 - accuracy: 0.9772\n",
            "Epoch 86: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5749 - accuracy: 0.9772 - val_loss: 1.6361 - val_accuracy: 0.8868\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5741 - accuracy: 0.9710\n",
            "Epoch 87: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 929ms/step - loss: 1.5741 - accuracy: 0.9710 - val_loss: 1.6358 - val_accuracy: 0.8868\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5744 - accuracy: 0.9751\n",
            "Epoch 88: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5744 - accuracy: 0.9751 - val_loss: 1.6444 - val_accuracy: 0.8491\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5716 - accuracy: 0.9813\n",
            "Epoch 89: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.5716 - accuracy: 0.9813 - val_loss: 1.6328 - val_accuracy: 0.9057\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5715 - accuracy: 0.9772\n",
            "Epoch 90: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5715 - accuracy: 0.9772 - val_loss: 1.6308 - val_accuracy: 0.8491\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5716 - accuracy: 0.9834\n",
            "Epoch 91: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.5716 - accuracy: 0.9834 - val_loss: 1.6329 - val_accuracy: 0.8302\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5721 - accuracy: 0.9834\n",
            "Epoch 92: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5721 - accuracy: 0.9834 - val_loss: 1.6408 - val_accuracy: 0.7925\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5713 - accuracy: 0.9793\n",
            "Epoch 93: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 1.5713 - accuracy: 0.9793 - val_loss: 1.6548 - val_accuracy: 0.7736\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5674 - accuracy: 0.9834\n",
            "Epoch 94: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5674 - accuracy: 0.9834 - val_loss: 1.6537 - val_accuracy: 0.7736\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5644 - accuracy: 0.9855\n",
            "Epoch 95: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 1.5644 - accuracy: 0.9855 - val_loss: 1.6358 - val_accuracy: 0.7736\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5668 - accuracy: 0.9876\n",
            "Epoch 96: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5668 - accuracy: 0.9876 - val_loss: 1.6317 - val_accuracy: 0.7736\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5684 - accuracy: 0.9772\n",
            "Epoch 97: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.5684 - accuracy: 0.9772 - val_loss: 1.6576 - val_accuracy: 0.7736\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5616 - accuracy: 0.9813\n",
            "Epoch 98: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5616 - accuracy: 0.9813 - val_loss: 1.6442 - val_accuracy: 0.7736\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5676 - accuracy: 0.9855\n",
            "Epoch 99: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 871ms/step - loss: 1.5676 - accuracy: 0.9855 - val_loss: 1.6309 - val_accuracy: 0.8113\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5635 - accuracy: 0.9876\n",
            "Epoch 100: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5635 - accuracy: 0.9876 - val_loss: 1.6298 - val_accuracy: 0.7925\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5635 - accuracy: 0.9855\n",
            "Epoch 101: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 954ms/step - loss: 1.5635 - accuracy: 0.9855 - val_loss: 1.6348 - val_accuracy: 0.7925\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5608 - accuracy: 0.9896\n",
            "Epoch 102: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5608 - accuracy: 0.9896 - val_loss: 1.6301 - val_accuracy: 0.8302\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5624 - accuracy: 0.9917\n",
            "Epoch 103: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 1.5624 - accuracy: 0.9917 - val_loss: 1.6247 - val_accuracy: 0.8302\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5608 - accuracy: 0.9813\n",
            "Epoch 104: val_accuracy improved from 0.90566 to 0.92453, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5608 - accuracy: 0.9813 - val_loss: 1.6141 - val_accuracy: 0.9245\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5579 - accuracy: 0.9917\n",
            "Epoch 105: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 923ms/step - loss: 1.5579 - accuracy: 0.9917 - val_loss: 1.6283 - val_accuracy: 0.9057\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5572 - accuracy: 0.9855\n",
            "Epoch 106: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5572 - accuracy: 0.9855 - val_loss: 1.6222 - val_accuracy: 0.9057\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5611 - accuracy: 0.9917\n",
            "Epoch 107: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 877ms/step - loss: 1.5611 - accuracy: 0.9917 - val_loss: 1.6135 - val_accuracy: 0.9057\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5539 - accuracy: 1.0000\n",
            "Epoch 108: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5539 - accuracy: 1.0000 - val_loss: 1.6322 - val_accuracy: 0.8679\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5573 - accuracy: 0.9938\n",
            "Epoch 109: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 8s 946ms/step - loss: 1.5573 - accuracy: 0.9938 - val_loss: 1.6150 - val_accuracy: 0.8679\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5564 - accuracy: 0.9855\n",
            "Epoch 110: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5564 - accuracy: 0.9855 - val_loss: 1.6130 - val_accuracy: 0.9057\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5572 - accuracy: 0.9876\n",
            "Epoch 111: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 914ms/step - loss: 1.5572 - accuracy: 0.9876 - val_loss: 1.6348 - val_accuracy: 0.8491\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5575 - accuracy: 0.9896\n",
            "Epoch 112: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5575 - accuracy: 0.9896 - val_loss: 1.6235 - val_accuracy: 0.9057\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5556 - accuracy: 0.9896\n",
            "Epoch 113: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 1.5556 - accuracy: 0.9896 - val_loss: 1.6299 - val_accuracy: 0.8868\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5546 - accuracy: 0.9855\n",
            "Epoch 114: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5546 - accuracy: 0.9855 - val_loss: 1.6350 - val_accuracy: 0.8302\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5553 - accuracy: 0.9896\n",
            "Epoch 115: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 1.5553 - accuracy: 0.9896 - val_loss: 1.6225 - val_accuracy: 0.9057\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5558 - accuracy: 0.9917\n",
            "Epoch 116: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5558 - accuracy: 0.9917 - val_loss: 1.6266 - val_accuracy: 0.8868\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5529 - accuracy: 0.9917\n",
            "Epoch 117: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 1.5529 - accuracy: 0.9917 - val_loss: 1.6127 - val_accuracy: 0.8302\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5506 - accuracy: 0.9938\n",
            "Epoch 118: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5506 - accuracy: 0.9938 - val_loss: 1.6050 - val_accuracy: 0.8868\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5544 - accuracy: 0.9938\n",
            "Epoch 119: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.5544 - accuracy: 0.9938 - val_loss: 1.6190 - val_accuracy: 0.8491\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5505 - accuracy: 0.9959\n",
            "Epoch 120: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5505 - accuracy: 0.9959 - val_loss: 1.6228 - val_accuracy: 0.8302\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5508 - accuracy: 0.9979\n",
            "Epoch 121: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 1.5508 - accuracy: 0.9979 - val_loss: 1.6109 - val_accuracy: 0.8868\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5527 - accuracy: 0.9938\n",
            "Epoch 122: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5527 - accuracy: 0.9938 - val_loss: 1.6103 - val_accuracy: 0.8679\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5536 - accuracy: 0.9938\n",
            "Epoch 123: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 8s 952ms/step - loss: 1.5536 - accuracy: 0.9938 - val_loss: 1.6028 - val_accuracy: 0.9245\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5515 - accuracy: 0.9938\n",
            "Epoch 124: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5515 - accuracy: 0.9938 - val_loss: 1.6125 - val_accuracy: 0.9057\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5543 - accuracy: 0.9896\n",
            "Epoch 125: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.5543 - accuracy: 0.9896 - val_loss: 1.5934 - val_accuracy: 0.8868\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5508 - accuracy: 0.9979\n",
            "Epoch 126: val_accuracy improved from 0.92453 to 0.94340, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5508 - accuracy: 0.9979 - val_loss: 1.6021 - val_accuracy: 0.9434\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5510 - accuracy: 0.9959\n",
            "Epoch 127: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 921ms/step - loss: 1.5510 - accuracy: 0.9959 - val_loss: 1.6279 - val_accuracy: 0.8113\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5537 - accuracy: 0.9938\n",
            "Epoch 128: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5537 - accuracy: 0.9938 - val_loss: 1.6101 - val_accuracy: 0.9057\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5477 - accuracy: 1.0000\n",
            "Epoch 129: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5477 - accuracy: 1.0000 - val_loss: 1.6112 - val_accuracy: 0.8491\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5466 - accuracy: 0.9938\n",
            "Epoch 130: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5466 - accuracy: 0.9938 - val_loss: 1.6055 - val_accuracy: 0.9057\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.9979\n",
            "Epoch 131: val_accuracy improved from 0.94340 to 0.96226, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5483 - accuracy: 0.9979 - val_loss: 1.6030 - val_accuracy: 0.9623\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5461 - accuracy: 1.0000\n",
            "Epoch 132: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5461 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.8868\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5457 - accuracy: 0.9938\n",
            "Epoch 133: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5457 - accuracy: 0.9938 - val_loss: 1.6026 - val_accuracy: 0.8679\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5468 - accuracy: 0.9959\n",
            "Epoch 134: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5468 - accuracy: 0.9959 - val_loss: 1.6076 - val_accuracy: 0.8491\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5413 - accuracy: 0.9979 - val_loss: 1.5997 - val_accuracy: 0.8679\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5448 - accuracy: 1.0000\n",
            "Epoch 136: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5448 - accuracy: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.9057\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5425 - accuracy: 0.9979\n",
            "Epoch 137: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5425 - accuracy: 0.9979 - val_loss: 1.6097 - val_accuracy: 0.8868\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5460 - accuracy: 0.9979\n",
            "Epoch 138: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 947ms/step - loss: 1.5460 - accuracy: 0.9979 - val_loss: 1.5896 - val_accuracy: 0.9057\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5424 - accuracy: 1.0000\n",
            "Epoch 139: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5424 - accuracy: 1.0000 - val_loss: 1.6049 - val_accuracy: 0.9057\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5440 - accuracy: 0.9979\n",
            "Epoch 140: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 886ms/step - loss: 1.5440 - accuracy: 0.9979 - val_loss: 1.5978 - val_accuracy: 0.8868\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5414 - accuracy: 0.9979\n",
            "Epoch 141: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5414 - accuracy: 0.9979 - val_loss: 1.5968 - val_accuracy: 0.8868\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5435 - accuracy: 1.0000\n",
            "Epoch 142: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 912ms/step - loss: 1.5435 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.8491\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5439 - accuracy: 1.0000\n",
            "Epoch 143: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5439 - accuracy: 1.0000 - val_loss: 1.6065 - val_accuracy: 0.8491\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5421 - accuracy: 0.9938\n",
            "Epoch 144: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.5421 - accuracy: 0.9938 - val_loss: 1.6026 - val_accuracy: 0.8868\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5416 - accuracy: 0.9959\n",
            "Epoch 145: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5416 - accuracy: 0.9959 - val_loss: 1.6087 - val_accuracy: 0.9245\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5414 - accuracy: 1.0000\n",
            "Epoch 146: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5414 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.9057\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5395 - accuracy: 0.9979\n",
            "Epoch 147: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5395 - accuracy: 0.9979 - val_loss: 1.6047 - val_accuracy: 0.8679\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5416 - accuracy: 0.9979\n",
            "Epoch 148: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 872ms/step - loss: 1.5416 - accuracy: 0.9979 - val_loss: 1.6044 - val_accuracy: 0.9057\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5407 - accuracy: 0.9979\n",
            "Epoch 149: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5407 - accuracy: 0.9979 - val_loss: 1.6044 - val_accuracy: 0.8868\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5396 - accuracy: 1.0000\n",
            "Epoch 150: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 894ms/step - loss: 1.5396 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.8679\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5393 - accuracy: 1.0000\n",
            "Epoch 151: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5393 - accuracy: 1.0000 - val_loss: 1.6096 - val_accuracy: 0.9057\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5403 - accuracy: 1.0000\n",
            "Epoch 152: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 898ms/step - loss: 1.5403 - accuracy: 1.0000 - val_loss: 1.6033 - val_accuracy: 0.9057\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5372 - accuracy: 1.0000\n",
            "Epoch 153: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5372 - accuracy: 1.0000 - val_loss: 1.5858 - val_accuracy: 0.9057\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5420 - accuracy: 1.0000\n",
            "Epoch 154: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.5420 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.9057\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5388 - accuracy: 1.0000\n",
            "Epoch 155: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5388 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.9434\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5418 - accuracy: 1.0000\n",
            "Epoch 156: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 1.5418 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.9245\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5406 - accuracy: 1.0000\n",
            "Epoch 157: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5406 - accuracy: 1.0000 - val_loss: 1.6032 - val_accuracy: 0.9057\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5392 - accuracy: 0.9979\n",
            "Epoch 158: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 880ms/step - loss: 1.5392 - accuracy: 0.9979 - val_loss: 1.6050 - val_accuracy: 0.9245\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5378 - accuracy: 0.9979\n",
            "Epoch 159: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5378 - accuracy: 0.9979 - val_loss: 1.5873 - val_accuracy: 0.9245\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5401 - accuracy: 0.9979\n",
            "Epoch 160: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 901ms/step - loss: 1.5401 - accuracy: 0.9979 - val_loss: 1.5880 - val_accuracy: 0.9245\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5359 - accuracy: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5359 - accuracy: 1.0000 - val_loss: 1.5992 - val_accuracy: 0.9434\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5368 - accuracy: 1.0000\n",
            "Epoch 162: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 880ms/step - loss: 1.5368 - accuracy: 1.0000 - val_loss: 1.5918 - val_accuracy: 0.9245\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5384 - accuracy: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5384 - accuracy: 1.0000 - val_loss: 1.5991 - val_accuracy: 0.9245\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5350 - accuracy: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5350 - accuracy: 1.0000 - val_loss: 1.6188 - val_accuracy: 0.8868\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5364 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5364 - accuracy: 1.0000 - val_loss: 1.5975 - val_accuracy: 0.9434\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 897ms/step - loss: 1.5361 - accuracy: 1.0000 - val_loss: 1.5997 - val_accuracy: 0.8868\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5351 - accuracy: 0.9979\n",
            "Epoch 167: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5351 - accuracy: 0.9979 - val_loss: 1.6075 - val_accuracy: 0.8679\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5379 - accuracy: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 876ms/step - loss: 1.5379 - accuracy: 1.0000 - val_loss: 1.6097 - val_accuracy: 0.8868\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5363 - accuracy: 0.9979\n",
            "Epoch 169: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5363 - accuracy: 0.9979 - val_loss: 1.5870 - val_accuracy: 0.9245\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5362 - accuracy: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.5362 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.9245\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5327 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5327 - accuracy: 1.0000 - val_loss: 1.5968 - val_accuracy: 0.9434\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5347 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.5347 - accuracy: 1.0000 - val_loss: 1.5947 - val_accuracy: 0.9245\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5344 - accuracy: 1.0000 - val_loss: 1.5977 - val_accuracy: 0.9245\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5350 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 870ms/step - loss: 1.5350 - accuracy: 1.0000 - val_loss: 1.6003 - val_accuracy: 0.9057\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5340 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5340 - accuracy: 1.0000 - val_loss: 1.5977 - val_accuracy: 0.8868\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5372 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 898ms/step - loss: 1.5372 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.9057\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5359 - accuracy: 0.9979\n",
            "Epoch 177: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5359 - accuracy: 0.9979 - val_loss: 1.6018 - val_accuracy: 0.8868\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5364 - accuracy: 0.9979\n",
            "Epoch 178: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.5364 - accuracy: 0.9979 - val_loss: 1.5945 - val_accuracy: 0.9057\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5317 - accuracy: 1.0000 - val_loss: 1.5900 - val_accuracy: 0.9057\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5342 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 1.5342 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.9245\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5324 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5324 - accuracy: 1.0000 - val_loss: 1.5877 - val_accuracy: 0.9623\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5343 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 921ms/step - loss: 1.5343 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.9434\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 0.9979\n",
            "Epoch 183: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5317 - accuracy: 0.9979 - val_loss: 1.5845 - val_accuracy: 0.9434\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5323 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 1.5323 - accuracy: 1.0000 - val_loss: 1.5883 - val_accuracy: 0.9245\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5332 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.9434\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.5332 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.9057\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5327 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5327 - accuracy: 1.0000 - val_loss: 1.6054 - val_accuracy: 0.9057\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5351 - accuracy: 1.0000\n",
            "Epoch 188: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.5351 - accuracy: 1.0000 - val_loss: 1.5917 - val_accuracy: 0.9245\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5326 - accuracy: 1.0000 - val_loss: 1.5913 - val_accuracy: 0.9245\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5342 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 905ms/step - loss: 1.5342 - accuracy: 1.0000 - val_loss: 1.6016 - val_accuracy: 0.9434\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5324 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5324 - accuracy: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.9434\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 925ms/step - loss: 1.5316 - accuracy: 1.0000 - val_loss: 1.5733 - val_accuracy: 0.9245\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5334 - accuracy: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5334 - accuracy: 1.0000 - val_loss: 1.5988 - val_accuracy: 0.9057\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5330 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.5330 - accuracy: 1.0000 - val_loss: 1.5843 - val_accuracy: 0.9434\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5302 - accuracy: 1.0000 - val_loss: 1.5856 - val_accuracy: 0.9057\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5304 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.5304 - accuracy: 1.0000 - val_loss: 1.6032 - val_accuracy: 0.9057\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5308 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5308 - accuracy: 1.0000 - val_loss: 1.5936 - val_accuracy: 0.9057\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5306 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 1.5306 - accuracy: 1.0000 - val_loss: 1.5869 - val_accuracy: 0.9434\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5316 - accuracy: 1.0000 - val_loss: 1.5849 - val_accuracy: 0.9434\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.5317 - accuracy: 1.0000 - val_loss: 1.6030 - val_accuracy: 0.9434\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5302 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.9434\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.5299 - accuracy: 1.0000 - val_loss: 1.5926 - val_accuracy: 0.9057\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 1.0000\n",
            "Epoch 203: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5315 - accuracy: 1.0000 - val_loss: 1.5989 - val_accuracy: 0.9057\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5310 - accuracy: 0.9979\n",
            "Epoch 204: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 948ms/step - loss: 1.5310 - accuracy: 0.9979 - val_loss: 1.5988 - val_accuracy: 0.9057\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5303 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.9434\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5300 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.5300 - accuracy: 1.0000 - val_loss: 1.5922 - val_accuracy: 0.9245\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5290 - accuracy: 1.0000 - val_loss: 1.5841 - val_accuracy: 0.9434\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.5285 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.9434\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5280 - accuracy: 1.0000 - val_loss: 1.5787 - val_accuracy: 0.9434\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5313 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 873ms/step - loss: 1.5313 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.9245\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5301 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5301 - accuracy: 1.0000 - val_loss: 1.5932 - val_accuracy: 0.9245\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5293 - accuracy: 1.0000 - val_loss: 1.5787 - val_accuracy: 0.9434\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5288 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.9434\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 1.0000\n",
            "Epoch 214: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5302 - accuracy: 1.0000 - val_loss: 1.5864 - val_accuracy: 0.9434\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5290 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.9434\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5271 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.5271 - accuracy: 1.0000 - val_loss: 1.5876 - val_accuracy: 0.9434\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5268 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5268 - accuracy: 1.0000 - val_loss: 1.5807 - val_accuracy: 0.9434\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5287 - accuracy: 1.0000\n",
            "Epoch 218: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 905ms/step - loss: 1.5287 - accuracy: 1.0000 - val_loss: 1.5742 - val_accuracy: 0.9434\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5279 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5279 - accuracy: 1.0000 - val_loss: 1.5802 - val_accuracy: 0.9434\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.5264 - accuracy: 1.0000 - val_loss: 1.5726 - val_accuracy: 0.9434\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5277 - accuracy: 1.0000\n",
            "Epoch 221: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5277 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.9434\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.5284 - accuracy: 1.0000 - val_loss: 1.5765 - val_accuracy: 0.9245\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5259 - accuracy: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5259 - accuracy: 1.0000 - val_loss: 1.5811 - val_accuracy: 0.9434\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 905ms/step - loss: 1.5280 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.9057\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5280 - accuracy: 1.0000 - val_loss: 1.5808 - val_accuracy: 0.9623\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5296 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 938ms/step - loss: 1.5296 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.9434\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5278 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5278 - accuracy: 1.0000 - val_loss: 1.5768 - val_accuracy: 0.9434\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.5289 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.9434\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5272 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5272 - accuracy: 1.0000 - val_loss: 1.5761 - val_accuracy: 0.9434\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 955ms/step - loss: 1.5290 - accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 0.9245\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5274 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5274 - accuracy: 1.0000 - val_loss: 1.5741 - val_accuracy: 0.9434\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5262 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 953ms/step - loss: 1.5262 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.9057\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5271 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5271 - accuracy: 1.0000 - val_loss: 1.5707 - val_accuracy: 0.9434\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5263 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 981ms/step - loss: 1.5263 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.9434\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5276 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5276 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.9434\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5260 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 978ms/step - loss: 1.5260 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.9434\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5268 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5268 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.9434\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.9245\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.9434\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5269 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5269 - accuracy: 1.0000 - val_loss: 1.5811 - val_accuracy: 0.9434\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5259 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5259 - accuracy: 1.0000 - val_loss: 1.5829 - val_accuracy: 0.9434\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 971ms/step - loss: 1.5264 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.9245\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5239 - accuracy: 1.0000 - val_loss: 1.5798 - val_accuracy: 0.9245\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5271 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 986ms/step - loss: 1.5271 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.9434\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5813 - val_accuracy: 0.9434\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5257 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 965ms/step - loss: 1.5257 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.9434\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5253 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5253 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.9434\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 994ms/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.9434\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5246 - accuracy: 1.0000 - val_loss: 1.5858 - val_accuracy: 0.9057\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5232 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.9434\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5247 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5247 - accuracy: 1.0000 - val_loss: 1.5843 - val_accuracy: 0.9245\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5262 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5262 - accuracy: 1.0000 - val_loss: 1.5814 - val_accuracy: 0.9434\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5257 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5257 - accuracy: 1.0000 - val_loss: 1.5807 - val_accuracy: 0.9434\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 991ms/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5782 - val_accuracy: 0.9434\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5254 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5254 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.9434\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 978ms/step - loss: 1.5264 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.9245\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.9434\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 952ms/step - loss: 1.5233 - accuracy: 1.0000 - val_loss: 1.5784 - val_accuracy: 0.9245\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5253 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5253 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.9057\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5243 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 975ms/step - loss: 1.5243 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.9245\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5242 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5242 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.8868\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5249 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 949ms/step - loss: 1.5249 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.9057\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5262 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5262 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.9057\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 956ms/step - loss: 1.5236 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.9434\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5241 - accuracy: 0.9979\n",
            "Epoch 265: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5241 - accuracy: 0.9979 - val_loss: 1.5765 - val_accuracy: 0.9245\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5250 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 936ms/step - loss: 1.5250 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.9434\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5236 - accuracy: 1.0000 - val_loss: 1.5916 - val_accuracy: 0.8868\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5245 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.5245 - accuracy: 1.0000 - val_loss: 1.5738 - val_accuracy: 0.9245\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5246 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.9057\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5243 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.5243 - accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 0.9434\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5246 - accuracy: 1.0000 - val_loss: 1.5830 - val_accuracy: 0.9057\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5228 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 872ms/step - loss: 1.5228 - accuracy: 1.0000 - val_loss: 1.5762 - val_accuracy: 0.9245\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5236 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.8868\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.5239 - accuracy: 1.0000 - val_loss: 1.5782 - val_accuracy: 0.9434\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5238 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.9245\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.5238 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.9245\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5237 - accuracy: 1.0000 - val_loss: 1.5813 - val_accuracy: 0.9245\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5222 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.5222 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.9245\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5246 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.9057\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5249 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5249 - accuracy: 1.0000 - val_loss: 1.5827 - val_accuracy: 0.9057\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5227 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5227 - accuracy: 1.0000 - val_loss: 1.5808 - val_accuracy: 0.9245\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5234 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 869ms/step - loss: 1.5234 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.9245\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5217 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5217 - accuracy: 1.0000 - val_loss: 1.5783 - val_accuracy: 0.9245\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5217 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5217 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.9245\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5232 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.9057\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5217 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.5217 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.9057\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5231 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5231 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.9245\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 1.5239 - accuracy: 1.0000 - val_loss: 1.5773 - val_accuracy: 0.9245\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5245 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5245 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.9245\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5213 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 1.5213 - accuracy: 1.0000 - val_loss: 1.5822 - val_accuracy: 0.9057\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5219 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5219 - accuracy: 1.0000 - val_loss: 1.5858 - val_accuracy: 0.9057\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 935ms/step - loss: 1.5233 - accuracy: 1.0000 - val_loss: 1.5863 - val_accuracy: 0.9245\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5246 - accuracy: 1.0000 - val_loss: 1.5854 - val_accuracy: 0.9057\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5226 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.5226 - accuracy: 1.0000 - val_loss: 1.5883 - val_accuracy: 0.9057\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5223 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5223 - accuracy: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.9245\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5215 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 867ms/step - loss: 1.5215 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.9245\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5237 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.9245\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5240 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.5240 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.9057\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5222 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5222 - accuracy: 1.0000 - val_loss: 1.5918 - val_accuracy: 0.8679\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 1.5238 - accuracy: 1.0000 - val_loss: 1.6042 - val_accuracy: 0.8868\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.6030 - accuracy: 0.9623\n",
            "8_Model evaluation:  [1.6029727458953857, 0.9622641801834106]    Now ACC: 93.475\n",
            "2/2 [==============================] - 3s 143ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        17\n",
            "     boredom       1.00      0.75      0.86         4\n",
            "     disgust       1.00      0.75      0.86         4\n",
            "        fear       0.88      1.00      0.93         7\n",
            "       happy       1.00      1.00      1.00         4\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "         sad       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.96        53\n",
            "   macro avg       0.97      0.93      0.94        53\n",
            "weighted avg       0.97      0.96      0.96        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.1615 - accuracy: 0.1598\n",
            "Epoch 1: val_accuracy improved from -inf to 0.13208, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 39s 1s/step - loss: 3.1615 - accuracy: 0.1598 - val_loss: 2.2937 - val_accuracy: 0.1321\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0387 - accuracy: 0.1992\n",
            "Epoch 2: val_accuracy did not improve from 0.13208\n",
            "8/8 [==============================] - 10s 1s/step - loss: 2.0387 - accuracy: 0.1992 - val_loss: 2.4720 - val_accuracy: 0.0755\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9551 - accuracy: 0.1743\n",
            "Epoch 3: val_accuracy did not improve from 0.13208\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 1.9551 - accuracy: 0.1743 - val_loss: 2.5806 - val_accuracy: 0.1132\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9562 - accuracy: 0.2116\n",
            "Epoch 4: val_accuracy improved from 0.13208 to 0.26415, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.9562 - accuracy: 0.2116 - val_loss: 2.3103 - val_accuracy: 0.2642\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9023 - accuracy: 0.3548\n",
            "Epoch 5: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 1.9023 - accuracy: 0.3548 - val_loss: 2.2995 - val_accuracy: 0.2642\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8749 - accuracy: 0.4129\n",
            "Epoch 6: val_accuracy did not improve from 0.26415\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8749 - accuracy: 0.4129 - val_loss: 2.3911 - val_accuracy: 0.2642\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8635 - accuracy: 0.4440\n",
            "Epoch 7: val_accuracy improved from 0.26415 to 0.28302, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.8635 - accuracy: 0.4440 - val_loss: 2.3788 - val_accuracy: 0.2830\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8516 - accuracy: 0.4668\n",
            "Epoch 8: val_accuracy improved from 0.28302 to 0.33962, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.8516 - accuracy: 0.4668 - val_loss: 2.2999 - val_accuracy: 0.3396\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8384 - accuracy: 0.5104\n",
            "Epoch 9: val_accuracy improved from 0.33962 to 0.37736, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 926ms/step - loss: 1.8384 - accuracy: 0.5104 - val_loss: 2.2637 - val_accuracy: 0.3774\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8266 - accuracy: 0.5290\n",
            "Epoch 10: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8266 - accuracy: 0.5290 - val_loss: 2.1851 - val_accuracy: 0.3774\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8203 - accuracy: 0.5394\n",
            "Epoch 11: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 1.8203 - accuracy: 0.5394 - val_loss: 2.1337 - val_accuracy: 0.3774\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8111 - accuracy: 0.5602\n",
            "Epoch 12: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8111 - accuracy: 0.5602 - val_loss: 2.0956 - val_accuracy: 0.3585\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8027 - accuracy: 0.6058\n",
            "Epoch 13: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 1.8027 - accuracy: 0.6058 - val_loss: 2.0565 - val_accuracy: 0.3774\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7956 - accuracy: 0.5851\n",
            "Epoch 14: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7956 - accuracy: 0.5851 - val_loss: 2.0549 - val_accuracy: 0.3774\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7858 - accuracy: 0.6535\n",
            "Epoch 15: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 7s 868ms/step - loss: 1.7858 - accuracy: 0.6535 - val_loss: 2.0248 - val_accuracy: 0.3774\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7876 - accuracy: 0.6245\n",
            "Epoch 16: val_accuracy improved from 0.37736 to 0.39623, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7876 - accuracy: 0.6245 - val_loss: 1.9492 - val_accuracy: 0.3962\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7743 - accuracy: 0.6846\n",
            "Epoch 17: val_accuracy improved from 0.39623 to 0.41509, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 915ms/step - loss: 1.7743 - accuracy: 0.6846 - val_loss: 1.9114 - val_accuracy: 0.4151\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7684 - accuracy: 0.6805\n",
            "Epoch 18: val_accuracy did not improve from 0.41509\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7684 - accuracy: 0.6805 - val_loss: 1.8949 - val_accuracy: 0.4151\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7624 - accuracy: 0.6763\n",
            "Epoch 19: val_accuracy improved from 0.41509 to 0.49057, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 1.7624 - accuracy: 0.6763 - val_loss: 1.8681 - val_accuracy: 0.4906\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7568 - accuracy: 0.7033\n",
            "Epoch 20: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7568 - accuracy: 0.7033 - val_loss: 1.8483 - val_accuracy: 0.4717\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7537 - accuracy: 0.7220\n",
            "Epoch 21: val_accuracy improved from 0.49057 to 0.50943, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 1.7537 - accuracy: 0.7220 - val_loss: 1.8324 - val_accuracy: 0.5094\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7472 - accuracy: 0.7427\n",
            "Epoch 22: val_accuracy did not improve from 0.50943\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7472 - accuracy: 0.7427 - val_loss: 1.8242 - val_accuracy: 0.5094\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7438 - accuracy: 0.7241\n",
            "Epoch 23: val_accuracy improved from 0.50943 to 0.56604, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.7438 - accuracy: 0.7241 - val_loss: 1.8139 - val_accuracy: 0.5660\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7423 - accuracy: 0.7573\n",
            "Epoch 24: val_accuracy did not improve from 0.56604\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7423 - accuracy: 0.7573 - val_loss: 1.8023 - val_accuracy: 0.5660\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7369 - accuracy: 0.7656\n",
            "Epoch 25: val_accuracy did not improve from 0.56604\n",
            "8/8 [==============================] - 7s 928ms/step - loss: 1.7369 - accuracy: 0.7656 - val_loss: 1.8012 - val_accuracy: 0.5660\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7277 - accuracy: 0.7739\n",
            "Epoch 26: val_accuracy improved from 0.56604 to 0.60377, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7277 - accuracy: 0.7739 - val_loss: 1.7897 - val_accuracy: 0.6038\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7248 - accuracy: 0.7884\n",
            "Epoch 27: val_accuracy improved from 0.60377 to 0.62264, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 915ms/step - loss: 1.7248 - accuracy: 0.7884 - val_loss: 1.7850 - val_accuracy: 0.6226\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7225 - accuracy: 0.7905\n",
            "Epoch 28: val_accuracy improved from 0.62264 to 0.66038, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7225 - accuracy: 0.7905 - val_loss: 1.7706 - val_accuracy: 0.6604\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7251 - accuracy: 0.7884\n",
            "Epoch 29: val_accuracy improved from 0.66038 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 8s 941ms/step - loss: 1.7251 - accuracy: 0.7884 - val_loss: 1.7566 - val_accuracy: 0.7170\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7133 - accuracy: 0.8237\n",
            "Epoch 30: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7133 - accuracy: 0.8237 - val_loss: 1.7543 - val_accuracy: 0.6981\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7193 - accuracy: 0.7884\n",
            "Epoch 31: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.7193 - accuracy: 0.7884 - val_loss: 1.7664 - val_accuracy: 0.7170\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7145 - accuracy: 0.8154\n",
            "Epoch 32: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7145 - accuracy: 0.8154 - val_loss: 1.7753 - val_accuracy: 0.6415\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7078 - accuracy: 0.8257\n",
            "Epoch 33: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 1.7078 - accuracy: 0.8257 - val_loss: 1.7396 - val_accuracy: 0.6981\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6989 - accuracy: 0.8402\n",
            "Epoch 34: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6989 - accuracy: 0.8402 - val_loss: 1.7335 - val_accuracy: 0.7170\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7004 - accuracy: 0.8506\n",
            "Epoch 35: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.7004 - accuracy: 0.8506 - val_loss: 1.7429 - val_accuracy: 0.7170\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7033 - accuracy: 0.8237\n",
            "Epoch 36: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7033 - accuracy: 0.8237 - val_loss: 1.7469 - val_accuracy: 0.6981\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6940 - accuracy: 0.8631\n",
            "Epoch 37: val_accuracy improved from 0.71698 to 0.73585, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 8s 941ms/step - loss: 1.6940 - accuracy: 0.8631 - val_loss: 1.7424 - val_accuracy: 0.7358\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6945 - accuracy: 0.8548\n",
            "Epoch 38: val_accuracy did not improve from 0.73585\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6945 - accuracy: 0.8548 - val_loss: 1.7312 - val_accuracy: 0.7170\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6939 - accuracy: 0.8589\n",
            "Epoch 39: val_accuracy improved from 0.73585 to 0.75472, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 936ms/step - loss: 1.6939 - accuracy: 0.8589 - val_loss: 1.7483 - val_accuracy: 0.7547\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6917 - accuracy: 0.8589\n",
            "Epoch 40: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6917 - accuracy: 0.8589 - val_loss: 1.7664 - val_accuracy: 0.6981\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6859 - accuracy: 0.8734\n",
            "Epoch 41: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.6859 - accuracy: 0.8734 - val_loss: 1.7651 - val_accuracy: 0.7170\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6858 - accuracy: 0.8734\n",
            "Epoch 42: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6858 - accuracy: 0.8734 - val_loss: 1.7421 - val_accuracy: 0.7170\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6861 - accuracy: 0.8734\n",
            "Epoch 43: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 7s 864ms/step - loss: 1.6861 - accuracy: 0.8734 - val_loss: 1.7554 - val_accuracy: 0.7358\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6796 - accuracy: 0.8880\n",
            "Epoch 44: val_accuracy improved from 0.75472 to 0.77358, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6796 - accuracy: 0.8880 - val_loss: 1.7242 - val_accuracy: 0.7736\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6798 - accuracy: 0.8797\n",
            "Epoch 45: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 1.6798 - accuracy: 0.8797 - val_loss: 1.7140 - val_accuracy: 0.7547\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6758 - accuracy: 0.9170\n",
            "Epoch 46: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6758 - accuracy: 0.9170 - val_loss: 1.7183 - val_accuracy: 0.7736\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6733 - accuracy: 0.8983\n",
            "Epoch 47: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 7s 866ms/step - loss: 1.6733 - accuracy: 0.8983 - val_loss: 1.7382 - val_accuracy: 0.7358\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6772 - accuracy: 0.8942\n",
            "Epoch 48: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6772 - accuracy: 0.8942 - val_loss: 1.7574 - val_accuracy: 0.6981\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6712 - accuracy: 0.9108\n",
            "Epoch 49: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.6712 - accuracy: 0.9108 - val_loss: 1.7620 - val_accuracy: 0.7170\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6672 - accuracy: 0.9232\n",
            "Epoch 50: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6672 - accuracy: 0.9232 - val_loss: 1.7576 - val_accuracy: 0.6981\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6682 - accuracy: 0.9149\n",
            "Epoch 51: val_accuracy improved from 0.77358 to 0.81132, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 939ms/step - loss: 1.6682 - accuracy: 0.9149 - val_loss: 1.7116 - val_accuracy: 0.8113\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6625 - accuracy: 0.9232\n",
            "Epoch 52: val_accuracy improved from 0.81132 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6625 - accuracy: 0.9232 - val_loss: 1.6859 - val_accuracy: 0.8868\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6657 - accuracy: 0.9108\n",
            "Epoch 53: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 867ms/step - loss: 1.6657 - accuracy: 0.9108 - val_loss: 1.7002 - val_accuracy: 0.8679\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6638 - accuracy: 0.9191\n",
            "Epoch 54: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6638 - accuracy: 0.9191 - val_loss: 1.7015 - val_accuracy: 0.8491\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6584 - accuracy: 0.9232\n",
            "Epoch 55: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.6584 - accuracy: 0.9232 - val_loss: 1.6974 - val_accuracy: 0.7925\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6559 - accuracy: 0.9336\n",
            "Epoch 56: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6559 - accuracy: 0.9336 - val_loss: 1.6999 - val_accuracy: 0.8113\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6588 - accuracy: 0.9274\n",
            "Epoch 57: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 853ms/step - loss: 1.6588 - accuracy: 0.9274 - val_loss: 1.6983 - val_accuracy: 0.8113\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6562 - accuracy: 0.9253\n",
            "Epoch 58: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6562 - accuracy: 0.9253 - val_loss: 1.7294 - val_accuracy: 0.7736\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6496 - accuracy: 0.9440\n",
            "Epoch 59: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.6496 - accuracy: 0.9440 - val_loss: 1.6967 - val_accuracy: 0.8113\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 0.9398\n",
            "Epoch 60: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6510 - accuracy: 0.9398 - val_loss: 1.6953 - val_accuracy: 0.8868\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6573 - accuracy: 0.9149\n",
            "Epoch 61: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 863ms/step - loss: 1.6573 - accuracy: 0.9149 - val_loss: 1.7027 - val_accuracy: 0.7925\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6551 - accuracy: 0.9274\n",
            "Epoch 62: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6551 - accuracy: 0.9274 - val_loss: 1.6817 - val_accuracy: 0.8302\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6517 - accuracy: 0.9378\n",
            "Epoch 63: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.6517 - accuracy: 0.9378 - val_loss: 1.6931 - val_accuracy: 0.8491\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6469 - accuracy: 0.9481\n",
            "Epoch 64: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6469 - accuracy: 0.9481 - val_loss: 1.6844 - val_accuracy: 0.8679\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6448 - accuracy: 0.9544\n",
            "Epoch 65: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 963ms/step - loss: 1.6448 - accuracy: 0.9544 - val_loss: 1.6786 - val_accuracy: 0.8868\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6463 - accuracy: 0.9564\n",
            "Epoch 66: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6463 - accuracy: 0.9564 - val_loss: 1.6742 - val_accuracy: 0.8868\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6436 - accuracy: 0.9544\n",
            "Epoch 67: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 7s 874ms/step - loss: 1.6436 - accuracy: 0.9544 - val_loss: 1.6795 - val_accuracy: 0.8302\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6402 - accuracy: 0.9689\n",
            "Epoch 68: val_accuracy improved from 0.88679 to 0.90566, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6402 - accuracy: 0.9689 - val_loss: 1.6753 - val_accuracy: 0.9057\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6396 - accuracy: 0.9772\n",
            "Epoch 69: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 876ms/step - loss: 1.6396 - accuracy: 0.9772 - val_loss: 1.6766 - val_accuracy: 0.8868\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6435 - accuracy: 0.9398\n",
            "Epoch 70: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6435 - accuracy: 0.9398 - val_loss: 1.6730 - val_accuracy: 0.8679\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6408 - accuracy: 0.9585\n",
            "Epoch 71: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 877ms/step - loss: 1.6408 - accuracy: 0.9585 - val_loss: 1.6747 - val_accuracy: 0.8868\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6421 - accuracy: 0.9502\n",
            "Epoch 72: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6421 - accuracy: 0.9502 - val_loss: 1.6672 - val_accuracy: 0.9057\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6363 - accuracy: 0.9627\n",
            "Epoch 73: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 1.6363 - accuracy: 0.9627 - val_loss: 1.7378 - val_accuracy: 0.8302\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6358 - accuracy: 0.9647\n",
            "Epoch 74: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6358 - accuracy: 0.9647 - val_loss: 1.8077 - val_accuracy: 0.7358\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6406 - accuracy: 0.9647\n",
            "Epoch 75: val_accuracy improved from 0.90566 to 0.92453, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.6406 - accuracy: 0.9647 - val_loss: 1.6844 - val_accuracy: 0.9245\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6362 - accuracy: 0.9834\n",
            "Epoch 76: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6362 - accuracy: 0.9834 - val_loss: 1.6698 - val_accuracy: 0.8868\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6360 - accuracy: 0.9668\n",
            "Epoch 77: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 7s 874ms/step - loss: 1.6360 - accuracy: 0.9668 - val_loss: 1.6704 - val_accuracy: 0.9057\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6367 - accuracy: 0.9647\n",
            "Epoch 78: val_accuracy improved from 0.92453 to 0.94340, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6367 - accuracy: 0.9647 - val_loss: 1.6664 - val_accuracy: 0.9434\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6340 - accuracy: 0.9668\n",
            "Epoch 79: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.6340 - accuracy: 0.9668 - val_loss: 1.6634 - val_accuracy: 0.9057\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6329 - accuracy: 0.9793\n",
            "Epoch 80: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6329 - accuracy: 0.9793 - val_loss: 1.6724 - val_accuracy: 0.8868\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6330 - accuracy: 0.9689\n",
            "Epoch 81: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 1.6330 - accuracy: 0.9689 - val_loss: 1.6683 - val_accuracy: 0.9057\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6302 - accuracy: 0.9689\n",
            "Epoch 82: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6302 - accuracy: 0.9689 - val_loss: 1.6678 - val_accuracy: 0.9245\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6323 - accuracy: 0.9772\n",
            "Epoch 83: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 873ms/step - loss: 1.6323 - accuracy: 0.9772 - val_loss: 1.6696 - val_accuracy: 0.9057\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6292 - accuracy: 0.9772\n",
            "Epoch 84: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6292 - accuracy: 0.9772 - val_loss: 1.6682 - val_accuracy: 0.9245\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6314 - accuracy: 0.9730\n",
            "Epoch 85: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.6314 - accuracy: 0.9730 - val_loss: 1.6830 - val_accuracy: 0.8491\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6297 - accuracy: 0.9751\n",
            "Epoch 86: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6297 - accuracy: 0.9751 - val_loss: 1.6781 - val_accuracy: 0.8679\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6292 - accuracy: 0.9751\n",
            "Epoch 87: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 865ms/step - loss: 1.6292 - accuracy: 0.9751 - val_loss: 1.6709 - val_accuracy: 0.9057\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6239 - accuracy: 0.9834\n",
            "Epoch 88: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6239 - accuracy: 0.9834 - val_loss: 1.6633 - val_accuracy: 0.9245\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.9813\n",
            "Epoch 89: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.6252 - accuracy: 0.9813 - val_loss: 1.6716 - val_accuracy: 0.8868\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6229 - accuracy: 0.9834\n",
            "Epoch 90: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6229 - accuracy: 0.9834 - val_loss: 1.6681 - val_accuracy: 0.8679\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6242 - accuracy: 0.9813\n",
            "Epoch 91: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 874ms/step - loss: 1.6242 - accuracy: 0.9813 - val_loss: 1.6684 - val_accuracy: 0.9057\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6242 - accuracy: 0.9917\n",
            "Epoch 92: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6242 - accuracy: 0.9917 - val_loss: 1.6704 - val_accuracy: 0.8679\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6206 - accuracy: 0.9855\n",
            "Epoch 93: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.6206 - accuracy: 0.9855 - val_loss: 1.6770 - val_accuracy: 0.8868\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6272 - accuracy: 0.9772\n",
            "Epoch 94: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6272 - accuracy: 0.9772 - val_loss: 1.6810 - val_accuracy: 0.8679\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6213 - accuracy: 0.9813\n",
            "Epoch 95: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.6213 - accuracy: 0.9813 - val_loss: 1.6687 - val_accuracy: 0.9434\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6203 - accuracy: 0.9855\n",
            "Epoch 96: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6203 - accuracy: 0.9855 - val_loss: 1.6702 - val_accuracy: 0.8679\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6208 - accuracy: 0.9834\n",
            "Epoch 97: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.6208 - accuracy: 0.9834 - val_loss: 1.6784 - val_accuracy: 0.8491\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6210 - accuracy: 0.9896\n",
            "Epoch 98: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6210 - accuracy: 0.9896 - val_loss: 1.6662 - val_accuracy: 0.8679\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6200 - accuracy: 0.9855\n",
            "Epoch 99: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 1.6200 - accuracy: 0.9855 - val_loss: 1.6643 - val_accuracy: 0.9434\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6194 - accuracy: 0.9876\n",
            "Epoch 100: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6194 - accuracy: 0.9876 - val_loss: 1.6785 - val_accuracy: 0.8302\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6185 - accuracy: 0.9876\n",
            "Epoch 101: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 1.6185 - accuracy: 0.9876 - val_loss: 1.6682 - val_accuracy: 0.8868\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6168 - accuracy: 0.9896\n",
            "Epoch 102: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6168 - accuracy: 0.9896 - val_loss: 1.6697 - val_accuracy: 0.9057\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6178 - accuracy: 0.9917\n",
            "Epoch 103: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 923ms/step - loss: 1.6178 - accuracy: 0.9917 - val_loss: 1.6796 - val_accuracy: 0.8302\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6180 - accuracy: 0.9917\n",
            "Epoch 104: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6180 - accuracy: 0.9917 - val_loss: 1.6830 - val_accuracy: 0.8302\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6156 - accuracy: 0.9938\n",
            "Epoch 105: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.6156 - accuracy: 0.9938 - val_loss: 1.6650 - val_accuracy: 0.8868\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6192 - accuracy: 0.9834\n",
            "Epoch 106: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6192 - accuracy: 0.9834 - val_loss: 1.6680 - val_accuracy: 0.8868\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6175 - accuracy: 0.9917\n",
            "Epoch 107: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 1.6175 - accuracy: 0.9917 - val_loss: 1.6726 - val_accuracy: 0.8491\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6114 - accuracy: 0.9959\n",
            "Epoch 108: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6114 - accuracy: 0.9959 - val_loss: 1.6655 - val_accuracy: 0.8868\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6155 - accuracy: 0.9938\n",
            "Epoch 109: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 911ms/step - loss: 1.6155 - accuracy: 0.9938 - val_loss: 1.6719 - val_accuracy: 0.8679\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6122 - accuracy: 0.9917\n",
            "Epoch 110: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6122 - accuracy: 0.9917 - val_loss: 1.6695 - val_accuracy: 0.8679\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6133 - accuracy: 0.9959\n",
            "Epoch 111: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 1.6133 - accuracy: 0.9959 - val_loss: 1.6700 - val_accuracy: 0.8679\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6130 - accuracy: 0.9938\n",
            "Epoch 112: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6130 - accuracy: 0.9938 - val_loss: 1.6686 - val_accuracy: 0.8679\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6118 - accuracy: 0.9959\n",
            "Epoch 113: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 1.6118 - accuracy: 0.9959 - val_loss: 1.6671 - val_accuracy: 0.8679\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6125 - accuracy: 0.9938\n",
            "Epoch 114: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6125 - accuracy: 0.9938 - val_loss: 1.6762 - val_accuracy: 0.8679\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6122 - accuracy: 0.9917\n",
            "Epoch 115: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 919ms/step - loss: 1.6122 - accuracy: 0.9917 - val_loss: 1.6897 - val_accuracy: 0.8113\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6122 - accuracy: 0.9938\n",
            "Epoch 116: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6122 - accuracy: 0.9938 - val_loss: 1.6745 - val_accuracy: 0.8679\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6134 - accuracy: 0.9959\n",
            "Epoch 117: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.6134 - accuracy: 0.9959 - val_loss: 1.6707 - val_accuracy: 0.8679\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6114 - accuracy: 0.9979\n",
            "Epoch 118: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6114 - accuracy: 0.9979 - val_loss: 1.6621 - val_accuracy: 0.8868\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6110 - accuracy: 0.9938\n",
            "Epoch 119: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 911ms/step - loss: 1.6110 - accuracy: 0.9938 - val_loss: 1.6640 - val_accuracy: 0.8679\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6122 - accuracy: 0.9959\n",
            "Epoch 120: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6122 - accuracy: 0.9959 - val_loss: 1.6702 - val_accuracy: 0.8868\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6092 - accuracy: 0.9979\n",
            "Epoch 121: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 947ms/step - loss: 1.6092 - accuracy: 0.9979 - val_loss: 1.6586 - val_accuracy: 0.9057\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6077 - accuracy: 0.9938\n",
            "Epoch 122: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6077 - accuracy: 0.9938 - val_loss: 1.6628 - val_accuracy: 0.8868\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6094 - accuracy: 0.9979\n",
            "Epoch 123: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 989ms/step - loss: 1.6094 - accuracy: 0.9979 - val_loss: 1.6643 - val_accuracy: 0.9057\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6077 - accuracy: 0.9979\n",
            "Epoch 124: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6077 - accuracy: 0.9979 - val_loss: 1.6609 - val_accuracy: 0.9057\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6074 - accuracy: 0.9979\n",
            "Epoch 125: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 960ms/step - loss: 1.6074 - accuracy: 0.9979 - val_loss: 1.6722 - val_accuracy: 0.8491\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6051 - accuracy: 0.9959\n",
            "Epoch 126: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6051 - accuracy: 0.9959 - val_loss: 1.6745 - val_accuracy: 0.8868\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6086 - accuracy: 1.0000\n",
            "Epoch 127: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 975ms/step - loss: 1.6086 - accuracy: 1.0000 - val_loss: 1.6763 - val_accuracy: 0.8302\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6067 - accuracy: 1.0000\n",
            "Epoch 128: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6067 - accuracy: 1.0000 - val_loss: 1.6735 - val_accuracy: 0.8679\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6064 - accuracy: 0.9959\n",
            "Epoch 129: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 972ms/step - loss: 1.6064 - accuracy: 0.9959 - val_loss: 1.6755 - val_accuracy: 0.8302\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6059 - accuracy: 0.9979\n",
            "Epoch 130: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6059 - accuracy: 0.9979 - val_loss: 1.6673 - val_accuracy: 0.8679\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6066 - accuracy: 1.0000\n",
            "Epoch 131: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6066 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.8868\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6077 - accuracy: 0.9938\n",
            "Epoch 132: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6077 - accuracy: 0.9938 - val_loss: 1.6702 - val_accuracy: 0.9057\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6081 - accuracy: 0.9979\n",
            "Epoch 133: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6081 - accuracy: 0.9979 - val_loss: 1.6696 - val_accuracy: 0.8679\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6059 - accuracy: 0.9979\n",
            "Epoch 134: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6059 - accuracy: 0.9979 - val_loss: 1.6731 - val_accuracy: 0.8491\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6042 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6042 - accuracy: 0.9979 - val_loss: 1.6699 - val_accuracy: 0.9057\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6054 - accuracy: 0.9979\n",
            "Epoch 136: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6054 - accuracy: 0.9979 - val_loss: 1.6714 - val_accuracy: 0.8679\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6034 - accuracy: 1.0000\n",
            "Epoch 137: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6034 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.8679\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6045 - accuracy: 1.0000\n",
            "Epoch 138: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6045 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.8868\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6042 - accuracy: 0.9959\n",
            "Epoch 139: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6042 - accuracy: 0.9959 - val_loss: 1.6645 - val_accuracy: 0.9057\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6036 - accuracy: 0.9979\n",
            "Epoch 140: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 968ms/step - loss: 1.6036 - accuracy: 0.9979 - val_loss: 1.6687 - val_accuracy: 0.8679\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6049 - accuracy: 0.9917\n",
            "Epoch 141: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6049 - accuracy: 0.9917 - val_loss: 1.6719 - val_accuracy: 0.8679\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6022 - accuracy: 1.0000\n",
            "Epoch 142: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 955ms/step - loss: 1.6022 - accuracy: 1.0000 - val_loss: 1.6703 - val_accuracy: 0.8679\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6009 - accuracy: 0.9979\n",
            "Epoch 143: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6009 - accuracy: 0.9979 - val_loss: 1.6753 - val_accuracy: 0.8868\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6016 - accuracy: 0.9979\n",
            "Epoch 144: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 958ms/step - loss: 1.6016 - accuracy: 0.9979 - val_loss: 1.6664 - val_accuracy: 0.9057\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6047 - accuracy: 1.0000\n",
            "Epoch 145: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6047 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.8679\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6027 - accuracy: 0.9979\n",
            "Epoch 146: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 920ms/step - loss: 1.6027 - accuracy: 0.9979 - val_loss: 1.6837 - val_accuracy: 0.8113\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6030 - accuracy: 1.0000\n",
            "Epoch 147: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6030 - accuracy: 1.0000 - val_loss: 1.6770 - val_accuracy: 0.8491\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6008 - accuracy: 0.9979\n",
            "Epoch 148: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 913ms/step - loss: 1.6008 - accuracy: 0.9979 - val_loss: 1.6807 - val_accuracy: 0.8491\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6026 - accuracy: 0.9979\n",
            "Epoch 149: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6026 - accuracy: 0.9979 - val_loss: 1.6745 - val_accuracy: 0.8491\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6028 - accuracy: 0.9938\n",
            "Epoch 150: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 912ms/step - loss: 1.6028 - accuracy: 0.9938 - val_loss: 1.6691 - val_accuracy: 0.8679\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.9979\n",
            "Epoch 151: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6037 - accuracy: 0.9979 - val_loss: 1.6808 - val_accuracy: 0.8491\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6012 - accuracy: 1.0000\n",
            "Epoch 152: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 1.6012 - accuracy: 1.0000 - val_loss: 1.6654 - val_accuracy: 0.9057\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6007 - accuracy: 1.0000\n",
            "Epoch 153: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6007 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.8679\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6022 - accuracy: 0.9959\n",
            "Epoch 154: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.6022 - accuracy: 0.9959 - val_loss: 1.6710 - val_accuracy: 0.8679\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6017 - accuracy: 1.0000\n",
            "Epoch 155: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6017 - accuracy: 1.0000 - val_loss: 1.6700 - val_accuracy: 0.8679\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5995 - accuracy: 0.9979\n",
            "Epoch 156: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.5995 - accuracy: 0.9979 - val_loss: 1.6737 - val_accuracy: 0.8679\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5996 - accuracy: 0.9979\n",
            "Epoch 157: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5996 - accuracy: 0.9979 - val_loss: 1.6711 - val_accuracy: 0.8679\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6010 - accuracy: 0.9979\n",
            "Epoch 158: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.6010 - accuracy: 0.9979 - val_loss: 1.6672 - val_accuracy: 0.8679\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5991 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5991 - accuracy: 1.0000 - val_loss: 1.6733 - val_accuracy: 0.8491\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5981 - accuracy: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 1.5981 - accuracy: 1.0000 - val_loss: 1.6708 - val_accuracy: 0.8491\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.9979\n",
            "Epoch 161: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5990 - accuracy: 0.9979 - val_loss: 1.6635 - val_accuracy: 0.8679\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5981 - accuracy: 0.9979\n",
            "Epoch 162: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.5981 - accuracy: 0.9979 - val_loss: 1.6692 - val_accuracy: 0.8491\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5978 - accuracy: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5978 - accuracy: 1.0000 - val_loss: 1.6667 - val_accuracy: 0.8868\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5989 - accuracy: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.5989 - accuracy: 1.0000 - val_loss: 1.6701 - val_accuracy: 0.8491\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5974 - accuracy: 0.9979\n",
            "Epoch 165: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5974 - accuracy: 0.9979 - val_loss: 1.6730 - val_accuracy: 0.8491\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5986 - accuracy: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.5986 - accuracy: 1.0000 - val_loss: 1.6704 - val_accuracy: 0.8302\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5986 - accuracy: 0.9979\n",
            "Epoch 167: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5986 - accuracy: 0.9979 - val_loss: 1.6693 - val_accuracy: 0.8868\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5987 - accuracy: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 1.5987 - accuracy: 1.0000 - val_loss: 1.6756 - val_accuracy: 0.8302\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5975 - accuracy: 0.9959\n",
            "Epoch 169: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5975 - accuracy: 0.9959 - val_loss: 1.6772 - val_accuracy: 0.8491\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5987 - accuracy: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 875ms/step - loss: 1.5987 - accuracy: 1.0000 - val_loss: 1.6697 - val_accuracy: 0.8679\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5988 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5988 - accuracy: 1.0000 - val_loss: 1.6739 - val_accuracy: 0.8679\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5984 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 1.5984 - accuracy: 1.0000 - val_loss: 1.6688 - val_accuracy: 0.8679\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5982 - accuracy: 0.9938\n",
            "Epoch 173: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5982 - accuracy: 0.9938 - val_loss: 1.6679 - val_accuracy: 0.8679\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5960 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 914ms/step - loss: 1.5960 - accuracy: 1.0000 - val_loss: 1.6710 - val_accuracy: 0.8491\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5987 - accuracy: 0.9979\n",
            "Epoch 175: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5987 - accuracy: 0.9979 - val_loss: 1.6683 - val_accuracy: 0.8679\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5986 - accuracy: 0.9959\n",
            "Epoch 176: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5986 - accuracy: 0.9959 - val_loss: 1.6653 - val_accuracy: 0.8868\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5980 - accuracy: 0.9979\n",
            "Epoch 177: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5980 - accuracy: 0.9979 - val_loss: 1.6704 - val_accuracy: 0.8679\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5971 - accuracy: 0.9979\n",
            "Epoch 178: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.5971 - accuracy: 0.9979 - val_loss: 1.6774 - val_accuracy: 0.8491\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5955 - accuracy: 0.9979\n",
            "Epoch 179: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5955 - accuracy: 0.9979 - val_loss: 1.6704 - val_accuracy: 0.8302\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5978 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 916ms/step - loss: 1.5978 - accuracy: 1.0000 - val_loss: 1.6628 - val_accuracy: 0.8679\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5964 - accuracy: 1.0000 - val_loss: 1.6713 - val_accuracy: 0.8679\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5970 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.5970 - accuracy: 1.0000 - val_loss: 1.6773 - val_accuracy: 0.8302\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5963 - accuracy: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5963 - accuracy: 1.0000 - val_loss: 1.6699 - val_accuracy: 0.8491\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5965 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 1.5965 - accuracy: 1.0000 - val_loss: 1.6680 - val_accuracy: 0.8491\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5954 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5954 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.8491\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5941 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.5941 - accuracy: 1.0000 - val_loss: 1.6811 - val_accuracy: 0.8679\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5978 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5978 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.9057\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5979 - accuracy: 0.9979\n",
            "Epoch 188: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 915ms/step - loss: 1.5979 - accuracy: 0.9979 - val_loss: 1.6638 - val_accuracy: 0.8868\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5946 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5946 - accuracy: 1.0000 - val_loss: 1.6649 - val_accuracy: 0.8868\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5936 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.5936 - accuracy: 1.0000 - val_loss: 1.6658 - val_accuracy: 0.8868\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5947 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5947 - accuracy: 1.0000 - val_loss: 1.6645 - val_accuracy: 0.8868\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.5966 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.8679\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5933 - accuracy: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5933 - accuracy: 1.0000 - val_loss: 1.6691 - val_accuracy: 0.8302\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5954 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 1.5954 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.8868\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5944 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5944 - accuracy: 1.0000 - val_loss: 1.6729 - val_accuracy: 0.8679\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5952 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5952 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.8491\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5934 - accuracy: 0.9979\n",
            "Epoch 197: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5934 - accuracy: 0.9979 - val_loss: 1.6708 - val_accuracy: 0.8302\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5940 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.5940 - accuracy: 1.0000 - val_loss: 1.6664 - val_accuracy: 0.8491\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5942 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5942 - accuracy: 1.0000 - val_loss: 1.6718 - val_accuracy: 0.8679\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5944 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 880ms/step - loss: 1.5944 - accuracy: 1.0000 - val_loss: 1.6749 - val_accuracy: 0.8679\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5934 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5934 - accuracy: 1.0000 - val_loss: 1.6689 - val_accuracy: 0.8491\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5937 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.5937 - accuracy: 1.0000 - val_loss: 1.6712 - val_accuracy: 0.8491\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5945 - accuracy: 0.9979\n",
            "Epoch 203: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5945 - accuracy: 0.9979 - val_loss: 1.6759 - val_accuracy: 0.8113\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5944 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 1.5944 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.8868\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 0.9979\n",
            "Epoch 205: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5966 - accuracy: 0.9979 - val_loss: 1.6699 - val_accuracy: 0.8679\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5946 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.5946 - accuracy: 1.0000 - val_loss: 1.6750 - val_accuracy: 0.8113\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5946 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5946 - accuracy: 1.0000 - val_loss: 1.6729 - val_accuracy: 0.8113\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5935 - accuracy: 0.9979\n",
            "Epoch 208: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 917ms/step - loss: 1.5935 - accuracy: 0.9979 - val_loss: 1.6795 - val_accuracy: 0.7925\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5942 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5942 - accuracy: 1.0000 - val_loss: 1.6691 - val_accuracy: 0.8491\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5929 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 943ms/step - loss: 1.5929 - accuracy: 1.0000 - val_loss: 1.6628 - val_accuracy: 0.8679\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5951 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5951 - accuracy: 1.0000 - val_loss: 1.6742 - val_accuracy: 0.8113\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5922 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 953ms/step - loss: 1.5922 - accuracy: 1.0000 - val_loss: 1.6690 - val_accuracy: 0.8679\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5947 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5947 - accuracy: 1.0000 - val_loss: 1.6728 - val_accuracy: 0.8491\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5933 - accuracy: 1.0000\n",
            "Epoch 214: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 989ms/step - loss: 1.5933 - accuracy: 1.0000 - val_loss: 1.6588 - val_accuracy: 0.8679\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5922 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5922 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.8679\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5945 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 980ms/step - loss: 1.5945 - accuracy: 1.0000 - val_loss: 1.6686 - val_accuracy: 0.8679\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5927 - accuracy: 1.0000 - val_loss: 1.6720 - val_accuracy: 0.8491\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5926 - accuracy: 1.0000\n",
            "Epoch 218: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5926 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.8491\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5914 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5914 - accuracy: 1.0000 - val_loss: 1.6687 - val_accuracy: 0.8491\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5909 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 993ms/step - loss: 1.5909 - accuracy: 1.0000 - val_loss: 1.6691 - val_accuracy: 0.8491\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5916 - accuracy: 1.0000\n",
            "Epoch 221: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5916 - accuracy: 1.0000 - val_loss: 1.6631 - val_accuracy: 0.8868\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5923 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5923 - accuracy: 1.0000 - val_loss: 1.6674 - val_accuracy: 0.8679\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5920 - accuracy: 0.9979\n",
            "Epoch 223: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5920 - accuracy: 0.9979 - val_loss: 1.6665 - val_accuracy: 0.8491\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5908 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 954ms/step - loss: 1.5908 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.8679\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5936 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5936 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.8113\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5907 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 945ms/step - loss: 1.5907 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.8491\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5919 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5919 - accuracy: 1.0000 - val_loss: 1.6692 - val_accuracy: 0.8679\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5910 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 955ms/step - loss: 1.5910 - accuracy: 1.0000 - val_loss: 1.6656 - val_accuracy: 0.8491\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5912 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5912 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.8302\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5902 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5902 - accuracy: 1.0000 - val_loss: 1.6630 - val_accuracy: 0.8679\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5905 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5905 - accuracy: 1.0000 - val_loss: 1.6650 - val_accuracy: 0.8491\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5893 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 983ms/step - loss: 1.5893 - accuracy: 1.0000 - val_loss: 1.6656 - val_accuracy: 0.8679\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5916 - accuracy: 0.9979\n",
            "Epoch 233: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5916 - accuracy: 0.9979 - val_loss: 1.6669 - val_accuracy: 0.8491\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5918 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5918 - accuracy: 1.0000 - val_loss: 1.6658 - val_accuracy: 0.8679\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5903 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5903 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.8491\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5899 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.8491\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5920 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5920 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.8491\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5925 - accuracy: 0.9979\n",
            "Epoch 238: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5925 - accuracy: 0.9979 - val_loss: 1.6690 - val_accuracy: 0.8491\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5901 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5901 - accuracy: 1.0000 - val_loss: 1.6755 - val_accuracy: 0.8302\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5919 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5919 - accuracy: 1.0000 - val_loss: 1.6758 - val_accuracy: 0.8302\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5889 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5889 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.8491\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5886 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5886 - accuracy: 1.0000 - val_loss: 1.6659 - val_accuracy: 0.8302\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5900 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5900 - accuracy: 1.0000 - val_loss: 1.6806 - val_accuracy: 0.7925\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5890 - accuracy: 1.0000 - val_loss: 1.6726 - val_accuracy: 0.8302\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5896 - accuracy: 1.0000 - val_loss: 1.6726 - val_accuracy: 0.8113\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5907 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5907 - accuracy: 1.0000 - val_loss: 1.6704 - val_accuracy: 0.8113\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5901 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5901 - accuracy: 1.0000 - val_loss: 1.6704 - val_accuracy: 0.8302\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5906 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5906 - accuracy: 1.0000 - val_loss: 1.6739 - val_accuracy: 0.8302\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 0.9979\n",
            "Epoch 249: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5904 - accuracy: 0.9979 - val_loss: 1.6657 - val_accuracy: 0.8868\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5912 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5912 - accuracy: 1.0000 - val_loss: 1.6751 - val_accuracy: 0.8302\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5905 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5905 - accuracy: 1.0000 - val_loss: 1.6723 - val_accuracy: 0.8302\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5895 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 965ms/step - loss: 1.5895 - accuracy: 1.0000 - val_loss: 1.6663 - val_accuracy: 0.8679\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5896 - accuracy: 1.0000 - val_loss: 1.6667 - val_accuracy: 0.8302\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5899 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.8679\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5898 - accuracy: 1.0000 - val_loss: 1.6588 - val_accuracy: 0.8679\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5914 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5914 - accuracy: 1.0000 - val_loss: 1.6618 - val_accuracy: 0.8868\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5891 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5891 - accuracy: 1.0000 - val_loss: 1.6614 - val_accuracy: 0.9057\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5897 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 995ms/step - loss: 1.5897 - accuracy: 1.0000 - val_loss: 1.6701 - val_accuracy: 0.8679\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5887 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5887 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.8679\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5900 - accuracy: 0.9979\n",
            "Epoch 260: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5900 - accuracy: 0.9979 - val_loss: 1.6720 - val_accuracy: 0.8679\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5891 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5891 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.8491\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5901 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5901 - accuracy: 1.0000 - val_loss: 1.6756 - val_accuracy: 0.8113\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5904 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.8302\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5896 - accuracy: 1.0000 - val_loss: 1.6625 - val_accuracy: 0.8679\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5891 - accuracy: 1.0000\n",
            "Epoch 265: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5891 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.8491\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5905 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5905 - accuracy: 1.0000 - val_loss: 1.6666 - val_accuracy: 0.8679\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5895 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5895 - accuracy: 1.0000 - val_loss: 1.6694 - val_accuracy: 0.8679\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5881 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.8868\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5888 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5888 - accuracy: 1.0000 - val_loss: 1.6722 - val_accuracy: 0.8491\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5893 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 977ms/step - loss: 1.5893 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.8679\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5875 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.8491\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5883 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 959ms/step - loss: 1.5883 - accuracy: 1.0000 - val_loss: 1.6716 - val_accuracy: 0.8491\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5889 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5889 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.8679\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5883 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 991ms/step - loss: 1.5883 - accuracy: 1.0000 - val_loss: 1.6684 - val_accuracy: 0.8491\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5874 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5874 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.8491\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5876 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 991ms/step - loss: 1.5876 - accuracy: 1.0000 - val_loss: 1.6685 - val_accuracy: 0.8491\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5880 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5880 - accuracy: 1.0000 - val_loss: 1.6668 - val_accuracy: 0.8302\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5888 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.5888 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.8679\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5883 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5883 - accuracy: 1.0000 - val_loss: 1.6653 - val_accuracy: 0.8491\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5887 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 967ms/step - loss: 1.5887 - accuracy: 1.0000 - val_loss: 1.6687 - val_accuracy: 0.8679\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5881 - accuracy: 1.0000 - val_loss: 1.6729 - val_accuracy: 0.8679\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5883 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 987ms/step - loss: 1.5883 - accuracy: 1.0000 - val_loss: 1.6673 - val_accuracy: 0.8491\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5892 - accuracy: 0.9979\n",
            "Epoch 283: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5892 - accuracy: 0.9979 - val_loss: 1.6703 - val_accuracy: 0.8302\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 985ms/step - loss: 1.5881 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.8302\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5873 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.5873 - accuracy: 1.0000 - val_loss: 1.6673 - val_accuracy: 0.8113\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5870 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 920ms/step - loss: 1.5870 - accuracy: 1.0000 - val_loss: 1.6628 - val_accuracy: 0.8679\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5876 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5876 - accuracy: 1.0000 - val_loss: 1.6676 - val_accuracy: 0.8302\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.5881 - accuracy: 1.0000 - val_loss: 1.6626 - val_accuracy: 0.8868\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5866 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5866 - accuracy: 1.0000 - val_loss: 1.6619 - val_accuracy: 0.8302\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5883 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 878ms/step - loss: 1.5883 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.8302\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5875 - accuracy: 1.0000 - val_loss: 1.6693 - val_accuracy: 0.8491\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5872 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.5872 - accuracy: 1.0000 - val_loss: 1.6699 - val_accuracy: 0.8679\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5879 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5879 - accuracy: 1.0000 - val_loss: 1.6627 - val_accuracy: 0.8491\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 916ms/step - loss: 1.5881 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.8491\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5890 - accuracy: 1.0000 - val_loss: 1.6656 - val_accuracy: 0.8302\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5862 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 1.5862 - accuracy: 1.0000 - val_loss: 1.6703 - val_accuracy: 0.8302\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5872 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.5872 - accuracy: 1.0000 - val_loss: 1.6703 - val_accuracy: 0.8491\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5876 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 943ms/step - loss: 1.5876 - accuracy: 1.0000 - val_loss: 1.6727 - val_accuracy: 0.8302\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.5871 - accuracy: 1.0000 - val_loss: 1.6690 - val_accuracy: 0.8491\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5868 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 972ms/step - loss: 1.5868 - accuracy: 1.0000 - val_loss: 1.6611 - val_accuracy: 0.8491\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 1.6664 - accuracy: 0.9434\n",
            "9_Model evaluation:  [1.6664270162582397, 0.9433962106704712]    Now ACC: 93.57111111111111\n",
            "2/2 [==============================] - 3s 141ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        11\n",
            "     boredom       0.86      1.00      0.92         6\n",
            "     disgust       1.00      0.75      0.86         4\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       1.00      1.00      1.00        13\n",
            "     neutral       0.86      0.86      0.86         7\n",
            "         sad       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.94        53\n",
            "   macro avg       0.94      0.92      0.92        53\n",
            "weighted avg       0.95      0.94      0.94        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.5088 - accuracy: 0.1888\n",
            "Epoch 1: val_accuracy improved from -inf to 0.24528, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 40s 1s/step - loss: 3.5088 - accuracy: 0.1888 - val_loss: 2.2511 - val_accuracy: 0.2453\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2287 - accuracy: 0.2116\n",
            "Epoch 2: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 10s 1s/step - loss: 2.2287 - accuracy: 0.2116 - val_loss: 4.2339 - val_accuracy: 0.2075\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9995 - accuracy: 0.1846\n",
            "Epoch 3: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 1.9995 - accuracy: 0.1846 - val_loss: 3.8441 - val_accuracy: 0.2075\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9834 - accuracy: 0.1867\n",
            "Epoch 4: val_accuracy improved from 0.24528 to 0.37736, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.9834 - accuracy: 0.1867 - val_loss: 2.2152 - val_accuracy: 0.3774\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9087 - accuracy: 0.3568\n",
            "Epoch 5: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 8s 946ms/step - loss: 1.9087 - accuracy: 0.3568 - val_loss: 2.3062 - val_accuracy: 0.2264\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8948 - accuracy: 0.4232\n",
            "Epoch 6: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8948 - accuracy: 0.4232 - val_loss: 2.2441 - val_accuracy: 0.2264\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8842 - accuracy: 0.4419\n",
            "Epoch 7: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 8s 946ms/step - loss: 1.8842 - accuracy: 0.4419 - val_loss: 2.1040 - val_accuracy: 0.2264\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8694 - accuracy: 0.4606\n",
            "Epoch 8: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8694 - accuracy: 0.4606 - val_loss: 1.9783 - val_accuracy: 0.2264\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8610 - accuracy: 0.5249\n",
            "Epoch 9: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.8610 - accuracy: 0.5249 - val_loss: 1.9598 - val_accuracy: 0.2453\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8559 - accuracy: 0.5187\n",
            "Epoch 10: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8559 - accuracy: 0.5187 - val_loss: 1.9517 - val_accuracy: 0.3019\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8453 - accuracy: 0.5643\n",
            "Epoch 11: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 8s 987ms/step - loss: 1.8453 - accuracy: 0.5643 - val_loss: 1.9441 - val_accuracy: 0.3585\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8391 - accuracy: 0.5747\n",
            "Epoch 12: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8391 - accuracy: 0.5747 - val_loss: 1.9559 - val_accuracy: 0.3585\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8340 - accuracy: 0.5705\n",
            "Epoch 13: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 8s 998ms/step - loss: 1.8340 - accuracy: 0.5705 - val_loss: 1.9589 - val_accuracy: 0.3585\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8264 - accuracy: 0.5934\n",
            "Epoch 14: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.8264 - accuracy: 0.5934 - val_loss: 1.9542 - val_accuracy: 0.3208\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8232 - accuracy: 0.6120\n",
            "Epoch 15: val_accuracy improved from 0.37736 to 0.39623, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.8232 - accuracy: 0.6120 - val_loss: 1.9467 - val_accuracy: 0.3962\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8156 - accuracy: 0.6079\n",
            "Epoch 16: val_accuracy improved from 0.39623 to 0.49057, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.8156 - accuracy: 0.6079 - val_loss: 1.9107 - val_accuracy: 0.4906\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8082 - accuracy: 0.6515\n",
            "Epoch 17: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.8082 - accuracy: 0.6515 - val_loss: 1.8955 - val_accuracy: 0.4906\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8031 - accuracy: 0.6722\n",
            "Epoch 18: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.8031 - accuracy: 0.6722 - val_loss: 1.8860 - val_accuracy: 0.4528\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7988 - accuracy: 0.6639\n",
            "Epoch 19: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7988 - accuracy: 0.6639 - val_loss: 1.8813 - val_accuracy: 0.4340\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7954 - accuracy: 0.6618\n",
            "Epoch 20: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7954 - accuracy: 0.6618 - val_loss: 1.8644 - val_accuracy: 0.4528\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7892 - accuracy: 0.6763\n",
            "Epoch 21: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7892 - accuracy: 0.6763 - val_loss: 1.8576 - val_accuracy: 0.4528\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7870 - accuracy: 0.6992\n",
            "Epoch 22: val_accuracy did not improve from 0.49057\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7870 - accuracy: 0.6992 - val_loss: 1.8585 - val_accuracy: 0.4906\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7773 - accuracy: 0.7531\n",
            "Epoch 23: val_accuracy improved from 0.49057 to 0.54717, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7773 - accuracy: 0.7531 - val_loss: 1.8556 - val_accuracy: 0.5472\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7726 - accuracy: 0.7614\n",
            "Epoch 24: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7726 - accuracy: 0.7614 - val_loss: 1.8681 - val_accuracy: 0.4906\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7773 - accuracy: 0.7593\n",
            "Epoch 25: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7773 - accuracy: 0.7593 - val_loss: 1.8603 - val_accuracy: 0.5094\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7715 - accuracy: 0.7635\n",
            "Epoch 26: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7715 - accuracy: 0.7635 - val_loss: 1.8645 - val_accuracy: 0.5283\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7628 - accuracy: 0.7946\n",
            "Epoch 27: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7628 - accuracy: 0.7946 - val_loss: 1.8692 - val_accuracy: 0.4906\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7589 - accuracy: 0.8071\n",
            "Epoch 28: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7589 - accuracy: 0.8071 - val_loss: 1.8615 - val_accuracy: 0.4906\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7659 - accuracy: 0.7614\n",
            "Epoch 29: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7659 - accuracy: 0.7614 - val_loss: 1.8793 - val_accuracy: 0.4717\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7574 - accuracy: 0.7884\n",
            "Epoch 30: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7574 - accuracy: 0.7884 - val_loss: 1.8679 - val_accuracy: 0.5472\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7525 - accuracy: 0.8091\n",
            "Epoch 31: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 8s 990ms/step - loss: 1.7525 - accuracy: 0.8091 - val_loss: 1.8567 - val_accuracy: 0.5472\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7476 - accuracy: 0.8340\n",
            "Epoch 32: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.7476 - accuracy: 0.8340 - val_loss: 1.8552 - val_accuracy: 0.5472\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7472 - accuracy: 0.8444\n",
            "Epoch 33: val_accuracy improved from 0.54717 to 0.62264, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7472 - accuracy: 0.8444 - val_loss: 1.8555 - val_accuracy: 0.6226\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7396 - accuracy: 0.8444\n",
            "Epoch 34: val_accuracy did not improve from 0.62264\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7396 - accuracy: 0.8444 - val_loss: 1.8369 - val_accuracy: 0.6038\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7472 - accuracy: 0.8423\n",
            "Epoch 35: val_accuracy did not improve from 0.62264\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7472 - accuracy: 0.8423 - val_loss: 1.8383 - val_accuracy: 0.6226\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7442 - accuracy: 0.8631\n",
            "Epoch 36: val_accuracy did not improve from 0.62264\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7442 - accuracy: 0.8631 - val_loss: 1.8585 - val_accuracy: 0.5849\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7361 - accuracy: 0.8693\n",
            "Epoch 37: val_accuracy improved from 0.62264 to 0.66038, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7361 - accuracy: 0.8693 - val_loss: 1.8413 - val_accuracy: 0.6604\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7387 - accuracy: 0.8506\n",
            "Epoch 38: val_accuracy did not improve from 0.66038\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7387 - accuracy: 0.8506 - val_loss: 1.8398 - val_accuracy: 0.6226\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7331 - accuracy: 0.8880\n",
            "Epoch 39: val_accuracy did not improve from 0.66038\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7331 - accuracy: 0.8880 - val_loss: 1.8309 - val_accuracy: 0.6226\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7319 - accuracy: 0.8755\n",
            "Epoch 40: val_accuracy did not improve from 0.66038\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7319 - accuracy: 0.8755 - val_loss: 1.8042 - val_accuracy: 0.6415\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7300 - accuracy: 0.8838\n",
            "Epoch 41: val_accuracy improved from 0.66038 to 0.67925, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7300 - accuracy: 0.8838 - val_loss: 1.7947 - val_accuracy: 0.6792\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7310 - accuracy: 0.8631\n",
            "Epoch 42: val_accuracy improved from 0.67925 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7310 - accuracy: 0.8631 - val_loss: 1.7760 - val_accuracy: 0.7170\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7259 - accuracy: 0.8880\n",
            "Epoch 43: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7259 - accuracy: 0.8880 - val_loss: 1.7976 - val_accuracy: 0.6981\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7233 - accuracy: 0.9025\n",
            "Epoch 44: val_accuracy improved from 0.71698 to 0.77358, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7233 - accuracy: 0.9025 - val_loss: 1.7836 - val_accuracy: 0.7736\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7173 - accuracy: 0.9191\n",
            "Epoch 45: val_accuracy improved from 0.77358 to 0.79245, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7173 - accuracy: 0.9191 - val_loss: 1.7728 - val_accuracy: 0.7925\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7171 - accuracy: 0.9108\n",
            "Epoch 46: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7171 - accuracy: 0.9108 - val_loss: 1.7641 - val_accuracy: 0.7736\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7176 - accuracy: 0.9046\n",
            "Epoch 47: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7176 - accuracy: 0.9046 - val_loss: 1.7519 - val_accuracy: 0.7925\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7146 - accuracy: 0.9191\n",
            "Epoch 48: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7146 - accuracy: 0.9191 - val_loss: 1.7632 - val_accuracy: 0.7925\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7163 - accuracy: 0.9108\n",
            "Epoch 49: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7163 - accuracy: 0.9108 - val_loss: 1.7787 - val_accuracy: 0.7170\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7163 - accuracy: 0.9191\n",
            "Epoch 50: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7163 - accuracy: 0.9191 - val_loss: 1.7586 - val_accuracy: 0.7925\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7104 - accuracy: 0.9274\n",
            "Epoch 51: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7104 - accuracy: 0.9274 - val_loss: 1.7813 - val_accuracy: 0.7170\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7129 - accuracy: 0.9295\n",
            "Epoch 52: val_accuracy improved from 0.79245 to 0.84906, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 8s 967ms/step - loss: 1.7129 - accuracy: 0.9295 - val_loss: 1.7405 - val_accuracy: 0.8491\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7109 - accuracy: 0.9295\n",
            "Epoch 53: val_accuracy improved from 0.84906 to 0.86792, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7109 - accuracy: 0.9295 - val_loss: 1.7397 - val_accuracy: 0.8679\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7065 - accuracy: 0.9440\n",
            "Epoch 54: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 8s 924ms/step - loss: 1.7065 - accuracy: 0.9440 - val_loss: 1.7474 - val_accuracy: 0.7925\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7024 - accuracy: 0.9357\n",
            "Epoch 55: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7024 - accuracy: 0.9357 - val_loss: 1.7568 - val_accuracy: 0.7736\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7005 - accuracy: 0.9419\n",
            "Epoch 56: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7005 - accuracy: 0.9419 - val_loss: 1.7548 - val_accuracy: 0.7736\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7041 - accuracy: 0.9523\n",
            "Epoch 57: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.7041 - accuracy: 0.9523 - val_loss: 1.7487 - val_accuracy: 0.8113\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6993 - accuracy: 0.9419\n",
            "Epoch 58: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6993 - accuracy: 0.9419 - val_loss: 1.7603 - val_accuracy: 0.7547\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7050 - accuracy: 0.9336\n",
            "Epoch 59: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.7050 - accuracy: 0.9336 - val_loss: 1.7671 - val_accuracy: 0.7547\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7025 - accuracy: 0.9461\n",
            "Epoch 60: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 998ms/step - loss: 1.7025 - accuracy: 0.9461 - val_loss: 1.7427 - val_accuracy: 0.8113\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6962 - accuracy: 0.9523\n",
            "Epoch 61: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6962 - accuracy: 0.9523 - val_loss: 1.7463 - val_accuracy: 0.7925\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6928 - accuracy: 0.9689\n",
            "Epoch 62: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6928 - accuracy: 0.9689 - val_loss: 1.8041 - val_accuracy: 0.6792\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6941 - accuracy: 0.9523\n",
            "Epoch 63: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6941 - accuracy: 0.9523 - val_loss: 1.7945 - val_accuracy: 0.6415\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6957 - accuracy: 0.9461\n",
            "Epoch 64: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 8s 981ms/step - loss: 1.6957 - accuracy: 0.9461 - val_loss: 1.7447 - val_accuracy: 0.7358\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6907 - accuracy: 0.9606\n",
            "Epoch 65: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6907 - accuracy: 0.9606 - val_loss: 1.7304 - val_accuracy: 0.8113\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6946 - accuracy: 0.9378\n",
            "Epoch 66: val_accuracy improved from 0.86792 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6946 - accuracy: 0.9378 - val_loss: 1.7331 - val_accuracy: 0.8868\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6906 - accuracy: 0.9606\n",
            "Epoch 67: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6906 - accuracy: 0.9606 - val_loss: 1.7249 - val_accuracy: 0.8679\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6893 - accuracy: 0.9647\n",
            "Epoch 68: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6893 - accuracy: 0.9647 - val_loss: 1.7282 - val_accuracy: 0.8491\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6891 - accuracy: 0.9647\n",
            "Epoch 69: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6891 - accuracy: 0.9647 - val_loss: 1.7220 - val_accuracy: 0.8868\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6902 - accuracy: 0.9523\n",
            "Epoch 70: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6902 - accuracy: 0.9523 - val_loss: 1.7343 - val_accuracy: 0.8302\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6841 - accuracy: 0.9689\n",
            "Epoch 71: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6841 - accuracy: 0.9689 - val_loss: 1.7283 - val_accuracy: 0.8491\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6875 - accuracy: 0.9772\n",
            "Epoch 72: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6875 - accuracy: 0.9772 - val_loss: 1.7366 - val_accuracy: 0.7925\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6853 - accuracy: 0.9772\n",
            "Epoch 73: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6853 - accuracy: 0.9772 - val_loss: 1.7378 - val_accuracy: 0.7925\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6843 - accuracy: 0.9689\n",
            "Epoch 74: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6843 - accuracy: 0.9689 - val_loss: 1.7146 - val_accuracy: 0.8868\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6835 - accuracy: 0.9834\n",
            "Epoch 75: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6835 - accuracy: 0.9834 - val_loss: 1.7204 - val_accuracy: 0.8679\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6821 - accuracy: 0.9772\n",
            "Epoch 76: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6821 - accuracy: 0.9772 - val_loss: 1.7260 - val_accuracy: 0.8491\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6820 - accuracy: 0.9876\n",
            "Epoch 77: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6820 - accuracy: 0.9876 - val_loss: 1.7217 - val_accuracy: 0.8868\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6803 - accuracy: 0.9834\n",
            "Epoch 78: val_accuracy improved from 0.88679 to 0.90566, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6803 - accuracy: 0.9834 - val_loss: 1.7211 - val_accuracy: 0.9057\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6816 - accuracy: 0.9834\n",
            "Epoch 79: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6816 - accuracy: 0.9834 - val_loss: 1.7161 - val_accuracy: 0.9057\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6790 - accuracy: 0.9772\n",
            "Epoch 80: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 976ms/step - loss: 1.6790 - accuracy: 0.9772 - val_loss: 1.7222 - val_accuracy: 0.8302\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6814 - accuracy: 0.9710\n",
            "Epoch 81: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6814 - accuracy: 0.9710 - val_loss: 1.7204 - val_accuracy: 0.8679\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6769 - accuracy: 0.9793\n",
            "Epoch 82: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6769 - accuracy: 0.9793 - val_loss: 1.7168 - val_accuracy: 0.8679\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6755 - accuracy: 0.9793\n",
            "Epoch 83: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6755 - accuracy: 0.9793 - val_loss: 1.7191 - val_accuracy: 0.8491\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6772 - accuracy: 0.9793\n",
            "Epoch 84: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6772 - accuracy: 0.9793 - val_loss: 1.7196 - val_accuracy: 0.8679\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6793 - accuracy: 0.9793\n",
            "Epoch 85: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6793 - accuracy: 0.9793 - val_loss: 1.7320 - val_accuracy: 0.7925\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6769 - accuracy: 0.9813\n",
            "Epoch 86: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 985ms/step - loss: 1.6769 - accuracy: 0.9813 - val_loss: 1.7431 - val_accuracy: 0.7736\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6730 - accuracy: 0.9938\n",
            "Epoch 87: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6730 - accuracy: 0.9938 - val_loss: 1.7357 - val_accuracy: 0.8302\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6772 - accuracy: 0.9813\n",
            "Epoch 88: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 9s 993ms/step - loss: 1.6772 - accuracy: 0.9813 - val_loss: 1.7249 - val_accuracy: 0.8679\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6721 - accuracy: 0.9938\n",
            "Epoch 89: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6721 - accuracy: 0.9938 - val_loss: 1.7290 - val_accuracy: 0.8302\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6757 - accuracy: 0.9896\n",
            "Epoch 90: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 927ms/step - loss: 1.6757 - accuracy: 0.9896 - val_loss: 1.7203 - val_accuracy: 0.8679\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6745 - accuracy: 0.9917\n",
            "Epoch 91: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6745 - accuracy: 0.9917 - val_loss: 1.7221 - val_accuracy: 0.8679\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6731 - accuracy: 0.9876\n",
            "Epoch 92: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 911ms/step - loss: 1.6731 - accuracy: 0.9876 - val_loss: 1.7223 - val_accuracy: 0.8302\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6721 - accuracy: 0.9959\n",
            "Epoch 93: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6721 - accuracy: 0.9959 - val_loss: 1.7215 - val_accuracy: 0.8302\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6709 - accuracy: 0.9938\n",
            "Epoch 94: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 886ms/step - loss: 1.6709 - accuracy: 0.9938 - val_loss: 1.7203 - val_accuracy: 0.8679\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6712 - accuracy: 0.9876\n",
            "Epoch 95: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6712 - accuracy: 0.9876 - val_loss: 1.7149 - val_accuracy: 0.8491\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6688 - accuracy: 0.9979\n",
            "Epoch 96: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 8s 895ms/step - loss: 1.6688 - accuracy: 0.9979 - val_loss: 1.7097 - val_accuracy: 0.8868\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6683 - accuracy: 0.9896\n",
            "Epoch 97: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6683 - accuracy: 0.9896 - val_loss: 1.7122 - val_accuracy: 0.9057\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6695 - accuracy: 0.9959\n",
            "Epoch 98: val_accuracy improved from 0.90566 to 0.92453, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 8s 902ms/step - loss: 1.6695 - accuracy: 0.9959 - val_loss: 1.7117 - val_accuracy: 0.9245\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6683 - accuracy: 0.9917\n",
            "Epoch 99: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6683 - accuracy: 0.9917 - val_loss: 1.7139 - val_accuracy: 0.8868\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6665 - accuracy: 0.9938\n",
            "Epoch 100: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 8s 880ms/step - loss: 1.6665 - accuracy: 0.9938 - val_loss: 1.7097 - val_accuracy: 0.9057\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6661 - accuracy: 0.9938\n",
            "Epoch 101: val_accuracy improved from 0.92453 to 0.94340, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6661 - accuracy: 0.9938 - val_loss: 1.7091 - val_accuracy: 0.9434\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6657 - accuracy: 0.9959\n",
            "Epoch 102: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 886ms/step - loss: 1.6657 - accuracy: 0.9959 - val_loss: 1.7102 - val_accuracy: 0.9057\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6660 - accuracy: 1.0000\n",
            "Epoch 103: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6660 - accuracy: 1.0000 - val_loss: 1.7096 - val_accuracy: 0.9057\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6635 - accuracy: 1.0000\n",
            "Epoch 104: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 884ms/step - loss: 1.6635 - accuracy: 1.0000 - val_loss: 1.7063 - val_accuracy: 0.8679\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6652 - accuracy: 0.9938\n",
            "Epoch 105: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6652 - accuracy: 0.9938 - val_loss: 1.7186 - val_accuracy: 0.8113\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6658 - accuracy: 0.9938\n",
            "Epoch 106: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 919ms/step - loss: 1.6658 - accuracy: 0.9938 - val_loss: 1.7168 - val_accuracy: 0.8302\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6669 - accuracy: 0.9938\n",
            "Epoch 107: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6669 - accuracy: 0.9938 - val_loss: 1.7120 - val_accuracy: 0.8679\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6628 - accuracy: 0.9979\n",
            "Epoch 108: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 922ms/step - loss: 1.6628 - accuracy: 0.9979 - val_loss: 1.7074 - val_accuracy: 0.9245\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6651 - accuracy: 0.9959\n",
            "Epoch 109: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6651 - accuracy: 0.9959 - val_loss: 1.7045 - val_accuracy: 0.8868\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6631 - accuracy: 1.0000\n",
            "Epoch 110: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 943ms/step - loss: 1.6631 - accuracy: 1.0000 - val_loss: 1.7138 - val_accuracy: 0.8868\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6622 - accuracy: 0.9959\n",
            "Epoch 111: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6622 - accuracy: 0.9959 - val_loss: 1.7125 - val_accuracy: 0.9057\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6636 - accuracy: 0.9959\n",
            "Epoch 112: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 949ms/step - loss: 1.6636 - accuracy: 0.9959 - val_loss: 1.7142 - val_accuracy: 0.9057\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6634 - accuracy: 0.9979\n",
            "Epoch 113: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6634 - accuracy: 0.9979 - val_loss: 1.7083 - val_accuracy: 0.9057\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6616 - accuracy: 0.9979\n",
            "Epoch 114: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 8s 975ms/step - loss: 1.6616 - accuracy: 0.9979 - val_loss: 1.7182 - val_accuracy: 0.7925\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6619 - accuracy: 0.9979\n",
            "Epoch 115: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6619 - accuracy: 0.9979 - val_loss: 1.7116 - val_accuracy: 0.8679\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6607 - accuracy: 0.9979\n",
            "Epoch 116: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6607 - accuracy: 0.9979 - val_loss: 1.7178 - val_accuracy: 0.8302\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6620 - accuracy: 0.9979\n",
            "Epoch 117: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6620 - accuracy: 0.9979 - val_loss: 1.7028 - val_accuracy: 0.9245\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6630 - accuracy: 0.9979\n",
            "Epoch 118: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 9s 1000ms/step - loss: 1.6630 - accuracy: 0.9979 - val_loss: 1.7021 - val_accuracy: 0.9057\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6623 - accuracy: 0.9979\n",
            "Epoch 119: val_accuracy improved from 0.94340 to 0.96226, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6623 - accuracy: 0.9979 - val_loss: 1.7032 - val_accuracy: 0.9623\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6614 - accuracy: 0.9959\n",
            "Epoch 120: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6614 - accuracy: 0.9959 - val_loss: 1.7041 - val_accuracy: 0.9057\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6612 - accuracy: 0.9979\n",
            "Epoch 121: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6612 - accuracy: 0.9979 - val_loss: 1.7104 - val_accuracy: 0.8679\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6600 - accuracy: 1.0000\n",
            "Epoch 122: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6600 - accuracy: 1.0000 - val_loss: 1.7143 - val_accuracy: 0.8868\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6634 - accuracy: 0.9959\n",
            "Epoch 123: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6634 - accuracy: 0.9959 - val_loss: 1.7127 - val_accuracy: 0.8868\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6603 - accuracy: 0.9979\n",
            "Epoch 124: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6603 - accuracy: 0.9979 - val_loss: 1.7086 - val_accuracy: 0.9245\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6631 - accuracy: 0.9938\n",
            "Epoch 125: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6631 - accuracy: 0.9938 - val_loss: 1.7121 - val_accuracy: 0.8491\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6587 - accuracy: 1.0000\n",
            "Epoch 126: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6587 - accuracy: 1.0000 - val_loss: 1.7020 - val_accuracy: 0.9057\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6586 - accuracy: 1.0000\n",
            "Epoch 127: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6586 - accuracy: 1.0000 - val_loss: 1.7112 - val_accuracy: 0.8491\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6581 - accuracy: 1.0000\n",
            "Epoch 128: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6581 - accuracy: 1.0000 - val_loss: 1.7061 - val_accuracy: 0.9245\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6587 - accuracy: 0.9979\n",
            "Epoch 129: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 996ms/step - loss: 1.6587 - accuracy: 0.9979 - val_loss: 1.7052 - val_accuracy: 0.9057\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6585 - accuracy: 1.0000\n",
            "Epoch 130: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6585 - accuracy: 1.0000 - val_loss: 1.7068 - val_accuracy: 0.9057\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6585 - accuracy: 0.9959\n",
            "Epoch 131: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 960ms/step - loss: 1.6585 - accuracy: 0.9959 - val_loss: 1.7073 - val_accuracy: 0.8868\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6608 - accuracy: 0.9959\n",
            "Epoch 132: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6608 - accuracy: 0.9959 - val_loss: 1.7038 - val_accuracy: 0.9623\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6570 - accuracy: 0.9979\n",
            "Epoch 133: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6570 - accuracy: 0.9979 - val_loss: 1.7113 - val_accuracy: 0.9245\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6584 - accuracy: 1.0000\n",
            "Epoch 134: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6584 - accuracy: 1.0000 - val_loss: 1.7143 - val_accuracy: 0.9434\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6564 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 984ms/step - loss: 1.6564 - accuracy: 0.9979 - val_loss: 1.7061 - val_accuracy: 0.9434\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6569 - accuracy: 1.0000\n",
            "Epoch 136: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6569 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.8679\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6572 - accuracy: 1.0000\n",
            "Epoch 137: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 982ms/step - loss: 1.6572 - accuracy: 1.0000 - val_loss: 1.7005 - val_accuracy: 0.9623\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6565 - accuracy: 1.0000\n",
            "Epoch 138: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6565 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.9434\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6566 - accuracy: 1.0000\n",
            "Epoch 139: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 955ms/step - loss: 1.6566 - accuracy: 1.0000 - val_loss: 1.7078 - val_accuracy: 0.9057\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6555 - accuracy: 1.0000\n",
            "Epoch 140: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6555 - accuracy: 1.0000 - val_loss: 1.7042 - val_accuracy: 0.9434\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6554 - accuracy: 1.0000\n",
            "Epoch 141: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 1.6554 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.9245\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6551 - accuracy: 1.0000\n",
            "Epoch 142: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6551 - accuracy: 1.0000 - val_loss: 1.7035 - val_accuracy: 0.9245\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6550 - accuracy: 1.0000\n",
            "Epoch 143: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 1.6550 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.9057\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6570 - accuracy: 0.9979\n",
            "Epoch 144: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6570 - accuracy: 0.9979 - val_loss: 1.7044 - val_accuracy: 0.8868\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6541 - accuracy: 1.0000\n",
            "Epoch 145: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 970ms/step - loss: 1.6541 - accuracy: 1.0000 - val_loss: 1.7061 - val_accuracy: 0.9434\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6553 - accuracy: 1.0000\n",
            "Epoch 146: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6553 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.9057\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6548 - accuracy: 1.0000\n",
            "Epoch 147: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 986ms/step - loss: 1.6548 - accuracy: 1.0000 - val_loss: 1.7060 - val_accuracy: 0.9245\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6548 - accuracy: 1.0000\n",
            "Epoch 148: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6548 - accuracy: 1.0000 - val_loss: 1.7000 - val_accuracy: 0.9623\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6563 - accuracy: 0.9979\n",
            "Epoch 149: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 970ms/step - loss: 1.6563 - accuracy: 0.9979 - val_loss: 1.6989 - val_accuracy: 0.9245\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6563 - accuracy: 0.9979\n",
            "Epoch 150: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6563 - accuracy: 0.9979 - val_loss: 1.7008 - val_accuracy: 0.9245\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6540 - accuracy: 1.0000\n",
            "Epoch 151: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 998ms/step - loss: 1.6540 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.9057\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 0.9979\n",
            "Epoch 152: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6544 - accuracy: 0.9979 - val_loss: 1.7023 - val_accuracy: 0.9245\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6542 - accuracy: 1.0000\n",
            "Epoch 153: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 967ms/step - loss: 1.6542 - accuracy: 1.0000 - val_loss: 1.7032 - val_accuracy: 0.9434\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6532 - accuracy: 1.0000\n",
            "Epoch 154: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6532 - accuracy: 1.0000 - val_loss: 1.6999 - val_accuracy: 0.8868\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6538 - accuracy: 0.9979\n",
            "Epoch 155: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 7s 935ms/step - loss: 1.6538 - accuracy: 0.9979 - val_loss: 1.7004 - val_accuracy: 0.9057\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 0.9959\n",
            "Epoch 156: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6544 - accuracy: 0.9959 - val_loss: 1.6961 - val_accuracy: 0.9434\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6535 - accuracy: 1.0000\n",
            "Epoch 157: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6535 - accuracy: 1.0000 - val_loss: 1.6980 - val_accuracy: 0.9623\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6538 - accuracy: 1.0000\n",
            "Epoch 158: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6538 - accuracy: 1.0000 - val_loss: 1.7013 - val_accuracy: 0.8868\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6536 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy improved from 0.96226 to 0.98113, saving model to ./Models/EMODB_46_2023-07-09_09-47-55/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6536 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.9811\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6546 - accuracy: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6546 - accuracy: 1.0000 - val_loss: 1.7016 - val_accuracy: 0.9434\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6525 - accuracy: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6525 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.9245\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6525 - accuracy: 1.0000\n",
            "Epoch 162: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6525 - accuracy: 1.0000 - val_loss: 1.7068 - val_accuracy: 0.9245\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6521 - accuracy: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6521 - accuracy: 1.0000 - val_loss: 1.6976 - val_accuracy: 0.9623\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6511 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.9245\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6528 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6528 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.9434\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6513 - accuracy: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6513 - accuracy: 1.0000 - val_loss: 1.6992 - val_accuracy: 0.9434\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6512 - accuracy: 1.0000\n",
            "Epoch 167: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6512 - accuracy: 1.0000 - val_loss: 1.6971 - val_accuracy: 0.9623\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6503 - accuracy: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6503 - accuracy: 1.0000 - val_loss: 1.7039 - val_accuracy: 0.8679\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6516 - accuracy: 1.0000\n",
            "Epoch 169: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6516 - accuracy: 1.0000 - val_loss: 1.7130 - val_accuracy: 0.8491\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.9434\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6511 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.9057\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.7000 - val_accuracy: 0.9623\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6504 - accuracy: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6504 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9057\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6526 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6526 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.9245\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6526 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6526 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.9245\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6515 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6515 - accuracy: 1.0000 - val_loss: 1.6954 - val_accuracy: 0.9434\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6492 - accuracy: 1.0000\n",
            "Epoch 177: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6492 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.9245\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6514 - accuracy: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6514 - accuracy: 1.0000 - val_loss: 1.6958 - val_accuracy: 0.9434\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6519 - accuracy: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6519 - accuracy: 1.0000 - val_loss: 1.7002 - val_accuracy: 0.9434\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9245\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6506 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6506 - accuracy: 1.0000 - val_loss: 1.6983 - val_accuracy: 0.9245\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6491 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6491 - accuracy: 1.0000 - val_loss: 1.6992 - val_accuracy: 0.9434\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6485 - accuracy: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6485 - accuracy: 1.0000 - val_loss: 1.7005 - val_accuracy: 0.9245\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6500 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 988ms/step - loss: 1.6500 - accuracy: 1.0000 - val_loss: 1.7049 - val_accuracy: 0.9057\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6504 - accuracy: 0.9979\n",
            "Epoch 185: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6504 - accuracy: 0.9979 - val_loss: 1.7040 - val_accuracy: 0.9245\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6491 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 985ms/step - loss: 1.6491 - accuracy: 1.0000 - val_loss: 1.7134 - val_accuracy: 0.8679\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6487 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6487 - accuracy: 1.0000 - val_loss: 1.7067 - val_accuracy: 0.8868\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6494 - accuracy: 1.0000\n",
            "Epoch 188: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 957ms/step - loss: 1.6494 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.9434\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6488 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6488 - accuracy: 1.0000 - val_loss: 1.7054 - val_accuracy: 0.9245\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6483 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 935ms/step - loss: 1.6483 - accuracy: 1.0000 - val_loss: 1.7060 - val_accuracy: 0.9057\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6497 - accuracy: 0.9979\n",
            "Epoch 191: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6497 - accuracy: 0.9979 - val_loss: 1.7048 - val_accuracy: 0.9245\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6483 - accuracy: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 921ms/step - loss: 1.6483 - accuracy: 1.0000 - val_loss: 1.7001 - val_accuracy: 0.9434\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6482 - accuracy: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6482 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.9434\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6484 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 939ms/step - loss: 1.6484 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.9434\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6485 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6485 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.9434\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6494 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 967ms/step - loss: 1.6494 - accuracy: 1.0000 - val_loss: 1.6985 - val_accuracy: 0.9434\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6480 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6480 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.9245\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6482 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 991ms/step - loss: 1.6482 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.9245\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6489 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6489 - accuracy: 1.0000 - val_loss: 1.6975 - val_accuracy: 0.9434\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6489 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 993ms/step - loss: 1.6489 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.9434\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6485 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6485 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.9434\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6492 - accuracy: 0.9979\n",
            "Epoch 202: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 959ms/step - loss: 1.6492 - accuracy: 0.9979 - val_loss: 1.6957 - val_accuracy: 0.9434\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6484 - accuracy: 1.0000\n",
            "Epoch 203: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6484 - accuracy: 1.0000 - val_loss: 1.7022 - val_accuracy: 0.9245\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6472 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 949ms/step - loss: 1.6472 - accuracy: 1.0000 - val_loss: 1.7036 - val_accuracy: 0.9434\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6483 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6483 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9434\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6485 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6485 - accuracy: 1.0000 - val_loss: 1.6985 - val_accuracy: 0.9434\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6483 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6483 - accuracy: 1.0000 - val_loss: 1.6954 - val_accuracy: 0.9623\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6480 - accuracy: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 974ms/step - loss: 1.6480 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.9245\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6477 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6477 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.9434\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6477 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 953ms/step - loss: 1.6477 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9434\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6473 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6473 - accuracy: 1.0000 - val_loss: 1.6978 - val_accuracy: 0.9434\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6476 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 919ms/step - loss: 1.6476 - accuracy: 1.0000 - val_loss: 1.6989 - val_accuracy: 0.9623\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6470 - accuracy: 0.9979\n",
            "Epoch 213: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6470 - accuracy: 0.9979 - val_loss: 1.7021 - val_accuracy: 0.9623\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6480 - accuracy: 1.0000\n",
            "Epoch 214: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 1.6480 - accuracy: 1.0000 - val_loss: 1.6985 - val_accuracy: 0.9623\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6479 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6479 - accuracy: 1.0000 - val_loss: 1.7045 - val_accuracy: 0.8868\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6471 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 928ms/step - loss: 1.6471 - accuracy: 1.0000 - val_loss: 1.7020 - val_accuracy: 0.9245\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6471 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6471 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.9057\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6479 - accuracy: 1.0000\n",
            "Epoch 218: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 1.6479 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.9623\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6467 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6467 - accuracy: 1.0000 - val_loss: 1.6998 - val_accuracy: 0.9623\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6472 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 914ms/step - loss: 1.6472 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.9245\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6465 - accuracy: 1.0000\n",
            "Epoch 221: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6465 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.9434\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6468 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 920ms/step - loss: 1.6468 - accuracy: 1.0000 - val_loss: 1.6974 - val_accuracy: 0.9623\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6467 - accuracy: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6467 - accuracy: 1.0000 - val_loss: 1.7018 - val_accuracy: 0.8868\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6453 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 1.6453 - accuracy: 1.0000 - val_loss: 1.7013 - val_accuracy: 0.8868\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6464 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6464 - accuracy: 1.0000 - val_loss: 1.7086 - val_accuracy: 0.8679\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6468 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 959ms/step - loss: 1.6468 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.9434\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6465 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6465 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.9245\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6474 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 911ms/step - loss: 1.6474 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.9434\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6470 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6470 - accuracy: 1.0000 - val_loss: 1.6968 - val_accuracy: 0.9245\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6461 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 1.6461 - accuracy: 1.0000 - val_loss: 1.7019 - val_accuracy: 0.9434\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6460 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6460 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.9245\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6455 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 1.6455 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.9623\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.7005 - val_accuracy: 0.9623\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6454 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 1.6454 - accuracy: 1.0000 - val_loss: 1.7011 - val_accuracy: 0.9057\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6462 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6462 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.9811\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6459 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.7018 - val_accuracy: 0.9057\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6460 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6460 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.9623\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 876ms/step - loss: 1.6457 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.9434\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.6940 - val_accuracy: 0.9434\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 1.6457 - accuracy: 1.0000 - val_loss: 1.6936 - val_accuracy: 0.9623\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6445 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6445 - accuracy: 1.0000 - val_loss: 1.6955 - val_accuracy: 0.9434\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 1.6451 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.9245\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6459 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.6979 - val_accuracy: 0.9434\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6459 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.9434\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6452 - accuracy: 1.0000 - val_loss: 1.6987 - val_accuracy: 0.9245\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6454 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 1.6454 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.9245\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6462 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 11s 1s/step - loss: 1.6462 - accuracy: 1.0000 - val_loss: 1.6966 - val_accuracy: 0.9434\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 924ms/step - loss: 1.6457 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.9811\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.9245\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6446 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 931ms/step - loss: 1.6446 - accuracy: 1.0000 - val_loss: 1.6975 - val_accuracy: 0.9811\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6445 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6445 - accuracy: 1.0000 - val_loss: 1.6971 - val_accuracy: 0.9623\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6453 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 7s 918ms/step - loss: 1.6453 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.9623\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6454 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6454 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.9245\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 987ms/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9434\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6450 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6450 - accuracy: 1.0000 - val_loss: 1.6984 - val_accuracy: 0.9434\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6451 - accuracy: 1.0000 - val_loss: 1.6968 - val_accuracy: 0.9057\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6459 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.9623\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6453 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6453 - accuracy: 1.0000 - val_loss: 1.6968 - val_accuracy: 0.9057\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.9434\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6446 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 1s/step - loss: 1.6446 - accuracy: 1.0000 - val_loss: 1.6958 - val_accuracy: 0.9245\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6448 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6448 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9434\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 0.9979\n",
            "Epoch 262: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6452 - accuracy: 0.9979 - val_loss: 1.7003 - val_accuracy: 0.9057\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6440 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6440 - accuracy: 1.0000 - val_loss: 1.6992 - val_accuracy: 0.9434\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6437 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6437 - accuracy: 1.0000 - val_loss: 1.6992 - val_accuracy: 0.9245\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6446 - accuracy: 1.0000\n",
            "Epoch 265: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6446 - accuracy: 1.0000 - val_loss: 1.6975 - val_accuracy: 0.9623\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6442 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6442 - accuracy: 1.0000 - val_loss: 1.6965 - val_accuracy: 0.9623\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6441 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6441 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9434\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.9434\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 966ms/step - loss: 1.6434 - accuracy: 1.0000 - val_loss: 1.6986 - val_accuracy: 0.9623\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6441 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6441 - accuracy: 1.0000 - val_loss: 1.7001 - val_accuracy: 0.9434\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 978ms/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 1.6953 - val_accuracy: 0.9623\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6440 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6440 - accuracy: 1.0000 - val_loss: 1.6945 - val_accuracy: 0.9434\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6432 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 991ms/step - loss: 1.6432 - accuracy: 1.0000 - val_loss: 1.6959 - val_accuracy: 0.9434\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6433 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6433 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.9057\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 960ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.9434\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 9s 1s/step - loss: 1.6434 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.9434\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6437 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 978ms/step - loss: 1.6437 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.9623\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6434 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9434\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6439 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 941ms/step - loss: 1.6439 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.9057\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6440 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6440 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.9245\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6431 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 924ms/step - loss: 1.6431 - accuracy: 1.0000 - val_loss: 1.7070 - val_accuracy: 0.8679\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6436 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6436 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9623\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6431 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 916ms/step - loss: 1.6431 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.9434\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6434 - accuracy: 1.0000 - val_loss: 1.7000 - val_accuracy: 0.9245\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6432 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 885ms/step - loss: 1.6432 - accuracy: 1.0000 - val_loss: 1.7018 - val_accuracy: 0.9245\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6433 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6433 - accuracy: 1.0000 - val_loss: 1.7018 - val_accuracy: 0.9245\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6432 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 883ms/step - loss: 1.6432 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.9623\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6426 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6426 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9623\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6432 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 907ms/step - loss: 1.6432 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.9434\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6438 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6438 - accuracy: 1.0000 - val_loss: 1.6961 - val_accuracy: 0.9623\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6429 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 886ms/step - loss: 1.6429 - accuracy: 1.0000 - val_loss: 1.6977 - val_accuracy: 0.9434\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6428 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6428 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.9623\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6427 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 897ms/step - loss: 1.6427 - accuracy: 1.0000 - val_loss: 1.6978 - val_accuracy: 0.9623\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6426 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6426 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.9245\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 885ms/step - loss: 1.6434 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.9434\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6416 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6416 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.9057\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6430 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 904ms/step - loss: 1.6430 - accuracy: 1.0000 - val_loss: 1.7054 - val_accuracy: 0.9057\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6435 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6435 - accuracy: 1.0000 - val_loss: 1.7035 - val_accuracy: 0.9245\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 8s 890ms/step - loss: 1.6434 - accuracy: 1.0000 - val_loss: 1.7038 - val_accuracy: 0.8868\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6436 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.98113\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.6436 - accuracy: 1.0000 - val_loss: 1.7001 - val_accuracy: 0.9434\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.7007 - accuracy: 0.9811\n",
            "10_Model evaluation:  [1.7007049322128296, 0.9811320900917053]    Now ACC: 94.025\n",
            "2/2 [==============================] - 2s 68ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        12\n",
            "     boredom       1.00      0.90      0.95        10\n",
            "     disgust       0.86      1.00      0.92         6\n",
            "        fear       1.00      1.00      1.00         4\n",
            "       happy       1.00      1.00      1.00         7\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.98        53\n",
            "   macro avg       0.98      0.99      0.98        53\n",
            "weighted avg       0.98      0.98      0.98        53\n",
            "\n",
            "Average ACC: 0.9402515769004822\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/content/TIM-Net_SER/Code/Model.py:138: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  writer.save()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode test --data SAVEE  --test_path ./Test_Models/SAVEE_44 --split_fold 10 --random_seed 44"
      ],
      "metadata": {
        "id": "1CfV8Qy0pSOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba04b0a-58eb-4b8e-ee1d-7b4bee6c3341"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 17:37:36.235181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 17:37:37.756453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "###gpus:[]\n",
            "TIMNET MODEL SHAPE: (254, 39)\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 73ms/step - loss: 0.5438 - accuracy: 0.8750\n",
            "1_Model evaluation:  [0.5437782406806946, 0.875]    Now ACC: 87.5\n",
            "2/2 [==============================] - 3s 132ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.75      1.00      0.86         3\n",
            "     disgust       1.00      0.50      0.67         8\n",
            "        fear       0.78      0.88      0.82         8\n",
            "       happy       0.75      1.00      0.86         3\n",
            "     neutral       0.88      1.00      0.93        14\n",
            "         sad       1.00      0.80      0.89         5\n",
            "    surprise       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.88        48\n",
            "   macro avg       0.88      0.88      0.86        48\n",
            "weighted avg       0.90      0.88      0.87        48\n",
            "\n",
            "2/2 [==============================] - 3s 64ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 87ms/step - loss: 0.6559 - accuracy: 0.8750\n",
            "2_Model evaluation:  [0.6559337973594666, 0.875]    Now ACC: 87.5\n",
            "2/2 [==============================] - 2s 67ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      1.00      0.80         6\n",
            "     disgust       1.00      0.67      0.80         6\n",
            "        fear       0.75      0.60      0.67         5\n",
            "       happy       1.00      0.88      0.93         8\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      0.86      0.92         7\n",
            "    surprise       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.88        48\n",
            "   macro avg       0.88      0.86      0.86        48\n",
            "weighted avg       0.90      0.88      0.87        48\n",
            "\n",
            "2/2 [==============================] - 2s 111ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 75ms/step - loss: 0.8832 - accuracy: 0.8333\n",
            "3_Model evaluation:  [0.8831873536109924, 0.8333333134651184]    Now ACC: 86.11\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6cfbce1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6cfbce1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.83      0.91         6\n",
            "     disgust       0.71      0.83      0.77         6\n",
            "        fear       0.83      0.62      0.71         8\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       0.86      1.00      0.92        12\n",
            "         sad       1.00      0.67      0.80         3\n",
            "    surprise       0.67      0.86      0.75         7\n",
            "\n",
            "    accuracy                           0.83        48\n",
            "   macro avg       0.87      0.81      0.82        48\n",
            "weighted avg       0.85      0.83      0.83        48\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6cfbce2440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6cfbce2440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 64ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 5s 147ms/step - loss: 0.6446 - accuracy: 0.9167\n",
            "4_Model evaluation:  [0.6445937156677246, 0.9166666865348816]    Now ACC: 87.5\n",
            "2/2 [==============================] - 3s 72ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         8\n",
            "     disgust       0.67      0.67      0.67         3\n",
            "        fear       0.67      0.67      0.67         3\n",
            "       happy       1.00      0.67      0.80         3\n",
            "     neutral       1.00      0.94      0.97        17\n",
            "         sad       1.00      1.00      1.00         9\n",
            "    surprise       0.71      1.00      0.83         5\n",
            "\n",
            "    accuracy                           0.92        48\n",
            "   macro avg       0.86      0.85      0.85        48\n",
            "weighted avg       0.93      0.92      0.92        48\n",
            "\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6cfbe95d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6cfbe95d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 4s 69ms/step - loss: 0.8626 - accuracy: 0.9583\n",
            "5_Model evaluation:  [0.8626158237457275, 0.9583333134651184]    Now ACC: 89.166\n",
            "2/2 [==============================] - 2s 129ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         3\n",
            "     disgust       0.88      1.00      0.93         7\n",
            "        fear       1.00      0.80      0.89         5\n",
            "       happy       1.00      0.89      0.94         9\n",
            "     neutral       1.00      1.00      1.00        13\n",
            "         sad       1.00      1.00      1.00         7\n",
            "    surprise       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.96        48\n",
            "   macro avg       0.95      0.96      0.95        48\n",
            "weighted avg       0.97      0.96      0.96        48\n",
            "\n",
            "2/2 [==============================] - 3s 136ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6cfbce3eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6cfbce3eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 69ms/step - loss: 0.8891 - accuracy: 0.8542\n",
            "6_Model evaluation:  [0.8891064524650574, 0.8541666865348816]    Now ACC: 88.54166666666667\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.89      0.89         9\n",
            "     disgust       0.71      1.00      0.83         5\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       0.75      0.43      0.55         7\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      0.75      0.86         4\n",
            "    surprise       0.62      0.83      0.71         6\n",
            "\n",
            "    accuracy                           0.85        48\n",
            "   macro avg       0.85      0.84      0.83        48\n",
            "weighted avg       0.87      0.85      0.85        48\n",
            "\n",
            "2/2 [==============================] - 2s 75ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 5s 130ms/step - loss: 1.0026 - accuracy: 0.8542\n",
            "7_Model evaluation:  [1.00259530544281, 0.8541666865348816]    Now ACC: 88.09571428571428\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.67      0.73         6\n",
            "     disgust       1.00      1.00      1.00         5\n",
            "        fear       1.00      0.75      0.86         8\n",
            "       happy       0.50      0.67      0.57         3\n",
            "     neutral       0.89      1.00      0.94         8\n",
            "         sad       0.78      0.88      0.82         8\n",
            "    surprise       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.85        48\n",
            "   macro avg       0.84      0.84      0.83        48\n",
            "weighted avg       0.87      0.85      0.86        48\n",
            "\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 81ms/step - loss: 1.0870 - accuracy: 0.8333\n",
            "8_Model evaluation:  [1.087006688117981, 0.8333333134651184]    Now ACC: 87.5\n",
            "2/2 [==============================] - 3s 116ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      1.00      0.89         4\n",
            "     disgust       1.00      0.50      0.67         4\n",
            "        fear       0.55      0.75      0.63         8\n",
            "       happy       0.89      0.73      0.80        11\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      1.00      1.00         4\n",
            "    surprise       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.83        48\n",
            "   macro avg       0.87      0.83      0.83        48\n",
            "weighted avg       0.86      0.83      0.83        48\n",
            "\n",
            "2/2 [==============================] - 3s 131ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 71ms/step - loss: 1.0964 - accuracy: 0.8750\n",
            "9_Model evaluation:  [1.0964230298995972, 0.875]    Now ACC: 87.5\n",
            "2/2 [==============================] - 2s 67ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.80      0.89        10\n",
            "     disgust       0.88      1.00      0.93         7\n",
            "        fear       1.00      0.80      0.89         5\n",
            "       happy       0.60      0.75      0.67         4\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      0.88      0.93         8\n",
            "    surprise       0.50      0.67      0.57         3\n",
            "\n",
            "    accuracy                           0.88        48\n",
            "   macro avg       0.84      0.84      0.83        48\n",
            "weighted avg       0.90      0.88      0.88        48\n",
            "\n",
            "2/2 [==============================] - 2s 119ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 73ms/step - loss: 1.0726 - accuracy: 0.8958\n",
            "10_Model evaluation:  [1.072625756263733, 0.8958333134651184]    Now ACC: 87.708\n",
            "2/2 [==============================] - 2s 67ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.80      0.80         5\n",
            "     disgust       0.90      1.00      0.95         9\n",
            "        fear       1.00      0.50      0.67         4\n",
            "       happy       0.83      0.83      0.83         6\n",
            "     neutral       1.00      1.00      1.00        12\n",
            "         sad       1.00      1.00      1.00         5\n",
            "    surprise       0.75      0.86      0.80         7\n",
            "\n",
            "    accuracy                           0.90        48\n",
            "   macro avg       0.90      0.86      0.86        48\n",
            "weighted avg       0.90      0.90      0.89        48\n",
            "\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "Average ACC: 0.8770833313465118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode test --data CASIA  --test_path ./Test_Models/CASIA_32 --split_fold 10 --random_seed 32"
      ],
      "metadata": {
        "id": "Dz0N89tTpgmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59b633c-765f-4e97-8cc1-be3ad809bcb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 17:44:18.948546: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 17:44:20.202855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "###gpus:[]\n",
            "TIMNET MODEL SHAPE: (172, 39)\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 4s 98ms/step - loss: 1.0349 - accuracy: 0.9583\n",
            "1_Model evaluation:  [1.0348995923995972, 0.9583333134651184]    Now ACC: 95.83\n",
            "4/4 [==============================] - 2s 93ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        20\n",
            "        fear       1.00      0.93      0.96        28\n",
            "       happy       0.92      0.96      0.94        23\n",
            "     neutral       1.00      1.00      1.00        14\n",
            "         sad       0.85      0.92      0.88        12\n",
            "    surprise       0.96      0.96      0.96        23\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.95      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "4/4 [==============================] - 2s 93ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 5s 169ms/step - loss: 0.9250 - accuracy: 0.9667\n",
            "2_Model evaluation:  [0.9249676465988159, 0.9666666388511658]    Now ACC: 96.25\n",
            "4/4 [==============================] - 3s 91ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.96      0.98        26\n",
            "        fear       1.00      0.95      0.97        19\n",
            "       happy       0.95      0.90      0.93        21\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      1.00      1.00        21\n",
            "    surprise       0.88      1.00      0.94        22\n",
            "\n",
            "    accuracy                           0.97       120\n",
            "   macro avg       0.97      0.97      0.97       120\n",
            "weighted avg       0.97      0.97      0.97       120\n",
            "\n",
            "4/4 [==============================] - 2s 90ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TIM-Net_SER/Code/main.py\", line 71, in <module>\n",
            "    x_feats, y_labels = model.test(x_source, y_source, path=args.test_path)# x_feats and y_labels are test datas for t-sne\n",
            "  File \"/content/TIM-Net_SER/Code/Model.py\", line 158, in test\n",
            "    self.model.load_weights(weight_path)#+source_name+'_single_best.hdf5')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\", line 567, in __init__\n",
            "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
            "    fid = h5f.open(name, flags, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
            "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = './Test_Models/CASIA_32/10-fold_weights_best_3.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode test --data EMODB  --test_path ./Test_Models/EMODB_46 --split_fold 10 --random_seed 46"
      ],
      "metadata": {
        "id": "UDurluC_phKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cecc29b-2e4a-45b9-8676-ecfc36f21b78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 17:44:53.500769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 17:44:55.116256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "###gpus:[]\n",
            "TIMNET MODEL SHAPE: (188, 39)\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 91ms/step - loss: 0.2783 - accuracy: 1.0000\n",
            "1_Model evaluation:  [0.2783001661300659, 1.0]    Now ACC: 100.0\n",
            "2/2 [==============================] - 2s 80ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        14\n",
            "     boredom       1.00      1.00      1.00         8\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         4\n",
            "       happy       1.00      1.00      1.00         6\n",
            "     neutral       1.00      1.00      1.00         6\n",
            "         sad       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n",
            "2/2 [==============================] - 2s 85ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 70ms/step - loss: 0.3815 - accuracy: 1.0000\n",
            "2_Model evaluation:  [0.3814920485019684, 1.0]    Now ACC: 100.0\n",
            "2/2 [==============================] - 2s 70ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         7\n",
            "     boredom       1.00      1.00      1.00        12\n",
            "     disgust       1.00      1.00      1.00         8\n",
            "        fear       1.00      1.00      1.00         9\n",
            "       happy       1.00      1.00      1.00         6\n",
            "     neutral       1.00      1.00      1.00         5\n",
            "         sad       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n",
            "2/2 [==============================] - 2s 69ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 181ms/step - loss: 0.5704 - accuracy: 0.9074\n",
            "3_Model evaluation:  [0.5704226493835449, 0.9074074029922485]    Now ACC: 96.91333333333334\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7655425c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7655425c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 131ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.93      1.00      0.96        13\n",
            "     boredom       1.00      0.75      0.86         8\n",
            "     disgust       1.00      0.80      0.89         5\n",
            "        fear       0.89      0.89      0.89         9\n",
            "       happy       0.86      1.00      0.92         6\n",
            "     neutral       0.78      0.88      0.82         8\n",
            "         sad       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.91        54\n",
            "   macro avg       0.92      0.90      0.91        54\n",
            "weighted avg       0.92      0.91      0.91        54\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7655426440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7655426440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 74ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 71ms/step - loss: 0.6386 - accuracy: 0.9444\n",
            "4_Model evaluation:  [0.6385939717292786, 0.9444444179534912]    Now ACC: 96.2975\n",
            "2/2 [==============================] - 2s 78ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.86      1.00      0.92        12\n",
            "     boredom       0.92      1.00      0.96        11\n",
            "     disgust       1.00      0.83      0.91         6\n",
            "        fear       1.00      1.00      1.00         8\n",
            "       happy       1.00      0.80      0.89         5\n",
            "     neutral       1.00      0.89      0.94         9\n",
            "         sad       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.94        54\n",
            "   macro avg       0.97      0.93      0.95        54\n",
            "weighted avg       0.95      0.94      0.94        54\n",
            "\n",
            "2/2 [==============================] - 3s 141ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7654925d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7654925d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 75ms/step - loss: 0.6638 - accuracy: 0.9444\n",
            "5_Model evaluation:  [0.6637794375419617, 0.9444444179534912]    Now ACC: 95.926\n",
            "2/2 [==============================] - 2s 70ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.94      0.97        18\n",
            "     boredom       1.00      0.86      0.92         7\n",
            "     disgust       1.00      1.00      1.00         2\n",
            "        fear       0.86      1.00      0.92         6\n",
            "       happy       0.89      0.89      0.89         9\n",
            "     neutral       0.86      1.00      0.92         6\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.94        54\n",
            "   macro avg       0.94      0.96      0.95        54\n",
            "weighted avg       0.95      0.94      0.94        54\n",
            "\n",
            "2/2 [==============================] - 2s 73ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7655427eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7655427eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 5s 141ms/step - loss: 0.7663 - accuracy: 0.9623\n",
            "6_Model evaluation:  [0.7662950754165649, 0.9622641801834106]    Now ACC: 95.97666666666667\n",
            "2/2 [==============================] - 2s 86ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      1.00      0.96        12\n",
            "     boredom       1.00      0.80      0.89         5\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         9\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.96        53\n",
            "   macro avg       0.98      0.95      0.96        53\n",
            "weighted avg       0.97      0.96      0.96        53\n",
            "\n",
            "2/2 [==============================] - 2s 65ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 76ms/step - loss: 0.9478 - accuracy: 0.9057\n",
            "7_Model evaluation:  [0.9477574825286865, 0.9056603908538818]    Now ACC: 95.20285714285714\n",
            "2/2 [==============================] - 4s 122ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.85      1.00      0.92        11\n",
            "     boredom       0.91      1.00      0.95        10\n",
            "     disgust       1.00      0.67      0.80         3\n",
            "        fear       0.88      1.00      0.93         7\n",
            "       happy       0.86      0.67      0.75         9\n",
            "     neutral       1.00      0.86      0.92         7\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.91        53\n",
            "   macro avg       0.93      0.88      0.90        53\n",
            "weighted avg       0.91      0.91      0.90        53\n",
            "\n",
            "2/2 [==============================] - 3s 67ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 73ms/step - loss: 0.8206 - accuracy: 0.9811\n",
            "8_Model evaluation:  [0.8205931782722473, 0.9811320900917053]    Now ACC: 95.5675\n",
            "2/2 [==============================] - 2s 70ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        17\n",
            "     boredom       1.00      0.75      0.86         4\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         7\n",
            "       happy       1.00      1.00      1.00         4\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "         sad       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.98        53\n",
            "   macro avg       0.98      0.96      0.97        53\n",
            "weighted avg       0.98      0.98      0.98        53\n",
            "\n",
            "2/2 [==============================] - 2s 75ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 5s 71ms/step - loss: 0.9167 - accuracy: 0.9434\n",
            "9_Model evaluation:  [0.9166657328605652, 0.9433962106704712]    Now ACC: 95.43\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        11\n",
            "     boredom       0.86      1.00      0.92         6\n",
            "     disgust       1.00      0.75      0.86         4\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       1.00      1.00      1.00        13\n",
            "     neutral       0.78      1.00      0.88         7\n",
            "         sad       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.94        53\n",
            "   macro avg       0.95      0.92      0.92        53\n",
            "weighted avg       0.95      0.94      0.94        53\n",
            "\n",
            "2/2 [==============================] - 2s 66ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 138ms/step - loss: 1.0000 - accuracy: 0.9811\n",
            "10_Model evaluation:  [0.9999573826789856, 0.9811320900917053]    Now ACC: 95.699\n",
            "2/2 [==============================] - 3s 117ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        12\n",
            "     boredom       0.91      1.00      0.95        10\n",
            "     disgust       1.00      1.00      1.00         6\n",
            "        fear       1.00      1.00      1.00         4\n",
            "       happy       1.00      1.00      1.00         7\n",
            "     neutral       1.00      0.91      0.95        11\n",
            "         sad       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.98        53\n",
            "   macro avg       0.99      0.99      0.99        53\n",
            "weighted avg       0.98      0.98      0.98        53\n",
            "\n",
            "2/2 [==============================] - 2s 69ms/step\n",
            "Average ACC: 0.9569881200790405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode test --data EMOVO  --test_path ./Test_Models/EMOVO_1 --split_fold 10 --random_seed 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXlLdoUqwb9w",
        "outputId": "0aad9984-eaba-45c7-d20d-3521f40eed3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 17:46:55.409772: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 17:46:56.645345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "###gpus:[]\n",
            "TIMNET MODEL SHAPE: (188, 39)\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 5s 176ms/step - loss: 1.0564 - accuracy: 0.9322\n",
            "1_Model evaluation:  [1.0563546419143677, 0.9322034120559692]    Now ACC: 93.22\n",
            "2/2 [==============================] - 2s 85ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.90      0.95        10\n",
            "     disgust       1.00      1.00      1.00        12\n",
            "        fear       0.92      1.00      0.96        11\n",
            "       happy       0.86      0.86      0.86         7\n",
            "     neutral       0.80      1.00      0.89         4\n",
            "         sad       1.00      1.00      1.00         7\n",
            "    surprise       0.86      0.75      0.80         8\n",
            "\n",
            "    accuracy                           0.93        59\n",
            "   macro avg       0.92      0.93      0.92        59\n",
            "weighted avg       0.93      0.93      0.93        59\n",
            "\n",
            "2/2 [==============================] - 2s 103ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 84ms/step - loss: 1.1231 - accuracy: 0.9492\n",
            "2_Model evaluation:  [1.123108983039856, 0.9491525292396545]    Now ACC: 94.07\n",
            "2/2 [==============================] - 3s 178ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         9\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         5\n",
            "       happy       1.00      0.62      0.77         8\n",
            "     neutral       0.92      1.00      0.96        12\n",
            "         sad       1.00      1.00      1.00         9\n",
            "    surprise       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.95        59\n",
            "   macro avg       0.97      0.95      0.95        59\n",
            "weighted avg       0.96      0.95      0.94        59\n",
            "\n",
            "2/2 [==============================] - 3s 165ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 85ms/step - loss: 1.2800 - accuracy: 0.9153\n",
            "3_Model evaluation:  [1.279953956604004, 0.9152542352676392]    Now ACC: 93.22000000000001\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57288e1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57288e1c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 85ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.92      0.96        13\n",
            "     disgust       0.67      1.00      0.80         6\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       1.00      1.00      1.00         8\n",
            "         sad       1.00      0.92      0.96        12\n",
            "    surprise       0.75      0.75      0.75         8\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.92      0.92      0.91        59\n",
            "weighted avg       0.93      0.92      0.92        59\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57288e2440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57288e2440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 85ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 5s 98ms/step - loss: 1.2502 - accuracy: 0.9153\n",
            "4_Model evaluation:  [1.2502334117889404, 0.9152542352676392]    Now ACC: 92.7975\n",
            "2/2 [==============================] - 2s 84ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.83      1.00      0.91         5\n",
            "     disgust       0.88      0.88      0.88         8\n",
            "        fear       1.00      0.80      0.89         5\n",
            "       happy       1.00      0.91      0.95        11\n",
            "     neutral       1.00      1.00      1.00         6\n",
            "         sad       1.00      1.00      1.00        15\n",
            "    surprise       0.70      0.78      0.74         9\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.92      0.91      0.91        59\n",
            "weighted avg       0.92      0.92      0.92        59\n",
            "\n",
            "2/2 [==============================] - 2s 82ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5728801d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5728801d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 138ms/step - loss: 1.3857 - accuracy: 0.8136\n",
            "5_Model evaluation:  [1.3856860399246216, 0.8135592937469482]    Now ACC: 90.50800000000001\n",
            "2/2 [==============================] - 3s 168ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      0.67      0.67         9\n",
            "     disgust       1.00      0.80      0.89        10\n",
            "        fear       0.70      0.78      0.74         9\n",
            "       happy       0.43      0.75      0.55         4\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      0.86      0.92         7\n",
            "    surprise       0.88      0.78      0.82         9\n",
            "\n",
            "    accuracy                           0.81        59\n",
            "   macro avg       0.81      0.80      0.80        59\n",
            "weighted avg       0.85      0.81      0.82        59\n",
            "\n",
            "2/2 [==============================] - 3s 82ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57288e3eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57288e3eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 89ms/step - loss: 1.3537 - accuracy: 0.9153\n",
            "6_Model evaluation:  [1.3537380695343018, 0.9152542352676392]    Now ACC: 90.67833333333334\n",
            "2/2 [==============================] - 2s 82ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      1.00      0.80         2\n",
            "     disgust       1.00      0.91      0.95        11\n",
            "        fear       1.00      0.90      0.95        10\n",
            "       happy       0.89      0.80      0.84        10\n",
            "     neutral       0.89      1.00      0.94         8\n",
            "         sad       1.00      1.00      1.00         9\n",
            "    surprise       0.80      0.89      0.84         9\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.89      0.93      0.90        59\n",
            "weighted avg       0.92      0.92      0.92        59\n",
            "\n",
            "2/2 [==============================] - 2s 164ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 93ms/step - loss: 1.3333 - accuracy: 0.9492\n",
            "7_Model evaluation:  [1.3332916498184204, 0.9491525292396545]    Now ACC: 91.28285714285714\n",
            "2/2 [==============================] - 3s 89ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        13\n",
            "     disgust       1.00      0.80      0.89        10\n",
            "        fear       1.00      1.00      1.00         8\n",
            "       happy       0.91      1.00      0.95        10\n",
            "     neutral       0.86      1.00      0.92         6\n",
            "         sad       0.80      1.00      0.89         4\n",
            "    surprise       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.95        59\n",
            "   macro avg       0.94      0.95      0.94        59\n",
            "weighted avg       0.96      0.95      0.95        59\n",
            "\n",
            "2/2 [==============================] - 2s 85ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 5s 145ms/step - loss: 1.3640 - accuracy: 0.9661\n",
            "8_Model evaluation:  [1.363973617553711, 0.9661017060279846]    Now ACC: 91.94875\n",
            "2/2 [==============================] - 3s 85ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         5\n",
            "     disgust       0.88      1.00      0.93         7\n",
            "        fear       1.00      0.88      0.93        16\n",
            "       happy       1.00      1.00      1.00         9\n",
            "     neutral       1.00      1.00      1.00         8\n",
            "         sad       0.86      1.00      0.92         6\n",
            "    surprise       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.97        59\n",
            "   macro avg       0.96      0.98      0.97        59\n",
            "weighted avg       0.97      0.97      0.97        59\n",
            "\n",
            "2/2 [==============================] - 2s 103ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 85ms/step - loss: 1.4110 - accuracy: 0.9310\n",
            "9_Model evaluation:  [1.411014199256897, 0.931034505367279]    Now ACC: 92.07777777777778\n",
            "2/2 [==============================] - 3s 162ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      1.00      0.89         8\n",
            "     disgust       1.00      1.00      1.00        10\n",
            "        fear       0.89      0.89      0.89         9\n",
            "       happy       1.00      0.88      0.93         8\n",
            "     neutral       1.00      0.92      0.96        12\n",
            "         sad       1.00      1.00      1.00         5\n",
            "    surprise       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.93        58\n",
            "   macro avg       0.93      0.93      0.93        58\n",
            "weighted avg       0.94      0.93      0.93        58\n",
            "\n",
            "2/2 [==============================] - 3s 137ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 90ms/step - loss: 1.5136 - accuracy: 0.9138\n",
            "10_Model evaluation:  [1.5136207342147827, 0.9137930870056152]    Now ACC: 92.00800000000001\n",
            "2/2 [==============================] - 2s 84ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.90      0.95        10\n",
            "     disgust       0.86      1.00      0.92         6\n",
            "        fear       0.83      1.00      0.91         5\n",
            "       happy       0.77      0.91      0.83        11\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "         sad       1.00      1.00      1.00        10\n",
            "    surprise       1.00      0.57      0.73         7\n",
            "\n",
            "    accuracy                           0.91        58\n",
            "   macro avg       0.92      0.91      0.91        58\n",
            "weighted avg       0.93      0.91      0.91        58\n",
            "\n",
            "2/2 [==============================] - 2s 83ms/step\n",
            "Average ACC: 0.9200759768486023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode test --data IEMOCAP  --test_path ./Test_Models/IEMOCAP_16 --split_fold 10 --random_seed 16\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvGV8JQxwYsP",
        "outputId": "b3b99cb5-03a0-4843-c620-80cbbd01d91a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 17:48:55.883157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 17:48:57.682660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "###gpus:[]\n",
            "TIMNET MODEL SHAPE: (606, 39)\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 19s 619ms/step - loss: 0.9190 - accuracy: 0.6895\n",
            "1_Model evaluation:  [0.9190255403518677, 0.6895306706428528]    Now ACC: 68.95\n",
            "18/18 [==============================] - 13s 559ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.70      0.75       122\n",
            "       happy       0.67      0.58      0.62       167\n",
            "     neutral       0.65      0.74      0.69       175\n",
            "         sad       0.67      0.78      0.72        90\n",
            "\n",
            "    accuracy                           0.69       554\n",
            "   macro avg       0.70      0.70      0.70       554\n",
            "weighted avg       0.69      0.69      0.69       554\n",
            "\n",
            "18/18 [==============================] - 10s 420ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 13s 511ms/step - loss: 0.7202 - accuracy: 0.7577\n",
            "2_Model evaluation:  [0.720224916934967, 0.7576853632926941]    Now ACC: 72.36\n",
            "18/18 [==============================] - 10s 409ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.76      0.73      0.74       117\n",
            "       happy       0.78      0.74      0.76       172\n",
            "     neutral       0.76      0.71      0.73       156\n",
            "         sad       0.72      0.89      0.80       108\n",
            "\n",
            "    accuracy                           0.76       553\n",
            "   macro avg       0.76      0.77      0.76       553\n",
            "weighted avg       0.76      0.76      0.76       553\n",
            "\n",
            "18/18 [==============================] - 13s 546ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 14s 506ms/step - loss: 0.8038 - accuracy: 0.7143\n",
            "3_Model evaluation:  [0.8038386106491089, 0.7142857313156128]    Now ACC: 72.05\n",
            "18/18 [==============================] - 14s 611ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.68      0.68      0.68        97\n",
            "       happy       0.85      0.53      0.65       165\n",
            "     neutral       0.68      0.82      0.74       185\n",
            "         sad       0.70      0.84      0.76       106\n",
            "\n",
            "    accuracy                           0.71       553\n",
            "   macro avg       0.73      0.72      0.71       553\n",
            "weighted avg       0.73      0.71      0.71       553\n",
            "\n",
            "18/18 [==============================] - 11s 427ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 13s 493ms/step - loss: 0.8555 - accuracy: 0.6998\n",
            "4_Model evaluation:  [0.8554527759552002, 0.6998191475868225]    Now ACC: 71.5325\n",
            "18/18 [==============================] - 11s 409ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.79      0.74      0.77       120\n",
            "       happy       0.69      0.63      0.66       171\n",
            "     neutral       0.61      0.65      0.63       150\n",
            "         sad       0.74      0.83      0.78       112\n",
            "\n",
            "    accuracy                           0.70       553\n",
            "   macro avg       0.71      0.71      0.71       553\n",
            "weighted avg       0.70      0.70      0.70       553\n",
            "\n",
            "18/18 [==============================] - 12s 460ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 13s 418ms/step - loss: 0.8448 - accuracy: 0.7197\n",
            "5_Model evaluation:  [0.844806969165802, 0.719710648059845]    Now ACC: 71.62\n",
            "18/18 [==============================] - 13s 542ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.74      0.75      0.75       114\n",
            "       happy       0.75      0.66      0.70       176\n",
            "     neutral       0.67      0.72      0.69       166\n",
            "         sad       0.75      0.78      0.76        97\n",
            "\n",
            "    accuracy                           0.72       553\n",
            "   macro avg       0.73      0.73      0.73       553\n",
            "weighted avg       0.72      0.72      0.72       553\n",
            "\n",
            "18/18 [==============================] - 13s 611ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 12s 422ms/step - loss: 0.8684 - accuracy: 0.7288\n",
            "6_Model evaluation:  [0.8684273362159729, 0.7287522554397583]    Now ACC: 71.83\n",
            "18/18 [==============================] - 12s 418ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.71      0.79      0.75       119\n",
            "       happy       0.77      0.61      0.68       157\n",
            "     neutral       0.70      0.75      0.72       167\n",
            "         sad       0.75      0.80      0.78       110\n",
            "\n",
            "    accuracy                           0.73       553\n",
            "   macro avg       0.73      0.74      0.73       553\n",
            "weighted avg       0.73      0.73      0.73       553\n",
            "\n",
            "18/18 [==============================] - 12s 508ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 14s 459ms/step - loss: 0.8847 - accuracy: 0.7161\n",
            "7_Model evaluation:  [0.8847178816795349, 0.7160940170288086]    Now ACC: 71.79857142857142\n",
            "18/18 [==============================] - 13s 605ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.65      0.72       101\n",
            "       happy       0.69      0.66      0.67       175\n",
            "     neutral       0.66      0.80      0.72       161\n",
            "         sad       0.81      0.75      0.78       116\n",
            "\n",
            "    accuracy                           0.72       553\n",
            "   macro avg       0.74      0.71      0.72       553\n",
            "weighted avg       0.72      0.72      0.72       553\n",
            "\n",
            "18/18 [==============================] - 11s 412ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 13s 416ms/step - loss: 0.9215 - accuracy: 0.6998\n",
            "8_Model evaluation:  [0.9214573502540588, 0.6998191475868225]    Now ACC: 71.57125\n",
            "18/18 [==============================] - 11s 405ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.81      0.69      0.74       105\n",
            "       happy       0.62      0.69      0.65       146\n",
            "     neutral       0.73      0.66      0.69       177\n",
            "         sad       0.69      0.78      0.73       125\n",
            "\n",
            "    accuracy                           0.70       553\n",
            "   macro avg       0.71      0.70      0.70       553\n",
            "weighted avg       0.71      0.70      0.70       553\n",
            "\n",
            "18/18 [==============================] - 13s 598ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 15s 572ms/step - loss: 0.9004 - accuracy: 0.7342\n",
            "9_Model evaluation:  [0.9004488587379456, 0.7341772317886353]    Now ACC: 71.77666666666667\n",
            "18/18 [==============================] - 12s 580ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.82      0.82      0.82       103\n",
            "       happy       0.65      0.68      0.66       158\n",
            "     neutral       0.69      0.72      0.70       180\n",
            "         sad       0.87      0.77      0.82       112\n",
            "\n",
            "    accuracy                           0.73       553\n",
            "   macro avg       0.76      0.74      0.75       553\n",
            "weighted avg       0.74      0.73      0.74       553\n",
            "\n",
            "18/18 [==============================] - 10s 412ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 14s 589ms/step - loss: 0.9784 - accuracy: 0.7052\n",
            "10_Model evaluation:  [0.9784132242202759, 0.7052441239356995]    Now ACC: 71.651\n",
            "18/18 [==============================] - 10s 411ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.82      0.72      0.77       105\n",
            "       happy       0.68      0.60      0.64       149\n",
            "     neutral       0.70      0.70      0.70       191\n",
            "         sad       0.65      0.84      0.74       108\n",
            "\n",
            "    accuracy                           0.71       553\n",
            "   macro avg       0.71      0.72      0.71       553\n",
            "weighted avg       0.71      0.71      0.70       553\n",
            "\n",
            "18/18 [==============================] - 11s 418ms/step\n",
            "Average ACC: 0.7165118336677552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py --mode test --data RAVDE  --test_path ./Test_Models/RAVDE_46 --split_fold 10 --random_seed 46"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDzn4mN7wi31",
        "outputId": "19c36a15-1531-4a3a-b238-e43666b8c388"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 17:57:04.255214: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 17:57:06.060163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "###gpus:[]\n",
            "TIMNET MODEL SHAPE: (215, 39)\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 4s 110ms/step - loss: 0.4587 - accuracy: 0.9306\n",
            "1_Model evaluation:  [0.45871469378471375, 0.9305555820465088]    Now ACC: 93.06\n",
            "5/5 [==============================] - 2s 108ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      1.00      0.94        24\n",
            "        calm       0.84      1.00      0.91        21\n",
            "     disgust       1.00      1.00      1.00        12\n",
            "        fear       0.94      0.85      0.89        20\n",
            "       happy       1.00      0.94      0.97        18\n",
            "     neutral       0.90      0.75      0.82        12\n",
            "         sad       0.93      0.93      0.93        15\n",
            "    surprise       1.00      0.91      0.95        22\n",
            "\n",
            "    accuracy                           0.93       144\n",
            "   macro avg       0.94      0.92      0.93       144\n",
            "weighted avg       0.94      0.93      0.93       144\n",
            "\n",
            "5/5 [==============================] - 4s 202ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 4s 107ms/step - loss: 0.5150 - accuracy: 0.9444\n",
            "2_Model evaluation:  [0.5150263905525208, 0.9444444179534912]    Now ACC: 93.75\n",
            "5/5 [==============================] - 3s 102ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.86      0.95      0.90        19\n",
            "        calm       1.00      1.00      1.00        24\n",
            "     disgust       0.91      0.95      0.93        22\n",
            "        fear       1.00      0.87      0.93        15\n",
            "       happy       1.00      0.89      0.94        18\n",
            "     neutral       1.00      1.00      1.00        10\n",
            "         sad       0.88      0.93      0.90        15\n",
            "    surprise       0.95      0.95      0.95        21\n",
            "\n",
            "    accuracy                           0.94       144\n",
            "   macro avg       0.95      0.94      0.94       144\n",
            "weighted avg       0.95      0.94      0.94       144\n",
            "\n",
            "5/5 [==============================] - 2s 107ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 5s 103ms/step - loss: 0.5885 - accuracy: 0.9306\n",
            "3_Model evaluation:  [0.5884856581687927, 0.9305555820465088]    Now ACC: 93.52\n",
            "5/5 [==============================] - 2s 100ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.94      0.91        17\n",
            "        calm       1.00      0.92      0.96        24\n",
            "     disgust       1.00      0.89      0.94        19\n",
            "        fear       0.92      1.00      0.96        24\n",
            "       happy       0.93      0.81      0.87        16\n",
            "     neutral       0.69      1.00      0.82         9\n",
            "         sad       0.94      0.94      0.94        18\n",
            "    surprise       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.93       144\n",
            "   macro avg       0.92      0.93      0.92       144\n",
            "weighted avg       0.94      0.93      0.93       144\n",
            "\n",
            "5/5 [==============================] - 2s 110ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 5s 191ms/step - loss: 0.5293 - accuracy: 0.9722\n",
            "4_Model evaluation:  [0.5293198227882385, 0.9722222089767456]    Now ACC: 94.445\n",
            "5/5 [==============================] - 3s 105ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      1.00      0.94        17\n",
            "        calm       0.95      1.00      0.97        18\n",
            "     disgust       1.00      0.91      0.95        23\n",
            "        fear       1.00      1.00      1.00        19\n",
            "       happy       0.96      1.00      0.98        24\n",
            "     neutral       1.00      1.00      1.00         4\n",
            "         sad       1.00      0.95      0.98        21\n",
            "    surprise       1.00      0.94      0.97        18\n",
            "\n",
            "    accuracy                           0.97       144\n",
            "   macro avg       0.98      0.98      0.97       144\n",
            "weighted avg       0.97      0.97      0.97       144\n",
            "\n",
            "5/5 [==============================] - 2s 107ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 3s 105ms/step - loss: 0.7704 - accuracy: 0.8889\n",
            "5_Model evaluation:  [0.7703957557678223, 0.8888888955116272]    Now ACC: 93.334\n",
            "5/5 [==============================] - 3s 202ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.95      0.95      0.95        19\n",
            "        calm       0.91      1.00      0.95        21\n",
            "     disgust       0.93      0.82      0.87        17\n",
            "        fear       0.88      0.82      0.85        17\n",
            "       happy       0.94      0.85      0.89        20\n",
            "     neutral       0.93      0.76      0.84        17\n",
            "         sad       0.70      1.00      0.83        19\n",
            "    surprise       1.00      0.86      0.92        14\n",
            "\n",
            "    accuracy                           0.89       144\n",
            "   macro avg       0.91      0.88      0.89       144\n",
            "weighted avg       0.90      0.89      0.89       144\n",
            "\n",
            "5/5 [==============================] - 4s 170ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 4s 106ms/step - loss: 0.8476 - accuracy: 0.9167\n",
            "6_Model evaluation:  [0.847649335861206, 0.9166666865348816]    Now ACC: 93.055\n",
            "5/5 [==============================] - 2s 106ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.86      0.93        22\n",
            "        calm       0.94      0.94      0.94        18\n",
            "     disgust       0.95      1.00      0.97        19\n",
            "        fear       0.73      1.00      0.84         8\n",
            "       happy       0.85      0.85      0.85        20\n",
            "     neutral       1.00      1.00      1.00         8\n",
            "         sad       0.89      0.94      0.92        18\n",
            "    surprise       0.93      0.87      0.90        31\n",
            "\n",
            "    accuracy                           0.92       144\n",
            "   macro avg       0.91      0.93      0.92       144\n",
            "weighted avg       0.92      0.92      0.92       144\n",
            "\n",
            "5/5 [==============================] - 3s 204ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 4s 104ms/step - loss: 0.9328 - accuracy: 0.8958\n",
            "7_Model evaluation:  [0.9328033924102783, 0.8958333134651184]    Now ACC: 92.55999999999999\n",
            "5/5 [==============================] - 3s 106ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.89      0.89        19\n",
            "        calm       1.00      0.95      0.97        20\n",
            "     disgust       1.00      1.00      1.00        14\n",
            "        fear       0.90      0.96      0.93        28\n",
            "       happy       0.82      0.64      0.72        14\n",
            "     neutral       0.69      1.00      0.81        11\n",
            "         sad       0.95      0.87      0.91        23\n",
            "    surprise       0.86      0.80      0.83        15\n",
            "\n",
            "    accuracy                           0.90       144\n",
            "   macro avg       0.89      0.89      0.88       144\n",
            "weighted avg       0.90      0.90      0.90       144\n",
            "\n",
            "5/5 [==============================] - 2s 104ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 5s 106ms/step - loss: 0.9257 - accuracy: 0.9167\n",
            "8_Model evaluation:  [0.9256696701049805, 0.9166666865348816]    Now ACC: 92.4475\n",
            "5/5 [==============================] - 2s 103ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.90      1.00      0.95        19\n",
            "        calm       0.96      0.96      0.96        25\n",
            "     disgust       1.00      0.92      0.96        13\n",
            "        fear       0.83      0.88      0.86        17\n",
            "       happy       0.94      0.80      0.86        20\n",
            "     neutral       0.75      0.90      0.82        10\n",
            "         sad       0.91      0.91      0.91        23\n",
            "    surprise       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.92       144\n",
            "   macro avg       0.91      0.91      0.91       144\n",
            "weighted avg       0.92      0.92      0.92       144\n",
            "\n",
            "5/5 [==============================] - 2s 101ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 6s 210ms/step - loss: 1.0318 - accuracy: 0.9097\n",
            "9_Model evaluation:  [1.0317704677581787, 0.9097222089767456]    Now ACC: 92.28444444444443\n",
            "5/5 [==============================] - 3s 106ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        18\n",
            "        calm       0.90      0.90      0.90        10\n",
            "     disgust       0.96      0.93      0.95        28\n",
            "        fear       1.00      0.95      0.98        21\n",
            "       happy       0.94      0.71      0.81        21\n",
            "     neutral       0.75      0.86      0.80         7\n",
            "         sad       0.91      0.95      0.93        22\n",
            "    surprise       0.73      0.94      0.82        17\n",
            "\n",
            "    accuracy                           0.91       144\n",
            "   macro avg       0.90      0.91      0.90       144\n",
            "weighted avg       0.92      0.91      0.91       144\n",
            "\n",
            "5/5 [==============================] - 2s 113ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 3s 104ms/step - loss: 1.0372 - accuracy: 0.9028\n",
            "10_Model evaluation:  [1.0371534824371338, 0.9027777910232544]    Now ACC: 92.083\n",
            "5/5 [==============================] - 3s 211ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.85      0.94      0.89        18\n",
            "        calm       0.71      0.91      0.80        11\n",
            "     disgust       0.96      1.00      0.98        25\n",
            "        fear       0.96      0.96      0.96        23\n",
            "       happy       1.00      0.86      0.92        21\n",
            "     neutral       0.58      0.88      0.70         8\n",
            "         sad       1.00      0.78      0.88        18\n",
            "    surprise       1.00      0.85      0.92        20\n",
            "\n",
            "    accuracy                           0.90       144\n",
            "   macro avg       0.88      0.90      0.88       144\n",
            "weighted avg       0.92      0.90      0.91       144\n",
            "\n",
            "5/5 [==============================] - 3s 102ms/step\n",
            "Average ACC: 0.9208333373069764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXFlIJ--wldA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}