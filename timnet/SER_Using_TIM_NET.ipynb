{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedFarzin/Speech-Emotion-Recognition-using-TIM-Net/blob/main/SER_Using_TIM_NET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNN8Ns3M5OxV"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Github cloning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SUe7NSLm5Qtn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start recording....\n",
            "Start stopped.\n"
          ]
        }
      ],
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "\n",
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 1\n",
        "RATE = 22050\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
        "\n",
        "print(\"start recording....\")\n",
        "\n",
        "frames = []\n",
        "seconds = 5\n",
        "for i in range(0, int(RATE / CHUNK * seconds)):\n",
        "\tdata = stream.read(CHUNK)\n",
        "\tframes.append(data)\n",
        " \n",
        "print('Start stopped.')\n",
        "\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate() \n",
        "\n",
        "wf = wave.open('output.wav', 'wb')\n",
        "wf.setnchannels(CHANNELS)\n",
        "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "wf.setframerate(RATE)\n",
        "wf.writeframes(b''.join(frames))\n",
        "wf.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8SyhTMTT-yG",
        "outputId": "d7ab8e27-25bd-44be-c492-1599ce82387d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'TIM-Net_SER'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 139 (delta 50), reused 106 (delta 35), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (139/139), 2.66 MiB | 17.83 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Jiaxin-Ye/TIM-Net_SER.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0bAoiQwUPEl",
        "outputId": "ad5204aa-beb0-44e3-8c87-0edee6489d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/TIM-Net_SER/Code\n"
          ]
        }
      ],
      "source": [
        "%cd TIM-Net_SER/Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6HnzLm9TUTch"
      },
      "outputs": [],
      "source": [
        "# !pip install virtualenv\n",
        "# !virtualenv tim-net\n",
        "# !source tim-net/bin/activate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2AW8qoO5bFy"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LUeWFeibrCqS"
      },
      "outputs": [],
      "source": [
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t3QHBkLfUduC"
      },
      "outputs": [],
      "source": [
        "def get_features(file_path: str, mfcc_len: int=39, mean_signal_length: int = 100000):\n",
        "  \"\"\"\n",
        "  file_path : Speech signal folder\n",
        "  mfcc_len : MFCC coefficient length\n",
        "  mean_signal_length : MFCC feature average length\n",
        "  \"\"\"\n",
        "\n",
        "  signal, fs = librosa.load(file_path)\n",
        "  s_len = len(signal)\n",
        "\n",
        "  if s_len < mean_signal_length:\n",
        "    pad_length = mean_signal_length - s_len\n",
        "    pad_reminder = pad_length % 2\n",
        "    pad_length //= 2\n",
        "  else:\n",
        "    pad_length = s_len - mean_signal_length\n",
        "    pad_reminder = pad_length % 2\n",
        "    pad_length //= 2\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=39)\n",
        "  mfcc = mfcc.T\n",
        "  feature = mfcc\n",
        "  return feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWxwuD3I5vdu"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVBJXHtNUi3X",
        "outputId": "f0c7aa34-6ed2-45d4-8281-a9d60f1d9944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3499 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.3499 - accuracy: 1.0000 - val_loss: 1.3981 - val_accuracy: 0.9245\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3500 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.3500 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.9245\n",
            "Epoch 287/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.3495 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.3499 - accuracy: 1.0000 - val_loss: 1.4001 - val_accuracy: 0.9245\n",
            "Epoch 288/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.3496 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.3498 - accuracy: 1.0000 - val_loss: 1.4031 - val_accuracy: 0.9245\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3485 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.3485 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.9245\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.3494 - accuracy: 1.0000 - val_loss: 1.4207 - val_accuracy: 0.9245\n",
            "Epoch 291/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.3497 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.3491 - accuracy: 1.0000 - val_loss: 1.4070 - val_accuracy: 0.9245\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3489 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.3489 - accuracy: 1.0000 - val_loss: 1.4151 - val_accuracy: 0.9245\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3497 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.3497 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.9245\n",
            "Epoch 294/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.3490 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.3484 - accuracy: 1.0000 - val_loss: 1.4194 - val_accuracy: 0.9245\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3499 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.3499 - accuracy: 1.0000 - val_loss: 1.4017 - val_accuracy: 0.9245\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3496 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.3496 - accuracy: 1.0000 - val_loss: 1.4195 - val_accuracy: 0.9057\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3507 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.3507 - accuracy: 1.0000 - val_loss: 1.3908 - val_accuracy: 0.9245\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3489 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.3489 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.9245\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3512 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.3512 - accuracy: 1.0000 - val_loss: 1.3916 - val_accuracy: 0.9245\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.3489 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.3489 - accuracy: 1.0000 - val_loss: 1.4032 - val_accuracy: 0.9245\n",
            "2/2 [==============================] - 0s 455ms/step - loss: 1.4507 - accuracy: 0.9434\n",
            "6_Model evaluation:  [1.4506750106811523, 0.9433962106704712]    Now ACC: 92.88333333333333\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2901829e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      1.00      0.96        12\n",
            "     boredom       1.00      0.80      0.89         5\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         9\n",
            "       happy       1.00      0.67      0.80         6\n",
            "     neutral       0.85      1.00      0.92        11\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.94        53\n",
            "   macro avg       0.97      0.92      0.94        53\n",
            "weighted avg       0.95      0.94      0.94        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 4.6084 - accuracy: 0.1286\n",
            "Epoch 1: val_accuracy improved from -inf to 0.20755, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 34s 426ms/step - loss: 4.6084 - accuracy: 0.1286 - val_loss: 3.0321 - val_accuracy: 0.2075\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2229 - accuracy: 0.2573\n",
            "Epoch 2: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 2.2229 - accuracy: 0.2573 - val_loss: 2.3414 - val_accuracy: 0.1321\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9608 - accuracy: 0.2178\n",
            "Epoch 3: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.9608 - accuracy: 0.2178 - val_loss: 2.2875 - val_accuracy: 0.0943\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0126 - accuracy: 0.1390\n",
            "Epoch 4: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 2.0126 - accuracy: 0.1390 - val_loss: 2.0966 - val_accuracy: 0.1698\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9643 - accuracy: 0.1909\n",
            "Epoch 5: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.9643 - accuracy: 0.1909 - val_loss: 2.1968 - val_accuracy: 0.2075\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9047 - accuracy: 0.3382\n",
            "Epoch 6: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.9047 - accuracy: 0.3382 - val_loss: 2.3803 - val_accuracy: 0.2075\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8660 - accuracy: 0.4315\n",
            "Epoch 7: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 1.8660 - accuracy: 0.4315 - val_loss: 2.4287 - val_accuracy: 0.2075\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8549 - accuracy: 0.4212\n",
            "Epoch 8: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.8549 - accuracy: 0.4212 - val_loss: 2.3429 - val_accuracy: 0.2075\n",
            "Epoch 9/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8416 - accuracy: 0.4174\n",
            "Epoch 9: val_accuracy did not improve from 0.20755\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.8404 - accuracy: 0.4212 - val_loss: 2.2153 - val_accuracy: 0.2075\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8254 - accuracy: 0.4523\n",
            "Epoch 10: val_accuracy improved from 0.20755 to 0.22642, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.8254 - accuracy: 0.4523 - val_loss: 2.1213 - val_accuracy: 0.2264\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8100 - accuracy: 0.5021\n",
            "Epoch 11: val_accuracy improved from 0.22642 to 0.24528, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.8100 - accuracy: 0.5021 - val_loss: 2.0763 - val_accuracy: 0.2453\n",
            "Epoch 12/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7991 - accuracy: 0.5134\n",
            "Epoch 12: val_accuracy improved from 0.24528 to 0.32075, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7977 - accuracy: 0.5124 - val_loss: 2.0447 - val_accuracy: 0.3208\n",
            "Epoch 13/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7856 - accuracy: 0.5089\n",
            "Epoch 13: val_accuracy improved from 0.32075 to 0.33962, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.7814 - accuracy: 0.5270 - val_loss: 2.0195 - val_accuracy: 0.3396\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7750 - accuracy: 0.5311\n",
            "Epoch 14: val_accuracy improved from 0.33962 to 0.35849, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7750 - accuracy: 0.5311 - val_loss: 1.9923 - val_accuracy: 0.3585\n",
            "Epoch 15/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7644 - accuracy: 0.5603\n",
            "Epoch 15: val_accuracy improved from 0.35849 to 0.39623, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7610 - accuracy: 0.5622 - val_loss: 1.9712 - val_accuracy: 0.3962\n",
            "Epoch 16/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7546 - accuracy: 0.5737\n",
            "Epoch 16: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7563 - accuracy: 0.5726 - val_loss: 1.9696 - val_accuracy: 0.3962\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7420 - accuracy: 0.5892\n",
            "Epoch 17: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7420 - accuracy: 0.5892 - val_loss: 1.9542 - val_accuracy: 0.3962\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7359 - accuracy: 0.6058\n",
            "Epoch 18: val_accuracy improved from 0.39623 to 0.41509, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7359 - accuracy: 0.6058 - val_loss: 1.9244 - val_accuracy: 0.4151\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7287 - accuracy: 0.6266\n",
            "Epoch 19: val_accuracy improved from 0.41509 to 0.43396, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7287 - accuracy: 0.6266 - val_loss: 1.9006 - val_accuracy: 0.4340\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7191 - accuracy: 0.6224\n",
            "Epoch 20: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7191 - accuracy: 0.6224 - val_loss: 1.8785 - val_accuracy: 0.4340\n",
            "Epoch 21/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7124 - accuracy: 0.6429\n",
            "Epoch 21: val_accuracy improved from 0.43396 to 0.45283, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7093 - accuracy: 0.6515 - val_loss: 1.8652 - val_accuracy: 0.4528\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7052 - accuracy: 0.6452\n",
            "Epoch 22: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7052 - accuracy: 0.6452 - val_loss: 1.8317 - val_accuracy: 0.4528\n",
            "Epoch 23/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6947 - accuracy: 0.6719\n",
            "Epoch 23: val_accuracy improved from 0.45283 to 0.47170, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6938 - accuracy: 0.6763 - val_loss: 1.8075 - val_accuracy: 0.4717\n",
            "Epoch 24/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6929 - accuracy: 0.6562\n",
            "Epoch 24: val_accuracy did not improve from 0.47170\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6925 - accuracy: 0.6535 - val_loss: 1.8042 - val_accuracy: 0.4528\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6814 - accuracy: 0.6763\n",
            "Epoch 25: val_accuracy did not improve from 0.47170\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6814 - accuracy: 0.6763 - val_loss: 1.7858 - val_accuracy: 0.4717\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6689 - accuracy: 0.7012\n",
            "Epoch 26: val_accuracy did not improve from 0.47170\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6689 - accuracy: 0.7012 - val_loss: 1.7685 - val_accuracy: 0.4717\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6715 - accuracy: 0.7033\n",
            "Epoch 27: val_accuracy improved from 0.47170 to 0.50943, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 1.6715 - accuracy: 0.7033 - val_loss: 1.7590 - val_accuracy: 0.5094\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6643 - accuracy: 0.7158\n",
            "Epoch 28: val_accuracy improved from 0.50943 to 0.52830, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 111ms/step - loss: 1.6643 - accuracy: 0.7158 - val_loss: 1.7540 - val_accuracy: 0.5283\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6570 - accuracy: 0.7386\n",
            "Epoch 29: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6570 - accuracy: 0.7386 - val_loss: 1.7463 - val_accuracy: 0.5094\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6514 - accuracy: 0.7697\n",
            "Epoch 30: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6514 - accuracy: 0.7697 - val_loss: 1.7443 - val_accuracy: 0.4717\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6513 - accuracy: 0.7448\n",
            "Epoch 31: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.6513 - accuracy: 0.7448 - val_loss: 1.7363 - val_accuracy: 0.5094\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6432 - accuracy: 0.7697\n",
            "Epoch 32: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 1.6432 - accuracy: 0.7697 - val_loss: 1.7409 - val_accuracy: 0.5283\n",
            "Epoch 33/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6376 - accuracy: 0.7768\n",
            "Epoch 33: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6349 - accuracy: 0.7842 - val_loss: 1.7639 - val_accuracy: 0.4906\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6358 - accuracy: 0.7946\n",
            "Epoch 34: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6358 - accuracy: 0.7946 - val_loss: 1.7476 - val_accuracy: 0.4906\n",
            "Epoch 35/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6276 - accuracy: 0.7857\n",
            "Epoch 35: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6282 - accuracy: 0.7884 - val_loss: 1.7507 - val_accuracy: 0.4906\n",
            "Epoch 36/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6224 - accuracy: 0.7902\n",
            "Epoch 36: val_accuracy improved from 0.52830 to 0.54717, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6244 - accuracy: 0.7905 - val_loss: 1.7345 - val_accuracy: 0.5472\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6213 - accuracy: 0.8154\n",
            "Epoch 37: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6213 - accuracy: 0.8154 - val_loss: 1.7093 - val_accuracy: 0.5283\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6189 - accuracy: 0.8382\n",
            "Epoch 38: val_accuracy improved from 0.54717 to 0.56604, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6189 - accuracy: 0.8382 - val_loss: 1.6901 - val_accuracy: 0.5660\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6128 - accuracy: 0.8154\n",
            "Epoch 39: val_accuracy did not improve from 0.56604\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6128 - accuracy: 0.8154 - val_loss: 1.6994 - val_accuracy: 0.5283\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6140 - accuracy: 0.8382\n",
            "Epoch 40: val_accuracy did not improve from 0.56604\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.6140 - accuracy: 0.8382 - val_loss: 1.6908 - val_accuracy: 0.5472\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6048 - accuracy: 0.8237\n",
            "Epoch 41: val_accuracy did not improve from 0.56604\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6048 - accuracy: 0.8237 - val_loss: 1.7001 - val_accuracy: 0.4906\n",
            "Epoch 42/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5998 - accuracy: 0.8438\n",
            "Epoch 42: val_accuracy did not improve from 0.56604\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6003 - accuracy: 0.8444 - val_loss: 1.6867 - val_accuracy: 0.5283\n",
            "Epoch 43/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5975 - accuracy: 0.8527\n",
            "Epoch 43: val_accuracy improved from 0.56604 to 0.62264, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5989 - accuracy: 0.8527 - val_loss: 1.6664 - val_accuracy: 0.6226\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5915 - accuracy: 0.8320\n",
            "Epoch 44: val_accuracy improved from 0.62264 to 0.64151, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.5915 - accuracy: 0.8320 - val_loss: 1.6671 - val_accuracy: 0.6415\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5864 - accuracy: 0.8776\n",
            "Epoch 45: val_accuracy improved from 0.64151 to 0.66038, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5864 - accuracy: 0.8776 - val_loss: 1.6507 - val_accuracy: 0.6604\n",
            "Epoch 46/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5867 - accuracy: 0.8482\n",
            "Epoch 46: val_accuracy improved from 0.66038 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5886 - accuracy: 0.8444 - val_loss: 1.6321 - val_accuracy: 0.7170\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5953 - accuracy: 0.8527\n",
            "Epoch 47: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5953 - accuracy: 0.8527 - val_loss: 1.6338 - val_accuracy: 0.7170\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5786 - accuracy: 0.8817\n",
            "Epoch 48: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5786 - accuracy: 0.8817 - val_loss: 1.6415 - val_accuracy: 0.6792\n",
            "Epoch 49/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5765 - accuracy: 0.8795\n",
            "Epoch 49: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5773 - accuracy: 0.8776 - val_loss: 1.6568 - val_accuracy: 0.6226\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5791 - accuracy: 0.8651\n",
            "Epoch 50: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 1.5791 - accuracy: 0.8651 - val_loss: 1.6523 - val_accuracy: 0.6415\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5824 - accuracy: 0.8755\n",
            "Epoch 51: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5824 - accuracy: 0.8755 - val_loss: 1.6705 - val_accuracy: 0.6415\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5751 - accuracy: 0.8776\n",
            "Epoch 52: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5751 - accuracy: 0.8776 - val_loss: 1.7175 - val_accuracy: 0.6415\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5669 - accuracy: 0.8880\n",
            "Epoch 53: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5669 - accuracy: 0.8880 - val_loss: 1.6926 - val_accuracy: 0.6792\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5649 - accuracy: 0.8942\n",
            "Epoch 54: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.5649 - accuracy: 0.8942 - val_loss: 1.6285 - val_accuracy: 0.6981\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5588 - accuracy: 0.9087\n",
            "Epoch 55: val_accuracy improved from 0.71698 to 0.75472, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 1.5588 - accuracy: 0.9087 - val_loss: 1.6076 - val_accuracy: 0.7547\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5614 - accuracy: 0.9046\n",
            "Epoch 56: val_accuracy improved from 0.75472 to 0.77358, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.5614 - accuracy: 0.9046 - val_loss: 1.6174 - val_accuracy: 0.7736\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5617 - accuracy: 0.9108\n",
            "Epoch 57: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5617 - accuracy: 0.9108 - val_loss: 1.6487 - val_accuracy: 0.7170\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5466 - accuracy: 0.9398\n",
            "Epoch 58: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5466 - accuracy: 0.9398 - val_loss: 1.6740 - val_accuracy: 0.6792\n",
            "Epoch 59/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5570 - accuracy: 0.8996\n",
            "Epoch 59: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5576 - accuracy: 0.8983 - val_loss: 1.7221 - val_accuracy: 0.6604\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5544 - accuracy: 0.9108\n",
            "Epoch 60: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5544 - accuracy: 0.9108 - val_loss: 1.6972 - val_accuracy: 0.6792\n",
            "Epoch 61/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5503 - accuracy: 0.9174\n",
            "Epoch 61: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5490 - accuracy: 0.9191 - val_loss: 1.6428 - val_accuracy: 0.7170\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5551 - accuracy: 0.9004\n",
            "Epoch 62: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5551 - accuracy: 0.9004 - val_loss: 1.6258 - val_accuracy: 0.7358\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5504 - accuracy: 0.9108\n",
            "Epoch 63: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5504 - accuracy: 0.9108 - val_loss: 1.6280 - val_accuracy: 0.7547\n",
            "Epoch 64/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5492 - accuracy: 0.9196\n",
            "Epoch 64: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5483 - accuracy: 0.9253 - val_loss: 1.6162 - val_accuracy: 0.7547\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5366 - accuracy: 0.9232\n",
            "Epoch 65: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5366 - accuracy: 0.9232 - val_loss: 1.6157 - val_accuracy: 0.7736\n",
            "Epoch 66/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5379 - accuracy: 0.9308\n",
            "Epoch 66: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5391 - accuracy: 0.9315 - val_loss: 1.6195 - val_accuracy: 0.7736\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5438 - accuracy: 0.9440\n",
            "Epoch 67: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5438 - accuracy: 0.9440 - val_loss: 1.6198 - val_accuracy: 0.7547\n",
            "Epoch 68/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5371 - accuracy: 0.9397\n",
            "Epoch 68: val_accuracy improved from 0.77358 to 0.81132, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5381 - accuracy: 0.9357 - val_loss: 1.6030 - val_accuracy: 0.8113\n",
            "Epoch 69/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5355 - accuracy: 0.9397\n",
            "Epoch 69: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5349 - accuracy: 0.9419 - val_loss: 1.5998 - val_accuracy: 0.7736\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5305 - accuracy: 0.9419\n",
            "Epoch 70: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5305 - accuracy: 0.9419 - val_loss: 1.6063 - val_accuracy: 0.7925\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 0.9419\n",
            "Epoch 71: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5337 - accuracy: 0.9419 - val_loss: 1.6154 - val_accuracy: 0.7547\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5277 - accuracy: 0.9419\n",
            "Epoch 72: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5277 - accuracy: 0.9419 - val_loss: 1.6192 - val_accuracy: 0.7358\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5226 - accuracy: 0.9461\n",
            "Epoch 73: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5226 - accuracy: 0.9461 - val_loss: 1.6077 - val_accuracy: 0.7736\n",
            "Epoch 74/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5244 - accuracy: 0.9442\n",
            "Epoch 74: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5239 - accuracy: 0.9481 - val_loss: 1.6060 - val_accuracy: 0.7736\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 0.9523\n",
            "Epoch 75: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5255 - accuracy: 0.9523 - val_loss: 1.5922 - val_accuracy: 0.8113\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5180 - accuracy: 0.9523\n",
            "Epoch 76: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5180 - accuracy: 0.9523 - val_loss: 1.5964 - val_accuracy: 0.7736\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5205 - accuracy: 0.9544\n",
            "Epoch 77: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5205 - accuracy: 0.9544 - val_loss: 1.6003 - val_accuracy: 0.8113\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5132 - accuracy: 0.9668\n",
            "Epoch 78: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5132 - accuracy: 0.9668 - val_loss: 1.5998 - val_accuracy: 0.7925\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5122 - accuracy: 0.9606\n",
            "Epoch 79: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5122 - accuracy: 0.9606 - val_loss: 1.5951 - val_accuracy: 0.7925\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5138 - accuracy: 0.9627\n",
            "Epoch 80: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5138 - accuracy: 0.9627 - val_loss: 1.6028 - val_accuracy: 0.7736\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5208 - accuracy: 0.9710\n",
            "Epoch 81: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5208 - accuracy: 0.9710 - val_loss: 1.6134 - val_accuracy: 0.7547\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5103 - accuracy: 0.9668\n",
            "Epoch 82: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5103 - accuracy: 0.9668 - val_loss: 1.6029 - val_accuracy: 0.8113\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5147 - accuracy: 0.9585\n",
            "Epoch 83: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5147 - accuracy: 0.9585 - val_loss: 1.6028 - val_accuracy: 0.7736\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5067 - accuracy: 0.9730\n",
            "Epoch 84: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5067 - accuracy: 0.9730 - val_loss: 1.5996 - val_accuracy: 0.8113\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5120 - accuracy: 0.9647\n",
            "Epoch 85: val_accuracy improved from 0.81132 to 0.83019, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5120 - accuracy: 0.9647 - val_loss: 1.5985 - val_accuracy: 0.8302\n",
            "Epoch 86/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5039 - accuracy: 0.9732\n",
            "Epoch 86: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5058 - accuracy: 0.9668 - val_loss: 1.5964 - val_accuracy: 0.8113\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5067 - accuracy: 0.9606\n",
            "Epoch 87: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5067 - accuracy: 0.9606 - val_loss: 1.5972 - val_accuracy: 0.7925\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5030 - accuracy: 0.9730\n",
            "Epoch 88: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5030 - accuracy: 0.9730 - val_loss: 1.6050 - val_accuracy: 0.8113\n",
            "Epoch 89/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5028 - accuracy: 0.9710\n",
            "Epoch 89: val_accuracy improved from 0.83019 to 0.84906, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.5043 - accuracy: 0.9668 - val_loss: 1.6030 - val_accuracy: 0.8491\n",
            "Epoch 90/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4999 - accuracy: 0.9888\n",
            "Epoch 90: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5021 - accuracy: 0.9855 - val_loss: 1.6018 - val_accuracy: 0.8302\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5023 - accuracy: 0.9730\n",
            "Epoch 91: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5023 - accuracy: 0.9730 - val_loss: 1.6051 - val_accuracy: 0.7736\n",
            "Epoch 92/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5007 - accuracy: 0.9821\n",
            "Epoch 92: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5019 - accuracy: 0.9793 - val_loss: 1.6004 - val_accuracy: 0.8113\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4979 - accuracy: 0.9772\n",
            "Epoch 93: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4979 - accuracy: 0.9772 - val_loss: 1.6095 - val_accuracy: 0.7736\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5012 - accuracy: 0.9689\n",
            "Epoch 94: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5012 - accuracy: 0.9689 - val_loss: 1.5975 - val_accuracy: 0.7736\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4991 - accuracy: 0.9772\n",
            "Epoch 95: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4991 - accuracy: 0.9772 - val_loss: 1.6060 - val_accuracy: 0.7547\n",
            "Epoch 96/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4943 - accuracy: 0.9821\n",
            "Epoch 96: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4966 - accuracy: 0.9813 - val_loss: 1.6114 - val_accuracy: 0.7358\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4925 - accuracy: 0.9896\n",
            "Epoch 97: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4925 - accuracy: 0.9896 - val_loss: 1.5984 - val_accuracy: 0.7547\n",
            "Epoch 98/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4904 - accuracy: 0.9866\n",
            "Epoch 98: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4913 - accuracy: 0.9855 - val_loss: 1.6001 - val_accuracy: 0.7925\n",
            "Epoch 99/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4934 - accuracy: 0.9888\n",
            "Epoch 99: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4939 - accuracy: 0.9876 - val_loss: 1.6024 - val_accuracy: 0.7925\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4878 - accuracy: 0.9855\n",
            "Epoch 100: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4878 - accuracy: 0.9855 - val_loss: 1.6119 - val_accuracy: 0.7547\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4867 - accuracy: 0.9813\n",
            "Epoch 101: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.4867 - accuracy: 0.9813 - val_loss: 1.6028 - val_accuracy: 0.7547\n",
            "Epoch 102/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4889 - accuracy: 0.9933\n",
            "Epoch 102: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4921 - accuracy: 0.9917 - val_loss: 1.5925 - val_accuracy: 0.7736\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4872 - accuracy: 0.9855\n",
            "Epoch 103: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4872 - accuracy: 0.9855 - val_loss: 1.6074 - val_accuracy: 0.7736\n",
            "Epoch 104/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4947 - accuracy: 0.9777\n",
            "Epoch 104: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4938 - accuracy: 0.9793 - val_loss: 1.6145 - val_accuracy: 0.7925\n",
            "Epoch 105/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4839 - accuracy: 0.9933\n",
            "Epoch 105: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4859 - accuracy: 0.9896 - val_loss: 1.6111 - val_accuracy: 0.7925\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4838 - accuracy: 0.9917\n",
            "Epoch 106: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.4838 - accuracy: 0.9917 - val_loss: 1.6138 - val_accuracy: 0.8113\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4837 - accuracy: 0.9896\n",
            "Epoch 107: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.4837 - accuracy: 0.9896 - val_loss: 1.5998 - val_accuracy: 0.7925\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4921 - accuracy: 0.9751\n",
            "Epoch 108: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.4921 - accuracy: 0.9751 - val_loss: 1.5939 - val_accuracy: 0.7925\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4848 - accuracy: 0.9834\n",
            "Epoch 109: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.4848 - accuracy: 0.9834 - val_loss: 1.5948 - val_accuracy: 0.7736\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4847 - accuracy: 0.9896\n",
            "Epoch 110: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.4847 - accuracy: 0.9896 - val_loss: 1.5950 - val_accuracy: 0.7925\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4822 - accuracy: 0.9979\n",
            "Epoch 111: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.4822 - accuracy: 0.9979 - val_loss: 1.5971 - val_accuracy: 0.8113\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4835 - accuracy: 0.9917\n",
            "Epoch 112: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4835 - accuracy: 0.9917 - val_loss: 1.5880 - val_accuracy: 0.8113\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4835 - accuracy: 0.9959\n",
            "Epoch 113: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4835 - accuracy: 0.9959 - val_loss: 1.5872 - val_accuracy: 0.8113\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4830 - accuracy: 0.9917\n",
            "Epoch 114: val_accuracy improved from 0.84906 to 0.86792, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_7.hdf5\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.4830 - accuracy: 0.9917 - val_loss: 1.5824 - val_accuracy: 0.8679\n",
            "Epoch 115/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4804 - accuracy: 0.9933\n",
            "Epoch 115: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4789 - accuracy: 0.9938 - val_loss: 1.5924 - val_accuracy: 0.8113\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4783 - accuracy: 0.9959\n",
            "Epoch 116: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4783 - accuracy: 0.9959 - val_loss: 1.5917 - val_accuracy: 0.8302\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4755 - accuracy: 0.9959\n",
            "Epoch 117: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4755 - accuracy: 0.9959 - val_loss: 1.6027 - val_accuracy: 0.7925\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4743 - accuracy: 0.9959\n",
            "Epoch 118: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4743 - accuracy: 0.9959 - val_loss: 1.5985 - val_accuracy: 0.8302\n",
            "Epoch 119/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4789 - accuracy: 0.9955\n",
            "Epoch 119: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4778 - accuracy: 0.9959 - val_loss: 1.5939 - val_accuracy: 0.8302\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4733 - accuracy: 0.9917\n",
            "Epoch 120: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4733 - accuracy: 0.9917 - val_loss: 1.5938 - val_accuracy: 0.8302\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4727 - accuracy: 0.9979\n",
            "Epoch 121: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.4727 - accuracy: 0.9979 - val_loss: 1.5907 - val_accuracy: 0.8679\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4765 - accuracy: 0.9938\n",
            "Epoch 122: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4765 - accuracy: 0.9938 - val_loss: 1.5935 - val_accuracy: 0.7736\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4755 - accuracy: 0.9917\n",
            "Epoch 123: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4755 - accuracy: 0.9917 - val_loss: 1.6096 - val_accuracy: 0.7736\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4708 - accuracy: 0.9979\n",
            "Epoch 124: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4708 - accuracy: 0.9979 - val_loss: 1.5946 - val_accuracy: 0.8302\n",
            "Epoch 125/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4731 - accuracy: 0.9933\n",
            "Epoch 125: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4731 - accuracy: 0.9938 - val_loss: 1.5947 - val_accuracy: 0.8302\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4714 - accuracy: 0.9979\n",
            "Epoch 126: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4714 - accuracy: 0.9979 - val_loss: 1.6028 - val_accuracy: 0.7925\n",
            "Epoch 127/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4671 - accuracy: 0.9955\n",
            "Epoch 127: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4687 - accuracy: 0.9959 - val_loss: 1.6091 - val_accuracy: 0.7925\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.9959\n",
            "Epoch 128: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4749 - accuracy: 0.9959 - val_loss: 1.5981 - val_accuracy: 0.8113\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4730 - accuracy: 0.9959\n",
            "Epoch 129: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4730 - accuracy: 0.9959 - val_loss: 1.5918 - val_accuracy: 0.7925\n",
            "Epoch 130/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4693 - accuracy: 0.9978\n",
            "Epoch 130: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4699 - accuracy: 0.9979 - val_loss: 1.6030 - val_accuracy: 0.7925\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 1.0000\n",
            "Epoch 131: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4709 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.8302\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4673 - accuracy: 1.0000\n",
            "Epoch 132: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4673 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.8113\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 1.0000\n",
            "Epoch 133: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.4707 - accuracy: 1.0000 - val_loss: 1.5985 - val_accuracy: 0.8302\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.9979\n",
            "Epoch 134: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.4698 - accuracy: 0.9979 - val_loss: 1.5991 - val_accuracy: 0.8302\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4686 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.4686 - accuracy: 0.9979 - val_loss: 1.6043 - val_accuracy: 0.8302\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4681 - accuracy: 1.0000\n",
            "Epoch 136: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.4681 - accuracy: 1.0000 - val_loss: 1.5943 - val_accuracy: 0.8302\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.9959\n",
            "Epoch 137: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.4662 - accuracy: 0.9959 - val_loss: 1.6031 - val_accuracy: 0.7925\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4653 - accuracy: 0.9938\n",
            "Epoch 138: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.4653 - accuracy: 0.9938 - val_loss: 1.5921 - val_accuracy: 0.7736\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4685 - accuracy: 0.9938\n",
            "Epoch 139: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.4685 - accuracy: 0.9938 - val_loss: 1.5868 - val_accuracy: 0.7925\n",
            "Epoch 140/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4643 - accuracy: 1.0000\n",
            "Epoch 140: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4659 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.7925\n",
            "Epoch 141/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4640 - accuracy: 0.9955\n",
            "Epoch 141: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.5947 - val_accuracy: 0.8302\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.9979\n",
            "Epoch 142: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4662 - accuracy: 0.9979 - val_loss: 1.5883 - val_accuracy: 0.7925\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 1.0000\n",
            "Epoch 143: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4644 - accuracy: 1.0000 - val_loss: 1.5898 - val_accuracy: 0.8113\n",
            "Epoch 144/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4643 - accuracy: 0.9955\n",
            "Epoch 144: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4633 - accuracy: 0.9959 - val_loss: 1.6032 - val_accuracy: 0.7925\n",
            "Epoch 145/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4613 - accuracy: 1.0000\n",
            "Epoch 145: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.4611 - accuracy: 1.0000 - val_loss: 1.5964 - val_accuracy: 0.7925\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4620 - accuracy: 1.0000\n",
            "Epoch 146: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4620 - accuracy: 1.0000 - val_loss: 1.5994 - val_accuracy: 0.7925\n",
            "Epoch 147/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4622 - accuracy: 1.0000\n",
            "Epoch 147: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4615 - accuracy: 1.0000 - val_loss: 1.6222 - val_accuracy: 0.7358\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4614 - accuracy: 1.0000\n",
            "Epoch 148: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4614 - accuracy: 1.0000 - val_loss: 1.5978 - val_accuracy: 0.8113\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 1.0000\n",
            "Epoch 149: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4638 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.8491\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4602 - accuracy: 1.0000\n",
            "Epoch 150: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 1.4602 - accuracy: 1.0000 - val_loss: 1.5901 - val_accuracy: 0.8113\n",
            "Epoch 151/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4646 - accuracy: 0.9978\n",
            "Epoch 151: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.4635 - accuracy: 0.9979 - val_loss: 1.5922 - val_accuracy: 0.8302\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4628 - accuracy: 1.0000\n",
            "Epoch 152: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.4628 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.7925\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4652 - accuracy: 0.9979\n",
            "Epoch 153: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4652 - accuracy: 0.9979 - val_loss: 1.5829 - val_accuracy: 0.8113\n",
            "Epoch 154/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4617 - accuracy: 1.0000\n",
            "Epoch 154: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4623 - accuracy: 1.0000 - val_loss: 1.5820 - val_accuracy: 0.8302\n",
            "Epoch 155/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4625 - accuracy: 0.9955\n",
            "Epoch 155: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4630 - accuracy: 0.9959 - val_loss: 1.5863 - val_accuracy: 0.8302\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4592 - accuracy: 0.9979\n",
            "Epoch 156: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4592 - accuracy: 0.9979 - val_loss: 1.6003 - val_accuracy: 0.8302\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4593 - accuracy: 1.0000\n",
            "Epoch 157: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4593 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.8302\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4576 - accuracy: 1.0000\n",
            "Epoch 158: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4576 - accuracy: 1.0000 - val_loss: 1.6017 - val_accuracy: 0.7925\n",
            "Epoch 159/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4601 - accuracy: 0.9978\n",
            "Epoch 159: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4614 - accuracy: 0.9979 - val_loss: 1.5975 - val_accuracy: 0.8302\n",
            "Epoch 160/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4598 - accuracy: 0.9978\n",
            "Epoch 160: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4609 - accuracy: 0.9979 - val_loss: 1.5862 - val_accuracy: 0.8302\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4595 - accuracy: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.4595 - accuracy: 1.0000 - val_loss: 1.5875 - val_accuracy: 0.8113\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4597 - accuracy: 0.9959\n",
            "Epoch 162: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.4597 - accuracy: 0.9959 - val_loss: 1.5868 - val_accuracy: 0.8113\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4573 - accuracy: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.4573 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.8491\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4575 - accuracy: 0.9959\n",
            "Epoch 164: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.4575 - accuracy: 0.9959 - val_loss: 1.5794 - val_accuracy: 0.8679\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4562 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.4562 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.8113\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4571 - accuracy: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.4571 - accuracy: 1.0000 - val_loss: 1.5781 - val_accuracy: 0.8491\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4552 - accuracy: 1.0000\n",
            "Epoch 167: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.4552 - accuracy: 1.0000 - val_loss: 1.5924 - val_accuracy: 0.8113\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4578 - accuracy: 0.9979\n",
            "Epoch 168: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4578 - accuracy: 0.9979 - val_loss: 1.5756 - val_accuracy: 0.8113\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4565 - accuracy: 1.0000\n",
            "Epoch 169: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4565 - accuracy: 1.0000 - val_loss: 1.5694 - val_accuracy: 0.8113\n",
            "Epoch 170/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4543 - accuracy: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4546 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.8302\n",
            "Epoch 171/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4577 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4563 - accuracy: 1.0000 - val_loss: 1.5810 - val_accuracy: 0.8302\n",
            "Epoch 172/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4551 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4556 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.8302\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4555 - accuracy: 0.9979\n",
            "Epoch 173: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4555 - accuracy: 0.9979 - val_loss: 1.5814 - val_accuracy: 0.8113\n",
            "Epoch 174/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4552 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4551 - accuracy: 1.0000 - val_loss: 1.5799 - val_accuracy: 0.8113\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4543 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.4543 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.8302\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4546 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4546 - accuracy: 1.0000 - val_loss: 1.5887 - val_accuracy: 0.7925\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4561 - accuracy: 0.9979\n",
            "Epoch 177: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4561 - accuracy: 0.9979 - val_loss: 1.5816 - val_accuracy: 0.8302\n",
            "Epoch 178/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4533 - accuracy: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4537 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.8113\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4561 - accuracy: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4561 - accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.7925\n",
            "Epoch 180/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4529 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4530 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.7925\n",
            "Epoch 181/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4534 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4539 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.7925\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4535 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.4535 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.7925\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4527 - accuracy: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4527 - accuracy: 1.0000 - val_loss: 1.6013 - val_accuracy: 0.7736\n",
            "Epoch 184/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4526 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4516 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.8302\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4532 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4532 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.8302\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4543 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4543 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.8113\n",
            "Epoch 187/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4515 - accuracy: 0.9978\n",
            "Epoch 187: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4524 - accuracy: 0.9979 - val_loss: 1.5788 - val_accuracy: 0.8113\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4578 - accuracy: 0.9959\n",
            "Epoch 188: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4578 - accuracy: 0.9959 - val_loss: 1.5845 - val_accuracy: 0.7925\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4516 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4516 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.8491\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4555 - accuracy: 0.9979\n",
            "Epoch 190: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.4555 - accuracy: 0.9979 - val_loss: 1.5817 - val_accuracy: 0.8302\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4530 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.4530 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.8302\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4550 - accuracy: 0.9979\n",
            "Epoch 192: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.4550 - accuracy: 0.9979 - val_loss: 1.5825 - val_accuracy: 0.8113\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 0.9979\n",
            "Epoch 193: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.4509 - accuracy: 0.9979 - val_loss: 1.5865 - val_accuracy: 0.8302\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4520 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.4520 - accuracy: 1.0000 - val_loss: 1.5922 - val_accuracy: 0.8302\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4522 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.4522 - accuracy: 1.0000 - val_loss: 1.5908 - val_accuracy: 0.8113\n",
            "Epoch 196/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4517 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4519 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.8113\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4509 - accuracy: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.8302\n",
            "Epoch 198/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4530 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4531 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.8302\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4501 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4501 - accuracy: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.8302\n",
            "Epoch 200/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4470 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4488 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.8302\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4516 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4516 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.8113\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4518 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4518 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.7925\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4514 - accuracy: 0.9979\n",
            "Epoch 203: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4514 - accuracy: 0.9979 - val_loss: 1.5864 - val_accuracy: 0.8302\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4490 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4490 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.8302\n",
            "Epoch 205/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4495 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4506 - accuracy: 1.0000 - val_loss: 1.5830 - val_accuracy: 0.8302\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4517 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4517 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.8302\n",
            "Epoch 207/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4492 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4487 - accuracy: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.8302\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4511 - accuracy: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 1.4511 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.8302\n",
            "Epoch 209/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4481 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4485 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.8302\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4509 - accuracy: 1.0000 - val_loss: 1.5959 - val_accuracy: 0.8302\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4496 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.8302\n",
            "Epoch 212/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4516 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.4513 - accuracy: 1.0000 - val_loss: 1.5931 - val_accuracy: 0.8302\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4517 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4517 - accuracy: 1.0000 - val_loss: 1.5817 - val_accuracy: 0.8113\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4507 - accuracy: 0.9979\n",
            "Epoch 214: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.4507 - accuracy: 0.9979 - val_loss: 1.5863 - val_accuracy: 0.8113\n",
            "Epoch 215/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4495 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4498 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.8302\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4485 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4485 - accuracy: 1.0000 - val_loss: 1.5886 - val_accuracy: 0.8113\n",
            "Epoch 217/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4473 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4479 - accuracy: 1.0000 - val_loss: 1.5826 - val_accuracy: 0.8491\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4494 - accuracy: 0.9979\n",
            "Epoch 218: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.4494 - accuracy: 0.9979 - val_loss: 1.5794 - val_accuracy: 0.8302\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4486 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.4486 - accuracy: 1.0000 - val_loss: 1.5914 - val_accuracy: 0.8113\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.4496 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.8113\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4487 - accuracy: 0.9979\n",
            "Epoch 221: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.4487 - accuracy: 0.9979 - val_loss: 1.5949 - val_accuracy: 0.7925\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4460 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.4460 - accuracy: 1.0000 - val_loss: 1.5833 - val_accuracy: 0.7925\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4459 - accuracy: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.4459 - accuracy: 1.0000 - val_loss: 1.6036 - val_accuracy: 0.7925\n",
            "Epoch 224/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4492 - accuracy: 0.9978\n",
            "Epoch 224: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.4490 - accuracy: 0.9979 - val_loss: 1.5950 - val_accuracy: 0.7925\n",
            "Epoch 225/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4467 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4473 - accuracy: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.8302\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4474 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4474 - accuracy: 1.0000 - val_loss: 1.5877 - val_accuracy: 0.8302\n",
            "Epoch 227/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4452 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4450 - accuracy: 1.0000 - val_loss: 1.5845 - val_accuracy: 0.8302\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4457 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4457 - accuracy: 1.0000 - val_loss: 1.5799 - val_accuracy: 0.8302\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4445 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4445 - accuracy: 1.0000 - val_loss: 1.5811 - val_accuracy: 0.8302\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4454 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4454 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.8302\n",
            "Epoch 231/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4453 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4460 - accuracy: 1.0000 - val_loss: 1.5766 - val_accuracy: 0.8302\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4480 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4480 - accuracy: 1.0000 - val_loss: 1.5798 - val_accuracy: 0.8113\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4471 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4471 - accuracy: 1.0000 - val_loss: 1.5865 - val_accuracy: 0.8113\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4470 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4470 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.7736\n",
            "Epoch 235/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4459 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4460 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.8113\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4456 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4456 - accuracy: 1.0000 - val_loss: 1.5980 - val_accuracy: 0.8113\n",
            "Epoch 237/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4454 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.4453 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.8302\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4467 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4467 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.8113\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4463 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4463 - accuracy: 1.0000 - val_loss: 1.5840 - val_accuracy: 0.8302\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4469 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4469 - accuracy: 1.0000 - val_loss: 1.5917 - val_accuracy: 0.8113\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4481 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4481 - accuracy: 1.0000 - val_loss: 1.5867 - val_accuracy: 0.8302\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4442 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4442 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.7925\n",
            "Epoch 243/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4462 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.4467 - accuracy: 1.0000 - val_loss: 1.5861 - val_accuracy: 0.8113\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4473 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4473 - accuracy: 1.0000 - val_loss: 1.6013 - val_accuracy: 0.8302\n",
            "Epoch 245/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4458 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4462 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.8113\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4462 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.4462 - accuracy: 1.0000 - val_loss: 1.5882 - val_accuracy: 0.8302\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4459 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.4459 - accuracy: 1.0000 - val_loss: 1.5947 - val_accuracy: 0.8113\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4459 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.4459 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.7736\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.4433 - accuracy: 1.0000 - val_loss: 1.5937 - val_accuracy: 0.7925\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4449 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.4449 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.8302\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.4440 - accuracy: 1.0000 - val_loss: 1.5818 - val_accuracy: 0.8491\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4449 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.4449 - accuracy: 1.0000 - val_loss: 1.5973 - val_accuracy: 0.7736\n",
            "Epoch 253/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4462 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4450 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.8113\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4449 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4449 - accuracy: 1.0000 - val_loss: 1.5873 - val_accuracy: 0.7736\n",
            "Epoch 255/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4434 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4432 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.7925\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4434 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4434 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.7925\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4458 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.4458 - accuracy: 1.0000 - val_loss: 1.5856 - val_accuracy: 0.7925\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4440 - accuracy: 1.0000 - val_loss: 1.5724 - val_accuracy: 0.8302\n",
            "Epoch 259/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4437 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4438 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.7925\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4448 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4448 - accuracy: 1.0000 - val_loss: 1.5766 - val_accuracy: 0.7925\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4438 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4438 - accuracy: 1.0000 - val_loss: 1.5787 - val_accuracy: 0.8302\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4439 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4439 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.8113\n",
            "Epoch 263/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4422 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.5819 - val_accuracy: 0.8302\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4419 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4419 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.8302\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4422 - accuracy: 0.9979\n",
            "Epoch 265: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4422 - accuracy: 0.9979 - val_loss: 1.5975 - val_accuracy: 0.8113\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4421 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4421 - accuracy: 1.0000 - val_loss: 1.5905 - val_accuracy: 0.8302\n",
            "Epoch 267/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4435 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4444 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.8113\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4440 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.8113\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4423 - accuracy: 1.0000 - val_loss: 1.5902 - val_accuracy: 0.8302\n",
            "Epoch 270/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4427 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4432 - accuracy: 1.0000 - val_loss: 1.5840 - val_accuracy: 0.8302\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4422 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.8491\n",
            "Epoch 272/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4423 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4426 - accuracy: 1.0000 - val_loss: 1.5817 - val_accuracy: 0.8302\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4428 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 1.4428 - accuracy: 1.0000 - val_loss: 1.5814 - val_accuracy: 0.8302\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4437 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.4437 - accuracy: 1.0000 - val_loss: 1.5837 - val_accuracy: 0.8302\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4413 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.4413 - accuracy: 1.0000 - val_loss: 1.5873 - val_accuracy: 0.8302\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4415 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.4415 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.8113\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4420 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.4420 - accuracy: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.8113\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4414 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.4414 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.8302\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.4423 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.8113\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4429 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.4429 - accuracy: 1.0000 - val_loss: 1.5813 - val_accuracy: 0.8302\n",
            "Epoch 281/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4429 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.5851 - val_accuracy: 0.8113\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4429 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4429 - accuracy: 1.0000 - val_loss: 1.5822 - val_accuracy: 0.8302\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4432 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4432 - accuracy: 1.0000 - val_loss: 1.5831 - val_accuracy: 0.8113\n",
            "Epoch 284/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4437 - accuracy: 0.9978\n",
            "Epoch 284: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4432 - accuracy: 0.9979 - val_loss: 1.5866 - val_accuracy: 0.8113\n",
            "Epoch 285/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4412 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4419 - accuracy: 1.0000 - val_loss: 1.5889 - val_accuracy: 0.8491\n",
            "Epoch 286/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4432 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4430 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.8491\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4420 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4420 - accuracy: 1.0000 - val_loss: 1.5875 - val_accuracy: 0.8491\n",
            "Epoch 288/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4420 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4413 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.8302\n",
            "Epoch 289/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4401 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4412 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.8302\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4419 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 1.4419 - accuracy: 1.0000 - val_loss: 1.5783 - val_accuracy: 0.8302\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4408 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4408 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.8113\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4429 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.4429 - accuracy: 1.0000 - val_loss: 1.5835 - val_accuracy: 0.8113\n",
            "Epoch 293/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4403 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.4400 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.8113\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4405 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4405 - accuracy: 1.0000 - val_loss: 1.5829 - val_accuracy: 0.8302\n",
            "Epoch 295/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4407 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4418 - accuracy: 1.0000 - val_loss: 1.5837 - val_accuracy: 0.8113\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4422 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.5770 - val_accuracy: 0.8113\n",
            "Epoch 297/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4414 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4406 - accuracy: 1.0000 - val_loss: 1.5807 - val_accuracy: 0.7925\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4402 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4402 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.7925\n",
            "Epoch 299/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.4409 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4399 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.8113\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.4401 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4401 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.8113\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5824 - accuracy: 0.8679\n",
            "7_Model evaluation:  [1.5823568105697632, 0.8679245114326477]    Now ACC: 92.01428571428572\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.91      0.91      0.91        11\n",
            "     boredom       0.90      0.90      0.90        10\n",
            "     disgust       1.00      0.67      0.80         3\n",
            "        fear       0.78      1.00      0.88         7\n",
            "       happy       0.75      0.67      0.71         9\n",
            "     neutral       0.86      0.86      0.86         7\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.87        53\n",
            "   macro avg       0.88      0.86      0.86        53\n",
            "weighted avg       0.87      0.87      0.87        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 5.0993 - accuracy: 0.1494\n",
            "Epoch 1: val_accuracy improved from -inf to 0.43396, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 35s 414ms/step - loss: 5.0993 - accuracy: 0.1494 - val_loss: 2.9853 - val_accuracy: 0.4340\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.4442 - accuracy: 0.2593\n",
            "Epoch 2: val_accuracy improved from 0.43396 to 0.45283, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 2.4442 - accuracy: 0.2593 - val_loss: 2.3753 - val_accuracy: 0.4528\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.0403 - accuracy: 0.2967\n",
            "Epoch 3: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.0403 - accuracy: 0.2967 - val_loss: 2.1850 - val_accuracy: 0.2642\n",
            "Epoch 4/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.9824 - accuracy: 0.2455\n",
            "Epoch 4: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.9825 - accuracy: 0.2510 - val_loss: 2.0403 - val_accuracy: 0.1509\n",
            "Epoch 5/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.9353 - accuracy: 0.2299\n",
            "Epoch 5: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.9336 - accuracy: 0.2386 - val_loss: 1.9868 - val_accuracy: 0.1698\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9084 - accuracy: 0.2946\n",
            "Epoch 6: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.9084 - accuracy: 0.2946 - val_loss: 2.0176 - val_accuracy: 0.2453\n",
            "Epoch 7/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.9005 - accuracy: 0.3504\n",
            "Epoch 7: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.9025 - accuracy: 0.3423 - val_loss: 1.9454 - val_accuracy: 0.3774\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8914 - accuracy: 0.3651\n",
            "Epoch 8: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.8914 - accuracy: 0.3651 - val_loss: 1.9053 - val_accuracy: 0.3962\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8763 - accuracy: 0.3755\n",
            "Epoch 9: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.8763 - accuracy: 0.3755 - val_loss: 1.8941 - val_accuracy: 0.4340\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8642 - accuracy: 0.3963\n",
            "Epoch 10: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.8642 - accuracy: 0.3963 - val_loss: 1.8827 - val_accuracy: 0.4340\n",
            "Epoch 11/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8570 - accuracy: 0.4129\n",
            "Epoch 11: val_accuracy improved from 0.45283 to 0.47170, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.8559 - accuracy: 0.4170 - val_loss: 1.8658 - val_accuracy: 0.4717\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8485 - accuracy: 0.4461\n",
            "Epoch 12: val_accuracy improved from 0.47170 to 0.50943, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.8485 - accuracy: 0.4461 - val_loss: 1.8412 - val_accuracy: 0.5094\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8394 - accuracy: 0.4834\n",
            "Epoch 13: val_accuracy improved from 0.50943 to 0.54717, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.8394 - accuracy: 0.4834 - val_loss: 1.8212 - val_accuracy: 0.5472\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8240 - accuracy: 0.4876\n",
            "Epoch 14: val_accuracy did not improve from 0.54717\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.8240 - accuracy: 0.4876 - val_loss: 1.8243 - val_accuracy: 0.5472\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8225 - accuracy: 0.4896\n",
            "Epoch 15: val_accuracy improved from 0.54717 to 0.56604, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.8225 - accuracy: 0.4896 - val_loss: 1.8121 - val_accuracy: 0.5660\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8141 - accuracy: 0.5187\n",
            "Epoch 16: val_accuracy improved from 0.56604 to 0.62264, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.8141 - accuracy: 0.5187 - val_loss: 1.8012 - val_accuracy: 0.6226\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8021 - accuracy: 0.5145\n",
            "Epoch 17: val_accuracy did not improve from 0.62264\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.8021 - accuracy: 0.5145 - val_loss: 1.7941 - val_accuracy: 0.6226\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7924 - accuracy: 0.5581\n",
            "Epoch 18: val_accuracy did not improve from 0.62264\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.7924 - accuracy: 0.5581 - val_loss: 1.7888 - val_accuracy: 0.6226\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7879 - accuracy: 0.5664\n",
            "Epoch 19: val_accuracy did not improve from 0.62264\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7879 - accuracy: 0.5664 - val_loss: 1.7813 - val_accuracy: 0.6226\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7803 - accuracy: 0.5809\n",
            "Epoch 20: val_accuracy improved from 0.62264 to 0.64151, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7803 - accuracy: 0.5809 - val_loss: 1.7865 - val_accuracy: 0.6415\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7763 - accuracy: 0.5934\n",
            "Epoch 21: val_accuracy improved from 0.64151 to 0.66038, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.7763 - accuracy: 0.5934 - val_loss: 1.7753 - val_accuracy: 0.6604\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7735 - accuracy: 0.5726\n",
            "Epoch 22: val_accuracy did not improve from 0.66038\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.7735 - accuracy: 0.5726 - val_loss: 1.7701 - val_accuracy: 0.6604\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7644 - accuracy: 0.6245\n",
            "Epoch 23: val_accuracy did not improve from 0.66038\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.7644 - accuracy: 0.6245 - val_loss: 1.7745 - val_accuracy: 0.6415\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7585 - accuracy: 0.6224\n",
            "Epoch 24: val_accuracy did not improve from 0.66038\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.7585 - accuracy: 0.6224 - val_loss: 1.7601 - val_accuracy: 0.6604\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7505 - accuracy: 0.6577\n",
            "Epoch 25: val_accuracy improved from 0.66038 to 0.67925, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.7505 - accuracy: 0.6577 - val_loss: 1.7543 - val_accuracy: 0.6792\n",
            "Epoch 26/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7458 - accuracy: 0.6696\n",
            "Epoch 26: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.7448 - accuracy: 0.6805 - val_loss: 1.7633 - val_accuracy: 0.5849\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7478 - accuracy: 0.6598\n",
            "Epoch 27: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.7478 - accuracy: 0.6598 - val_loss: 1.7682 - val_accuracy: 0.6038\n",
            "Epoch 28/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7390 - accuracy: 0.6786\n",
            "Epoch 28: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7393 - accuracy: 0.6743 - val_loss: 1.7655 - val_accuracy: 0.6415\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7327 - accuracy: 0.6909\n",
            "Epoch 29: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7327 - accuracy: 0.6909 - val_loss: 1.7897 - val_accuracy: 0.5660\n",
            "Epoch 30/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7314 - accuracy: 0.6897\n",
            "Epoch 30: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7302 - accuracy: 0.6950 - val_loss: 1.7525 - val_accuracy: 0.6604\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7182 - accuracy: 0.7324\n",
            "Epoch 31: val_accuracy improved from 0.67925 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7182 - accuracy: 0.7324 - val_loss: 1.7554 - val_accuracy: 0.7170\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7163 - accuracy: 0.7365\n",
            "Epoch 32: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.7163 - accuracy: 0.7365 - val_loss: 1.7760 - val_accuracy: 0.6604\n",
            "Epoch 33/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7155 - accuracy: 0.7366\n",
            "Epoch 33: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.7141 - accuracy: 0.7407 - val_loss: 1.7747 - val_accuracy: 0.6604\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7034 - accuracy: 0.7386\n",
            "Epoch 34: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.7034 - accuracy: 0.7386 - val_loss: 1.7672 - val_accuracy: 0.6981\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6958 - accuracy: 0.7863\n",
            "Epoch 35: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6958 - accuracy: 0.7863 - val_loss: 1.7603 - val_accuracy: 0.6981\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6950 - accuracy: 0.7884\n",
            "Epoch 36: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6950 - accuracy: 0.7884 - val_loss: 1.7766 - val_accuracy: 0.6415\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6972 - accuracy: 0.7842\n",
            "Epoch 37: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6972 - accuracy: 0.7842 - val_loss: 1.7595 - val_accuracy: 0.6604\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6887 - accuracy: 0.7925\n",
            "Epoch 38: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6887 - accuracy: 0.7925 - val_loss: 1.7754 - val_accuracy: 0.6415\n",
            "Epoch 39/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6837 - accuracy: 0.8147\n",
            "Epoch 39: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6845 - accuracy: 0.8091 - val_loss: 1.7588 - val_accuracy: 0.6981\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6744 - accuracy: 0.8216\n",
            "Epoch 40: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6744 - accuracy: 0.8216 - val_loss: 1.7775 - val_accuracy: 0.6604\n",
            "Epoch 41/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6787 - accuracy: 0.8125\n",
            "Epoch 41: val_accuracy improved from 0.71698 to 0.75472, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6776 - accuracy: 0.8195 - val_loss: 1.7314 - val_accuracy: 0.7547\n",
            "Epoch 42/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6746 - accuracy: 0.8147\n",
            "Epoch 42: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6734 - accuracy: 0.8174 - val_loss: 1.7176 - val_accuracy: 0.7358\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6660 - accuracy: 0.8423\n",
            "Epoch 43: val_accuracy improved from 0.75472 to 0.77358, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6660 - accuracy: 0.8423 - val_loss: 1.7185 - val_accuracy: 0.7736\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6665 - accuracy: 0.8174\n",
            "Epoch 44: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6665 - accuracy: 0.8174 - val_loss: 1.6744 - val_accuracy: 0.7736\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6597 - accuracy: 0.8485\n",
            "Epoch 45: val_accuracy did not improve from 0.77358\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6597 - accuracy: 0.8485 - val_loss: 1.6862 - val_accuracy: 0.7358\n",
            "Epoch 46/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6570 - accuracy: 0.8594\n",
            "Epoch 46: val_accuracy improved from 0.77358 to 0.81132, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.6580 - accuracy: 0.8568 - val_loss: 1.6866 - val_accuracy: 0.8113\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6509 - accuracy: 0.8672\n",
            "Epoch 47: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6509 - accuracy: 0.8672 - val_loss: 1.6648 - val_accuracy: 0.8113\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 0.8734\n",
            "Epoch 48: val_accuracy improved from 0.81132 to 0.83019, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 1.6452 - accuracy: 0.8734 - val_loss: 1.6782 - val_accuracy: 0.8302\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6440 - accuracy: 0.8817\n",
            "Epoch 49: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.6440 - accuracy: 0.8817 - val_loss: 1.6700 - val_accuracy: 0.8302\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6478 - accuracy: 0.8631\n",
            "Epoch 50: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6478 - accuracy: 0.8631 - val_loss: 1.6752 - val_accuracy: 0.8302\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6358 - accuracy: 0.8734\n",
            "Epoch 51: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6358 - accuracy: 0.8734 - val_loss: 1.6655 - val_accuracy: 0.8302\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6398 - accuracy: 0.8797\n",
            "Epoch 52: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6398 - accuracy: 0.8797 - val_loss: 1.6749 - val_accuracy: 0.8113\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6337 - accuracy: 0.8817\n",
            "Epoch 53: val_accuracy improved from 0.83019 to 0.84906, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6337 - accuracy: 0.8817 - val_loss: 1.6582 - val_accuracy: 0.8491\n",
            "Epoch 54/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6328 - accuracy: 0.8884\n",
            "Epoch 54: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6326 - accuracy: 0.8838 - val_loss: 1.6630 - val_accuracy: 0.8113\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6331 - accuracy: 0.8880\n",
            "Epoch 55: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6331 - accuracy: 0.8880 - val_loss: 1.6596 - val_accuracy: 0.8113\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6324 - accuracy: 0.8900\n",
            "Epoch 56: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6324 - accuracy: 0.8900 - val_loss: 1.6449 - val_accuracy: 0.8491\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6315 - accuracy: 0.8797\n",
            "Epoch 57: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6315 - accuracy: 0.8797 - val_loss: 1.6520 - val_accuracy: 0.7547\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6204 - accuracy: 0.9170\n",
            "Epoch 58: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6204 - accuracy: 0.9170 - val_loss: 1.6427 - val_accuracy: 0.8491\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.8963\n",
            "Epoch 59: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6252 - accuracy: 0.8963 - val_loss: 1.6400 - val_accuracy: 0.8491\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6182 - accuracy: 0.9336\n",
            "Epoch 60: val_accuracy improved from 0.84906 to 0.86792, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.6182 - accuracy: 0.9336 - val_loss: 1.6570 - val_accuracy: 0.8679\n",
            "Epoch 61/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6157 - accuracy: 0.9174\n",
            "Epoch 61: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6177 - accuracy: 0.9191 - val_loss: 1.6458 - val_accuracy: 0.8491\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6188 - accuracy: 0.9046\n",
            "Epoch 62: val_accuracy improved from 0.86792 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6188 - accuracy: 0.9046 - val_loss: 1.6382 - val_accuracy: 0.8868\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6127 - accuracy: 0.9170\n",
            "Epoch 63: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6127 - accuracy: 0.9170 - val_loss: 1.6227 - val_accuracy: 0.8679\n",
            "Epoch 64/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6091 - accuracy: 0.9196\n",
            "Epoch 64: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6091 - accuracy: 0.9191 - val_loss: 1.6172 - val_accuracy: 0.8868\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6085 - accuracy: 0.9315\n",
            "Epoch 65: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6085 - accuracy: 0.9315 - val_loss: 1.6256 - val_accuracy: 0.8491\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6070 - accuracy: 0.9295\n",
            "Epoch 66: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6070 - accuracy: 0.9295 - val_loss: 1.6322 - val_accuracy: 0.8868\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6076 - accuracy: 0.9170\n",
            "Epoch 67: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6076 - accuracy: 0.9170 - val_loss: 1.6365 - val_accuracy: 0.8868\n",
            "Epoch 68/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6002 - accuracy: 0.9442\n",
            "Epoch 68: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6026 - accuracy: 0.9419 - val_loss: 1.6443 - val_accuracy: 0.8302\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5970 - accuracy: 0.9481\n",
            "Epoch 69: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5970 - accuracy: 0.9481 - val_loss: 1.6335 - val_accuracy: 0.8868\n",
            "Epoch 70/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5989 - accuracy: 0.9464\n",
            "Epoch 70: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5992 - accuracy: 0.9481 - val_loss: 1.6247 - val_accuracy: 0.8679\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6016 - accuracy: 0.9357\n",
            "Epoch 71: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6016 - accuracy: 0.9357 - val_loss: 1.6286 - val_accuracy: 0.8491\n",
            "Epoch 72/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6038 - accuracy: 0.9241\n",
            "Epoch 72: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6053 - accuracy: 0.9253 - val_loss: 1.6320 - val_accuracy: 0.8491\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5910 - accuracy: 0.9523\n",
            "Epoch 73: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.5910 - accuracy: 0.9523 - val_loss: 1.6277 - val_accuracy: 0.8491\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5970 - accuracy: 0.9440\n",
            "Epoch 74: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5970 - accuracy: 0.9440 - val_loss: 1.6265 - val_accuracy: 0.8491\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5924 - accuracy: 0.9502\n",
            "Epoch 75: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5924 - accuracy: 0.9502 - val_loss: 1.6193 - val_accuracy: 0.8679\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5967 - accuracy: 0.9461\n",
            "Epoch 76: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.5967 - accuracy: 0.9461 - val_loss: 1.6270 - val_accuracy: 0.8491\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5945 - accuracy: 0.9461\n",
            "Epoch 77: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5945 - accuracy: 0.9461 - val_loss: 1.6197 - val_accuracy: 0.8868\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5916 - accuracy: 0.9523\n",
            "Epoch 78: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5916 - accuracy: 0.9523 - val_loss: 1.6195 - val_accuracy: 0.8679\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5855 - accuracy: 0.9647\n",
            "Epoch 79: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.5855 - accuracy: 0.9647 - val_loss: 1.6162 - val_accuracy: 0.8679\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5895 - accuracy: 0.9564\n",
            "Epoch 80: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5895 - accuracy: 0.9564 - val_loss: 1.6195 - val_accuracy: 0.8679\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5829 - accuracy: 0.9710\n",
            "Epoch 81: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5829 - accuracy: 0.9710 - val_loss: 1.6218 - val_accuracy: 0.8679\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5856 - accuracy: 0.9585\n",
            "Epoch 82: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.5856 - accuracy: 0.9585 - val_loss: 1.6240 - val_accuracy: 0.8679\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5840 - accuracy: 0.9606\n",
            "Epoch 83: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5840 - accuracy: 0.9606 - val_loss: 1.6236 - val_accuracy: 0.8491\n",
            "Epoch 84/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5791 - accuracy: 0.9710\n",
            "Epoch 84: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5801 - accuracy: 0.9689 - val_loss: 1.6135 - val_accuracy: 0.8679\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5802 - accuracy: 0.9793\n",
            "Epoch 85: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.5802 - accuracy: 0.9793 - val_loss: 1.6331 - val_accuracy: 0.8302\n",
            "Epoch 86/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5814 - accuracy: 0.9665\n",
            "Epoch 86: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5814 - accuracy: 0.9647 - val_loss: 1.6307 - val_accuracy: 0.8679\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5813 - accuracy: 0.9710\n",
            "Epoch 87: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5813 - accuracy: 0.9710 - val_loss: 1.6419 - val_accuracy: 0.8491\n",
            "Epoch 88/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5751 - accuracy: 0.9799\n",
            "Epoch 88: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5747 - accuracy: 0.9813 - val_loss: 1.6156 - val_accuracy: 0.8491\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5767 - accuracy: 0.9834\n",
            "Epoch 89: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5767 - accuracy: 0.9834 - val_loss: 1.6051 - val_accuracy: 0.8868\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5748 - accuracy: 0.9876\n",
            "Epoch 90: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5748 - accuracy: 0.9876 - val_loss: 1.6250 - val_accuracy: 0.8679\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5714 - accuracy: 0.9813\n",
            "Epoch 91: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5714 - accuracy: 0.9813 - val_loss: 1.6151 - val_accuracy: 0.8868\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5764 - accuracy: 0.9730\n",
            "Epoch 92: val_accuracy improved from 0.88679 to 0.90566, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5764 - accuracy: 0.9730 - val_loss: 1.6033 - val_accuracy: 0.9057\n",
            "Epoch 93/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5735 - accuracy: 0.9732\n",
            "Epoch 93: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5744 - accuracy: 0.9710 - val_loss: 1.6121 - val_accuracy: 0.8868\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5724 - accuracy: 0.9710\n",
            "Epoch 94: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5724 - accuracy: 0.9710 - val_loss: 1.6006 - val_accuracy: 0.8868\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5711 - accuracy: 0.9772\n",
            "Epoch 95: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5711 - accuracy: 0.9772 - val_loss: 1.6002 - val_accuracy: 0.8868\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5701 - accuracy: 0.9751\n",
            "Epoch 96: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5701 - accuracy: 0.9751 - val_loss: 1.6104 - val_accuracy: 0.8491\n",
            "Epoch 97/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5701 - accuracy: 0.9821\n",
            "Epoch 97: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5708 - accuracy: 0.9813 - val_loss: 1.6003 - val_accuracy: 0.9057\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5736 - accuracy: 0.9813\n",
            "Epoch 98: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5736 - accuracy: 0.9813 - val_loss: 1.6207 - val_accuracy: 0.8491\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5686 - accuracy: 0.9813\n",
            "Epoch 99: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5686 - accuracy: 0.9813 - val_loss: 1.5983 - val_accuracy: 0.8868\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5671 - accuracy: 0.9855\n",
            "Epoch 100: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5671 - accuracy: 0.9855 - val_loss: 1.6094 - val_accuracy: 0.8679\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5663 - accuracy: 0.9896\n",
            "Epoch 101: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5663 - accuracy: 0.9896 - val_loss: 1.6124 - val_accuracy: 0.8679\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5662 - accuracy: 0.9772\n",
            "Epoch 102: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.5662 - accuracy: 0.9772 - val_loss: 1.5990 - val_accuracy: 0.8868\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5677 - accuracy: 0.9793\n",
            "Epoch 103: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.5677 - accuracy: 0.9793 - val_loss: 1.6113 - val_accuracy: 0.8679\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5612 - accuracy: 0.9834\n",
            "Epoch 104: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.5612 - accuracy: 0.9834 - val_loss: 1.6014 - val_accuracy: 0.8868\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5644 - accuracy: 0.9813\n",
            "Epoch 105: val_accuracy improved from 0.90566 to 0.92453, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 109ms/step - loss: 1.5644 - accuracy: 0.9813 - val_loss: 1.6102 - val_accuracy: 0.9245\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5605 - accuracy: 0.9876\n",
            "Epoch 106: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5605 - accuracy: 0.9876 - val_loss: 1.6049 - val_accuracy: 0.8868\n",
            "Epoch 107/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5644 - accuracy: 0.9866\n",
            "Epoch 107: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5646 - accuracy: 0.9855 - val_loss: 1.6222 - val_accuracy: 0.8679\n",
            "Epoch 108/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5591 - accuracy: 0.9911\n",
            "Epoch 108: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5602 - accuracy: 0.9917 - val_loss: 1.6161 - val_accuracy: 0.8302\n",
            "Epoch 109/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5597 - accuracy: 0.9888\n",
            "Epoch 109: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5584 - accuracy: 0.9896 - val_loss: 1.6048 - val_accuracy: 0.9057\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5618 - accuracy: 0.9855\n",
            "Epoch 110: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5618 - accuracy: 0.9855 - val_loss: 1.6114 - val_accuracy: 0.8868\n",
            "Epoch 111/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5593 - accuracy: 0.9888\n",
            "Epoch 111: val_accuracy improved from 0.92453 to 0.94340, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.5590 - accuracy: 0.9896 - val_loss: 1.5990 - val_accuracy: 0.9434\n",
            "Epoch 112/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5561 - accuracy: 0.9978\n",
            "Epoch 112: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5558 - accuracy: 0.9979 - val_loss: 1.6193 - val_accuracy: 0.8491\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5556 - accuracy: 0.9917\n",
            "Epoch 113: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5556 - accuracy: 0.9917 - val_loss: 1.6014 - val_accuracy: 0.8868\n",
            "Epoch 114/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5555 - accuracy: 0.9933\n",
            "Epoch 114: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5557 - accuracy: 0.9938 - val_loss: 1.6134 - val_accuracy: 0.8302\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5576 - accuracy: 0.9896\n",
            "Epoch 115: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5576 - accuracy: 0.9896 - val_loss: 1.6128 - val_accuracy: 0.8868\n",
            "Epoch 116/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5539 - accuracy: 0.9888\n",
            "Epoch 116: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5549 - accuracy: 0.9876 - val_loss: 1.6156 - val_accuracy: 0.9057\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5558 - accuracy: 0.9979\n",
            "Epoch 117: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5558 - accuracy: 0.9979 - val_loss: 1.6008 - val_accuracy: 0.9057\n",
            "Epoch 118/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5524 - accuracy: 0.9978\n",
            "Epoch 118: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5531 - accuracy: 0.9959 - val_loss: 1.6200 - val_accuracy: 0.8679\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5544 - accuracy: 0.9959\n",
            "Epoch 119: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5544 - accuracy: 0.9959 - val_loss: 1.6195 - val_accuracy: 0.8491\n",
            "Epoch 120/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5530 - accuracy: 0.9933\n",
            "Epoch 120: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5547 - accuracy: 0.9938 - val_loss: 1.6007 - val_accuracy: 0.9057\n",
            "Epoch 121/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5548 - accuracy: 0.9978\n",
            "Epoch 121: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5553 - accuracy: 0.9938 - val_loss: 1.6009 - val_accuracy: 0.9057\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5570 - accuracy: 0.9917\n",
            "Epoch 122: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5570 - accuracy: 0.9917 - val_loss: 1.6120 - val_accuracy: 0.9057\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5506 - accuracy: 0.9917\n",
            "Epoch 123: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5506 - accuracy: 0.9917 - val_loss: 1.5913 - val_accuracy: 0.8491\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5496 - accuracy: 0.9959\n",
            "Epoch 124: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5496 - accuracy: 0.9959 - val_loss: 1.6065 - val_accuracy: 0.8868\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5555 - accuracy: 0.9938\n",
            "Epoch 125: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5555 - accuracy: 0.9938 - val_loss: 1.5898 - val_accuracy: 0.8868\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5503 - accuracy: 0.9979\n",
            "Epoch 126: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5503 - accuracy: 0.9979 - val_loss: 1.5846 - val_accuracy: 0.9245\n",
            "Epoch 127/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5494 - accuracy: 0.9955\n",
            "Epoch 127: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5509 - accuracy: 0.9938 - val_loss: 1.5915 - val_accuracy: 0.8679\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5514 - accuracy: 0.9979\n",
            "Epoch 128: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5514 - accuracy: 0.9979 - val_loss: 1.5961 - val_accuracy: 0.8868\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5496 - accuracy: 0.9938\n",
            "Epoch 129: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5496 - accuracy: 0.9938 - val_loss: 1.5861 - val_accuracy: 0.9245\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5500 - accuracy: 0.9938\n",
            "Epoch 130: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5500 - accuracy: 0.9938 - val_loss: 1.6013 - val_accuracy: 0.8491\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5485 - accuracy: 0.9938\n",
            "Epoch 131: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5485 - accuracy: 0.9938 - val_loss: 1.5859 - val_accuracy: 0.9057\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5477 - accuracy: 0.9876\n",
            "Epoch 132: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5477 - accuracy: 0.9876 - val_loss: 1.5852 - val_accuracy: 0.9057\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5515 - accuracy: 0.9979\n",
            "Epoch 133: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5515 - accuracy: 0.9979 - val_loss: 1.5889 - val_accuracy: 0.9245\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5469 - accuracy: 0.9979\n",
            "Epoch 134: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5469 - accuracy: 0.9979 - val_loss: 1.5855 - val_accuracy: 0.9245\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5473 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5473 - accuracy: 0.9979 - val_loss: 1.5900 - val_accuracy: 0.8868\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5465 - accuracy: 0.9938\n",
            "Epoch 136: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5465 - accuracy: 0.9938 - val_loss: 1.5930 - val_accuracy: 0.8868\n",
            "Epoch 137/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5492 - accuracy: 0.9933\n",
            "Epoch 137: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5492 - accuracy: 0.9938 - val_loss: 1.6078 - val_accuracy: 0.8491\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5490 - accuracy: 0.9917\n",
            "Epoch 138: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5490 - accuracy: 0.9917 - val_loss: 1.6196 - val_accuracy: 0.8113\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5463 - accuracy: 0.9979\n",
            "Epoch 139: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5463 - accuracy: 0.9979 - val_loss: 1.5939 - val_accuracy: 0.8491\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5457 - accuracy: 0.9938\n",
            "Epoch 140: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5457 - accuracy: 0.9938 - val_loss: 1.5870 - val_accuracy: 0.8868\n",
            "Epoch 141/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5422 - accuracy: 1.0000\n",
            "Epoch 141: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5432 - accuracy: 1.0000 - val_loss: 1.5931 - val_accuracy: 0.8868\n",
            "Epoch 142/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5449 - accuracy: 0.9978\n",
            "Epoch 142: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5456 - accuracy: 0.9979 - val_loss: 1.5879 - val_accuracy: 0.9434\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5453 - accuracy: 1.0000\n",
            "Epoch 143: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.5453 - accuracy: 1.0000 - val_loss: 1.5901 - val_accuracy: 0.9057\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5425 - accuracy: 0.9979\n",
            "Epoch 144: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.5425 - accuracy: 0.9979 - val_loss: 1.5869 - val_accuracy: 0.9434\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.9959\n",
            "Epoch 145: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 1.5431 - accuracy: 0.9959 - val_loss: 1.5811 - val_accuracy: 0.9245\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5447 - accuracy: 0.9979\n",
            "Epoch 146: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5447 - accuracy: 0.9979 - val_loss: 1.5956 - val_accuracy: 0.8679\n",
            "Epoch 147/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5442 - accuracy: 0.9955\n",
            "Epoch 147: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5447 - accuracy: 0.9959 - val_loss: 1.5919 - val_accuracy: 0.9057\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5437 - accuracy: 0.9979\n",
            "Epoch 148: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5437 - accuracy: 0.9979 - val_loss: 1.5914 - val_accuracy: 0.8679\n",
            "Epoch 149/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5424 - accuracy: 0.9955\n",
            "Epoch 149: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5419 - accuracy: 0.9959 - val_loss: 1.5887 - val_accuracy: 0.9057\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5443 - accuracy: 1.0000\n",
            "Epoch 150: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5443 - accuracy: 1.0000 - val_loss: 1.5916 - val_accuracy: 0.8868\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5426 - accuracy: 0.9979\n",
            "Epoch 151: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5426 - accuracy: 0.9979 - val_loss: 1.5875 - val_accuracy: 0.8868\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5425 - accuracy: 0.9938\n",
            "Epoch 152: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5425 - accuracy: 0.9938 - val_loss: 1.5914 - val_accuracy: 0.8679\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5408 - accuracy: 0.9938\n",
            "Epoch 153: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5408 - accuracy: 0.9938 - val_loss: 1.5963 - val_accuracy: 0.8868\n",
            "Epoch 154/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5426 - accuracy: 0.9978\n",
            "Epoch 154: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5434 - accuracy: 0.9979 - val_loss: 1.5888 - val_accuracy: 0.9434\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5401 - accuracy: 0.9979\n",
            "Epoch 155: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5401 - accuracy: 0.9979 - val_loss: 1.5967 - val_accuracy: 0.9057\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5386 - accuracy: 1.0000\n",
            "Epoch 156: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5386 - accuracy: 1.0000 - val_loss: 1.5931 - val_accuracy: 0.9434\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5423 - accuracy: 1.0000\n",
            "Epoch 157: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 1.5423 - accuracy: 1.0000 - val_loss: 1.5908 - val_accuracy: 0.8868\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5421 - accuracy: 1.0000\n",
            "Epoch 158: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.5421 - accuracy: 1.0000 - val_loss: 1.5919 - val_accuracy: 0.9245\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5420 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5420 - accuracy: 1.0000 - val_loss: 1.5859 - val_accuracy: 0.9057\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5400 - accuracy: 0.9979\n",
            "Epoch 160: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.5400 - accuracy: 0.9979 - val_loss: 1.5894 - val_accuracy: 0.9434\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5398 - accuracy: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.5398 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.9057\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5366 - accuracy: 1.0000\n",
            "Epoch 162: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.5366 - accuracy: 1.0000 - val_loss: 1.5819 - val_accuracy: 0.9245\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5392 - accuracy: 0.9959\n",
            "Epoch 163: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.5392 - accuracy: 0.9959 - val_loss: 1.5881 - val_accuracy: 0.9245\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5407 - accuracy: 0.9979\n",
            "Epoch 164: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5407 - accuracy: 0.9979 - val_loss: 1.5885 - val_accuracy: 0.8868\n",
            "Epoch 165/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5366 - accuracy: 0.9978\n",
            "Epoch 165: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5370 - accuracy: 0.9979 - val_loss: 1.5855 - val_accuracy: 0.9057\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5378 - accuracy: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5378 - accuracy: 1.0000 - val_loss: 1.5974 - val_accuracy: 0.8302\n",
            "Epoch 167/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5373 - accuracy: 1.0000\n",
            "Epoch 167: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5367 - accuracy: 1.0000 - val_loss: 1.5843 - val_accuracy: 0.9057\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5385 - accuracy: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5385 - accuracy: 1.0000 - val_loss: 1.5919 - val_accuracy: 0.8868\n",
            "Epoch 169/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5382 - accuracy: 1.0000\n",
            "Epoch 169: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5380 - accuracy: 1.0000 - val_loss: 1.5869 - val_accuracy: 0.8868\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5369 - accuracy: 0.9979\n",
            "Epoch 170: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5369 - accuracy: 0.9979 - val_loss: 1.5938 - val_accuracy: 0.9057\n",
            "Epoch 171/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5386 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5384 - accuracy: 1.0000 - val_loss: 1.5963 - val_accuracy: 0.8679\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5357 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5357 - accuracy: 1.0000 - val_loss: 1.5845 - val_accuracy: 0.9057\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5334 - accuracy: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5334 - accuracy: 1.0000 - val_loss: 1.5934 - val_accuracy: 0.8679\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5393 - accuracy: 0.9979\n",
            "Epoch 174: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5393 - accuracy: 0.9979 - val_loss: 1.5796 - val_accuracy: 0.9057\n",
            "Epoch 175/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5360 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5361 - accuracy: 1.0000 - val_loss: 1.5888 - val_accuracy: 0.9057\n",
            "Epoch 176/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5351 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5344 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.9057\n",
            "Epoch 177/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5343 - accuracy: 1.0000\n",
            "Epoch 177: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5344 - accuracy: 1.0000 - val_loss: 1.5915 - val_accuracy: 0.9245\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5355 - accuracy: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5355 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.9245\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5363 - accuracy: 0.9979\n",
            "Epoch 179: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5363 - accuracy: 0.9979 - val_loss: 1.5963 - val_accuracy: 0.9057\n",
            "Epoch 180/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5349 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5345 - accuracy: 1.0000 - val_loss: 1.5988 - val_accuracy: 0.8868\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5346 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5346 - accuracy: 1.0000 - val_loss: 1.5930 - val_accuracy: 0.9057\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5373 - accuracy: 0.9959\n",
            "Epoch 182: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5373 - accuracy: 0.9959 - val_loss: 1.5943 - val_accuracy: 0.8868\n",
            "Epoch 183/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5356 - accuracy: 0.9978\n",
            "Epoch 183: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5344 - accuracy: 0.9979 - val_loss: 1.5903 - val_accuracy: 0.9057\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5337 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.9434\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.5341 - accuracy: 1.0000 - val_loss: 1.5828 - val_accuracy: 0.9245\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5362 - accuracy: 0.9979\n",
            "Epoch 186: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5362 - accuracy: 0.9979 - val_loss: 1.5835 - val_accuracy: 0.9057\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5368 - accuracy: 0.9979\n",
            "Epoch 187: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.5368 - accuracy: 0.9979 - val_loss: 1.5857 - val_accuracy: 0.9057\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 1.0000\n",
            "Epoch 188: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5344 - accuracy: 1.0000 - val_loss: 1.5921 - val_accuracy: 0.8868\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5333 - accuracy: 1.0000 - val_loss: 1.5962 - val_accuracy: 0.8491\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5339 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5339 - accuracy: 1.0000 - val_loss: 1.5899 - val_accuracy: 0.9245\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5333 - accuracy: 1.0000 - val_loss: 1.6025 - val_accuracy: 0.8302\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.5341 - accuracy: 1.0000 - val_loss: 1.5883 - val_accuracy: 0.9245\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5331 - accuracy: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5331 - accuracy: 1.0000 - val_loss: 1.6001 - val_accuracy: 0.8491\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5317 - accuracy: 1.0000 - val_loss: 1.5913 - val_accuracy: 0.8868\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5327 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5327 - accuracy: 1.0000 - val_loss: 1.5898 - val_accuracy: 0.9057\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5321 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5321 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.8868\n",
            "Epoch 197/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5312 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5312 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.9245\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5323 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5323 - accuracy: 1.0000 - val_loss: 1.5882 - val_accuracy: 0.9245\n",
            "Epoch 199/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5303 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5309 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.9245\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5321 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy improved from 0.94340 to 0.96226, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_8.hdf5\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.5321 - accuracy: 1.0000 - val_loss: 1.5764 - val_accuracy: 0.9623\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5307 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5307 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.9434\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5309 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5309 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.9245\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 1.0000\n",
            "Epoch 203: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5320 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.8868\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5303 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.9434\n",
            "Epoch 205/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5274 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5277 - accuracy: 1.0000 - val_loss: 1.5807 - val_accuracy: 0.9057\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5291 - accuracy: 1.0000 - val_loss: 1.5883 - val_accuracy: 0.9057\n",
            "Epoch 207/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5297 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5295 - accuracy: 1.0000 - val_loss: 1.5843 - val_accuracy: 0.9245\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5297 - accuracy: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5297 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.9057\n",
            "Epoch 209/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5298 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5298 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.8868\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5299 - accuracy: 1.0000 - val_loss: 1.5876 - val_accuracy: 0.9057\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5291 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.9057\n",
            "Epoch 212/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5303 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5310 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.9057\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5295 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.5295 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.9057\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5294 - accuracy: 0.9979\n",
            "Epoch 214: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5294 - accuracy: 0.9979 - val_loss: 1.5897 - val_accuracy: 0.8679\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5298 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5298 - accuracy: 1.0000 - val_loss: 1.5831 - val_accuracy: 0.9057\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5294 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5294 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.8679\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5302 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.9057\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5305 - accuracy: 0.9979\n",
            "Epoch 218: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.5305 - accuracy: 0.9979 - val_loss: 1.5896 - val_accuracy: 0.8868\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5270 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5270 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.9057\n",
            "Epoch 220/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5292 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5288 - accuracy: 1.0000 - val_loss: 1.5827 - val_accuracy: 0.9057\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 1.0000\n",
            "Epoch 221: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5284 - accuracy: 1.0000 - val_loss: 1.5851 - val_accuracy: 0.9057\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5288 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.9057\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5278 - accuracy: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5278 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.9057\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5288 - accuracy: 1.0000 - val_loss: 1.5784 - val_accuracy: 0.9057\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5280 - accuracy: 1.0000 - val_loss: 1.5888 - val_accuracy: 0.8868\n",
            "Epoch 226/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5280 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5277 - accuracy: 1.0000 - val_loss: 1.5921 - val_accuracy: 0.8868\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5264 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.8868\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5278 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5278 - accuracy: 1.0000 - val_loss: 1.5883 - val_accuracy: 0.9245\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5276 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5276 - accuracy: 1.0000 - val_loss: 1.5814 - val_accuracy: 0.8679\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5251 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5251 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.9245\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5274 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5274 - accuracy: 1.0000 - val_loss: 1.5913 - val_accuracy: 0.8491\n",
            "Epoch 232/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5257 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5262 - accuracy: 1.0000 - val_loss: 1.5854 - val_accuracy: 0.8868\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5276 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5276 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.8491\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5257 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5257 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.9057\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5285 - accuracy: 1.0000 - val_loss: 1.5889 - val_accuracy: 0.8868\n",
            "Epoch 236/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5283 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5282 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.9245\n",
            "Epoch 237/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5286 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5283 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.8679\n",
            "Epoch 238/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5266 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5264 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.9245\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5264 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5264 - accuracy: 1.0000 - val_loss: 1.5769 - val_accuracy: 0.9245\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5265 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5265 - accuracy: 1.0000 - val_loss: 1.5802 - val_accuracy: 0.9057\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5266 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5266 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.9245\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5284 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.9245\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5277 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5277 - accuracy: 1.0000 - val_loss: 1.5881 - val_accuracy: 0.8868\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5253 - accuracy: 0.9979\n",
            "Epoch 244: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5253 - accuracy: 0.9979 - val_loss: 1.5845 - val_accuracy: 0.8868\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5256 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.5256 - accuracy: 1.0000 - val_loss: 1.5867 - val_accuracy: 0.9245\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5269 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.5269 - accuracy: 1.0000 - val_loss: 1.5908 - val_accuracy: 0.9057\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5262 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5262 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.8679\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5273 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5273 - accuracy: 1.0000 - val_loss: 1.5842 - val_accuracy: 0.9057\n",
            "Epoch 249/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5284 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5285 - accuracy: 1.0000 - val_loss: 1.5841 - val_accuracy: 0.8868\n",
            "Epoch 250/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5267 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 64ms/step - loss: 1.5265 - accuracy: 1.0000 - val_loss: 1.5922 - val_accuracy: 0.9057\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5268 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5268 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.8868\n",
            "Epoch 252/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5268 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5269 - accuracy: 1.0000 - val_loss: 1.5843 - val_accuracy: 0.9057\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5254 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5254 - accuracy: 1.0000 - val_loss: 1.5841 - val_accuracy: 0.8679\n",
            "Epoch 254/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5239 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5243 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.9057\n",
            "Epoch 255/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5243 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5243 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.9057\n",
            "Epoch 256/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5238 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.9057\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5259 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5259 - accuracy: 1.0000 - val_loss: 1.5799 - val_accuracy: 0.9245\n",
            "Epoch 258/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5250 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5250 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.9057\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5252 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5252 - accuracy: 1.0000 - val_loss: 1.5822 - val_accuracy: 0.9057\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5251 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5251 - accuracy: 1.0000 - val_loss: 1.5859 - val_accuracy: 0.8868\n",
            "Epoch 261/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5263 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5259 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.9057\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5241 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5241 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.9245\n",
            "Epoch 263/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5255 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5253 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.9057\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5230 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5230 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.9245\n",
            "Epoch 265/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5252 - accuracy: 1.0000\n",
            "Epoch 265: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5255 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.9245\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5243 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5243 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.9434\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5247 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.5247 - accuracy: 1.0000 - val_loss: 1.5784 - val_accuracy: 0.9245\n",
            "Epoch 268/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5247 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.5245 - accuracy: 1.0000 - val_loss: 1.5818 - val_accuracy: 0.9245\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5250 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5250 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.9245\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5243 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5243 - accuracy: 1.0000 - val_loss: 1.5812 - val_accuracy: 0.9245\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5237 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.9057\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5229 - accuracy: 1.0000 - val_loss: 1.5781 - val_accuracy: 0.9057\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.5233 - accuracy: 1.0000 - val_loss: 1.5820 - val_accuracy: 0.9245\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5235 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5235 - accuracy: 1.0000 - val_loss: 1.5802 - val_accuracy: 0.9245\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5223 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5223 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.9057\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5246 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.9057\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5248 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5248 - accuracy: 1.0000 - val_loss: 1.5779 - val_accuracy: 0.9245\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5237 - accuracy: 1.0000 - val_loss: 1.5882 - val_accuracy: 0.8868\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5241 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5241 - accuracy: 1.0000 - val_loss: 1.5817 - val_accuracy: 0.9057\n",
            "Epoch 280/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5222 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5230 - accuracy: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.8491\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5251 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5251 - accuracy: 1.0000 - val_loss: 1.5826 - val_accuracy: 0.9057\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5232 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.9245\n",
            "Epoch 283/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5247 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5244 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.9434\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5242 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5242 - accuracy: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.9057\n",
            "Epoch 285/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5225 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5234 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.9245\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5227 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5227 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.9057\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5232 - accuracy: 1.0000 - val_loss: 1.5832 - val_accuracy: 0.8868\n",
            "Epoch 288/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5231 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5230 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.8868\n",
            "Epoch 289/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5232 - accuracy: 1.0000 - val_loss: 1.5854 - val_accuracy: 0.9434\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5237 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5237 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.9057\n",
            "Epoch 291/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5243 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5240 - accuracy: 1.0000 - val_loss: 1.5865 - val_accuracy: 0.8868\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5234 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5234 - accuracy: 1.0000 - val_loss: 1.5831 - val_accuracy: 0.8868\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5224 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5224 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.9057\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5229 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.9057\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5226 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5226 - accuracy: 1.0000 - val_loss: 1.5791 - val_accuracy: 0.9245\n",
            "Epoch 296/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5225 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5222 - accuracy: 1.0000 - val_loss: 1.5818 - val_accuracy: 0.9057\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5232 - accuracy: 1.0000 - val_loss: 1.5873 - val_accuracy: 0.9434\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.5229 - accuracy: 1.0000 - val_loss: 1.5807 - val_accuracy: 0.9057\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5208 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 1.5208 - accuracy: 1.0000 - val_loss: 1.5777 - val_accuracy: 0.9245\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5234 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.96226\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5234 - accuracy: 1.0000 - val_loss: 1.5784 - val_accuracy: 0.9245\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.5764 - accuracy: 0.9623\n",
            "8_Model evaluation:  [1.5764349699020386, 0.9622641801834106]    Now ACC: 92.54\n",
            "2/2 [==============================] - 3s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.94      1.00      0.97        17\n",
            "     boredom       1.00      0.75      0.86         4\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         7\n",
            "       happy       1.00      0.75      0.86         4\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "         sad       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.96        53\n",
            "   macro avg       0.98      0.93      0.95        53\n",
            "weighted avg       0.97      0.96      0.96        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 3.8055 - accuracy: 0.2427\n",
            "Epoch 1: val_accuracy improved from -inf to 0.24528, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 34s 287ms/step - loss: 3.8055 - accuracy: 0.2427 - val_loss: 2.8290 - val_accuracy: 0.2453\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 2.2538 - accuracy: 0.1680\n",
            "Epoch 2: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 2.2538 - accuracy: 0.1680 - val_loss: 2.1592 - val_accuracy: 0.1132\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9647 - accuracy: 0.1390\n",
            "Epoch 3: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.9647 - accuracy: 0.1390 - val_loss: 2.1687 - val_accuracy: 0.1321\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.2282\n",
            "Epoch 4: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.9463 - accuracy: 0.2282 - val_loss: 2.4475 - val_accuracy: 0.1321\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9353 - accuracy: 0.3029\n",
            "Epoch 5: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.9353 - accuracy: 0.3029 - val_loss: 2.3517 - val_accuracy: 0.2075\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9189 - accuracy: 0.3465\n",
            "Epoch 6: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.9189 - accuracy: 0.3465 - val_loss: 2.1090 - val_accuracy: 0.2075\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8954 - accuracy: 0.3817\n",
            "Epoch 7: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.8954 - accuracy: 0.3817 - val_loss: 1.9928 - val_accuracy: 0.2075\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8780 - accuracy: 0.4295\n",
            "Epoch 8: val_accuracy did not improve from 0.24528\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.8780 - accuracy: 0.4295 - val_loss: 1.9449 - val_accuracy: 0.2264\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8650 - accuracy: 0.4627\n",
            "Epoch 9: val_accuracy improved from 0.24528 to 0.26415, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.8650 - accuracy: 0.4627 - val_loss: 1.9449 - val_accuracy: 0.2642\n",
            "Epoch 10/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8583 - accuracy: 0.4397\n",
            "Epoch 10: val_accuracy improved from 0.26415 to 0.28302, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.8580 - accuracy: 0.4357 - val_loss: 1.9680 - val_accuracy: 0.2830\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8485 - accuracy: 0.4855\n",
            "Epoch 11: val_accuracy improved from 0.28302 to 0.32075, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.8485 - accuracy: 0.4855 - val_loss: 1.9681 - val_accuracy: 0.3208\n",
            "Epoch 12/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8414 - accuracy: 0.5112\n",
            "Epoch 12: val_accuracy improved from 0.32075 to 0.35849, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.8431 - accuracy: 0.5021 - val_loss: 1.9551 - val_accuracy: 0.3585\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8360 - accuracy: 0.4813\n",
            "Epoch 13: val_accuracy improved from 0.35849 to 0.37736, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.8360 - accuracy: 0.4813 - val_loss: 1.9248 - val_accuracy: 0.3774\n",
            "Epoch 14/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8281 - accuracy: 0.5402\n",
            "Epoch 14: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.8286 - accuracy: 0.5436 - val_loss: 1.9154 - val_accuracy: 0.3774\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8220 - accuracy: 0.5436\n",
            "Epoch 15: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.8220 - accuracy: 0.5436 - val_loss: 1.9316 - val_accuracy: 0.3774\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8111 - accuracy: 0.5913\n",
            "Epoch 16: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.8111 - accuracy: 0.5913 - val_loss: 1.9223 - val_accuracy: 0.3774\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8083 - accuracy: 0.5871\n",
            "Epoch 17: val_accuracy did not improve from 0.37736\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.8083 - accuracy: 0.5871 - val_loss: 1.9248 - val_accuracy: 0.3774\n",
            "Epoch 18/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8027 - accuracy: 0.5938\n",
            "Epoch 18: val_accuracy improved from 0.37736 to 0.41509, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.8018 - accuracy: 0.5934 - val_loss: 1.8949 - val_accuracy: 0.4151\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7983 - accuracy: 0.6079\n",
            "Epoch 19: val_accuracy improved from 0.41509 to 0.43396, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7983 - accuracy: 0.6079 - val_loss: 1.8966 - val_accuracy: 0.4340\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7861 - accuracy: 0.6266\n",
            "Epoch 20: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7861 - accuracy: 0.6266 - val_loss: 1.9097 - val_accuracy: 0.4151\n",
            "Epoch 21/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7871 - accuracy: 0.6429\n",
            "Epoch 21: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.7862 - accuracy: 0.6452 - val_loss: 1.9304 - val_accuracy: 0.3962\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7830 - accuracy: 0.6349\n",
            "Epoch 22: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.7830 - accuracy: 0.6349 - val_loss: 1.9507 - val_accuracy: 0.3774\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7734 - accuracy: 0.6743\n",
            "Epoch 23: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.7734 - accuracy: 0.6743 - val_loss: 1.9658 - val_accuracy: 0.3585\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7689 - accuracy: 0.7012\n",
            "Epoch 24: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.7689 - accuracy: 0.7012 - val_loss: 1.9557 - val_accuracy: 0.4151\n",
            "Epoch 25/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7611 - accuracy: 0.7366\n",
            "Epoch 25: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7647 - accuracy: 0.7261 - val_loss: 1.9443 - val_accuracy: 0.4340\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7641 - accuracy: 0.7033\n",
            "Epoch 26: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.7641 - accuracy: 0.7033 - val_loss: 1.9621 - val_accuracy: 0.4340\n",
            "Epoch 27/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7541 - accuracy: 0.7433\n",
            "Epoch 27: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7570 - accuracy: 0.7365 - val_loss: 1.9826 - val_accuracy: 0.3774\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7587 - accuracy: 0.7178\n",
            "Epoch 28: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.7587 - accuracy: 0.7178 - val_loss: 1.9847 - val_accuracy: 0.3396\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7556 - accuracy: 0.7407\n",
            "Epoch 29: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.7556 - accuracy: 0.7407 - val_loss: 1.9977 - val_accuracy: 0.3208\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7473 - accuracy: 0.7510\n",
            "Epoch 30: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.7473 - accuracy: 0.7510 - val_loss: 1.9397 - val_accuracy: 0.4340\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7414 - accuracy: 0.7386\n",
            "Epoch 31: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7414 - accuracy: 0.7386 - val_loss: 1.9451 - val_accuracy: 0.4340\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7389 - accuracy: 0.7656\n",
            "Epoch 32: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7389 - accuracy: 0.7656 - val_loss: 1.9439 - val_accuracy: 0.3962\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7383 - accuracy: 0.7801\n",
            "Epoch 33: val_accuracy did not improve from 0.43396\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7383 - accuracy: 0.7801 - val_loss: 1.9559 - val_accuracy: 0.4151\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7297 - accuracy: 0.7842\n",
            "Epoch 34: val_accuracy improved from 0.43396 to 0.45283, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.7297 - accuracy: 0.7842 - val_loss: 1.9696 - val_accuracy: 0.4528\n",
            "Epoch 35/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7310 - accuracy: 0.7902\n",
            "Epoch 35: val_accuracy did not improve from 0.45283\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.7335 - accuracy: 0.7822 - val_loss: 1.9563 - val_accuracy: 0.4340\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7263 - accuracy: 0.8050\n",
            "Epoch 36: val_accuracy improved from 0.45283 to 0.52830, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7263 - accuracy: 0.8050 - val_loss: 1.8796 - val_accuracy: 0.5283\n",
            "Epoch 37/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7310 - accuracy: 0.7969\n",
            "Epoch 37: val_accuracy improved from 0.52830 to 0.54717, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7278 - accuracy: 0.8050 - val_loss: 1.8666 - val_accuracy: 0.5472\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7275 - accuracy: 0.8091\n",
            "Epoch 38: val_accuracy improved from 0.54717 to 0.58491, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.7275 - accuracy: 0.8091 - val_loss: 1.8384 - val_accuracy: 0.5849\n",
            "Epoch 39/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7214 - accuracy: 0.8058\n",
            "Epoch 39: val_accuracy improved from 0.58491 to 0.67925, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7213 - accuracy: 0.8050 - val_loss: 1.8064 - val_accuracy: 0.6792\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7164 - accuracy: 0.8195\n",
            "Epoch 40: val_accuracy improved from 0.67925 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7164 - accuracy: 0.8195 - val_loss: 1.7891 - val_accuracy: 0.7170\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7110 - accuracy: 0.8340\n",
            "Epoch 41: val_accuracy improved from 0.71698 to 0.79245, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.7110 - accuracy: 0.8340 - val_loss: 1.7714 - val_accuracy: 0.7925\n",
            "Epoch 42/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7076 - accuracy: 0.8438\n",
            "Epoch 42: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7086 - accuracy: 0.8423 - val_loss: 1.7829 - val_accuracy: 0.7736\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7095 - accuracy: 0.8320\n",
            "Epoch 43: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7095 - accuracy: 0.8320 - val_loss: 1.7890 - val_accuracy: 0.7358\n",
            "Epoch 44/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7085 - accuracy: 0.8348\n",
            "Epoch 44: val_accuracy did not improve from 0.79245\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.7093 - accuracy: 0.8320 - val_loss: 1.7910 - val_accuracy: 0.7358\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7035 - accuracy: 0.8568\n",
            "Epoch 45: val_accuracy improved from 0.79245 to 0.81132, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 1.7035 - accuracy: 0.8568 - val_loss: 1.7660 - val_accuracy: 0.8113\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7002 - accuracy: 0.8506\n",
            "Epoch 46: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.7002 - accuracy: 0.8506 - val_loss: 1.7899 - val_accuracy: 0.7547\n",
            "Epoch 47/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7016 - accuracy: 0.8527\n",
            "Epoch 47: val_accuracy did not improve from 0.81132\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6999 - accuracy: 0.8548 - val_loss: 1.7488 - val_accuracy: 0.7925\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6947 - accuracy: 0.8797\n",
            "Epoch 48: val_accuracy improved from 0.81132 to 0.83019, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6947 - accuracy: 0.8797 - val_loss: 1.7244 - val_accuracy: 0.8302\n",
            "Epoch 49/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6957 - accuracy: 0.8705\n",
            "Epoch 49: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6952 - accuracy: 0.8714 - val_loss: 1.7283 - val_accuracy: 0.8302\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6878 - accuracy: 0.8797\n",
            "Epoch 50: val_accuracy improved from 0.83019 to 0.84906, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.6878 - accuracy: 0.8797 - val_loss: 1.7321 - val_accuracy: 0.8491\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6923 - accuracy: 0.8838\n",
            "Epoch 51: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6923 - accuracy: 0.8838 - val_loss: 1.7154 - val_accuracy: 0.8113\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6844 - accuracy: 0.8797\n",
            "Epoch 52: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.6844 - accuracy: 0.8797 - val_loss: 1.7136 - val_accuracy: 0.8113\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6859 - accuracy: 0.8859\n",
            "Epoch 53: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6859 - accuracy: 0.8859 - val_loss: 1.7060 - val_accuracy: 0.8302\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6837 - accuracy: 0.9025\n",
            "Epoch 54: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6837 - accuracy: 0.9025 - val_loss: 1.7106 - val_accuracy: 0.8113\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6819 - accuracy: 0.8900\n",
            "Epoch 55: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6819 - accuracy: 0.8900 - val_loss: 1.7120 - val_accuracy: 0.8302\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6804 - accuracy: 0.8838\n",
            "Epoch 56: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.6804 - accuracy: 0.8838 - val_loss: 1.7023 - val_accuracy: 0.8491\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6714 - accuracy: 0.9087\n",
            "Epoch 57: val_accuracy improved from 0.84906 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 1.6714 - accuracy: 0.9087 - val_loss: 1.6899 - val_accuracy: 0.8868\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6763 - accuracy: 0.9087\n",
            "Epoch 58: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6763 - accuracy: 0.9087 - val_loss: 1.6852 - val_accuracy: 0.8491\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6770 - accuracy: 0.8963\n",
            "Epoch 59: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6770 - accuracy: 0.8963 - val_loss: 1.6922 - val_accuracy: 0.8491\n",
            "Epoch 60/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6760 - accuracy: 0.8973\n",
            "Epoch 60: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6755 - accuracy: 0.9004 - val_loss: 1.6889 - val_accuracy: 0.8113\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6686 - accuracy: 0.9087\n",
            "Epoch 61: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6686 - accuracy: 0.9087 - val_loss: 1.6743 - val_accuracy: 0.8679\n",
            "Epoch 62/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6612 - accuracy: 0.9375\n",
            "Epoch 62: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6614 - accuracy: 0.9398 - val_loss: 1.6914 - val_accuracy: 0.8113\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6703 - accuracy: 0.9087\n",
            "Epoch 63: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6703 - accuracy: 0.9087 - val_loss: 1.6854 - val_accuracy: 0.8679\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6731 - accuracy: 0.8880\n",
            "Epoch 64: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6731 - accuracy: 0.8880 - val_loss: 1.6774 - val_accuracy: 0.8679\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6646 - accuracy: 0.9108\n",
            "Epoch 65: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6646 - accuracy: 0.9108 - val_loss: 1.6661 - val_accuracy: 0.8868\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6655 - accuracy: 0.9108\n",
            "Epoch 66: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.6655 - accuracy: 0.9108 - val_loss: 1.6752 - val_accuracy: 0.8491\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6571 - accuracy: 0.9149\n",
            "Epoch 67: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.6571 - accuracy: 0.9149 - val_loss: 1.6746 - val_accuracy: 0.8868\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6549 - accuracy: 0.9419\n",
            "Epoch 68: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6549 - accuracy: 0.9419 - val_loss: 1.6755 - val_accuracy: 0.8679\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6564 - accuracy: 0.9232\n",
            "Epoch 69: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6564 - accuracy: 0.9232 - val_loss: 1.6836 - val_accuracy: 0.8679\n",
            "Epoch 70/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6551 - accuracy: 0.9375\n",
            "Epoch 70: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6554 - accuracy: 0.9357 - val_loss: 1.6730 - val_accuracy: 0.8302\n",
            "Epoch 71/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6520 - accuracy: 0.9554\n",
            "Epoch 71: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6527 - accuracy: 0.9523 - val_loss: 1.6739 - val_accuracy: 0.8679\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6540 - accuracy: 0.9357\n",
            "Epoch 72: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6540 - accuracy: 0.9357 - val_loss: 1.6676 - val_accuracy: 0.8868\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6536 - accuracy: 0.9378\n",
            "Epoch 73: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6536 - accuracy: 0.9378 - val_loss: 1.6669 - val_accuracy: 0.8679\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6494 - accuracy: 0.9274\n",
            "Epoch 74: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6494 - accuracy: 0.9274 - val_loss: 1.6747 - val_accuracy: 0.8302\n",
            "Epoch 75/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6459 - accuracy: 0.9464\n",
            "Epoch 75: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6450 - accuracy: 0.9481 - val_loss: 1.6722 - val_accuracy: 0.8679\n",
            "Epoch 76/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6434 - accuracy: 0.9464\n",
            "Epoch 76: val_accuracy improved from 0.88679 to 0.90566, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6422 - accuracy: 0.9502 - val_loss: 1.6663 - val_accuracy: 0.9057\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6497 - accuracy: 0.9419\n",
            "Epoch 77: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6497 - accuracy: 0.9419 - val_loss: 1.6664 - val_accuracy: 0.9057\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6503 - accuracy: 0.9336\n",
            "Epoch 78: val_accuracy improved from 0.90566 to 0.92453, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 1.6503 - accuracy: 0.9336 - val_loss: 1.6682 - val_accuracy: 0.9245\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6462 - accuracy: 0.9585\n",
            "Epoch 79: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6462 - accuracy: 0.9585 - val_loss: 1.6659 - val_accuracy: 0.9057\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6467 - accuracy: 0.9502\n",
            "Epoch 80: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6467 - accuracy: 0.9502 - val_loss: 1.6642 - val_accuracy: 0.8679\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6458 - accuracy: 0.9440\n",
            "Epoch 81: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6458 - accuracy: 0.9440 - val_loss: 1.6639 - val_accuracy: 0.8868\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6440 - accuracy: 0.9564\n",
            "Epoch 82: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.6440 - accuracy: 0.9564 - val_loss: 1.6630 - val_accuracy: 0.8679\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6435 - accuracy: 0.9544\n",
            "Epoch 83: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6435 - accuracy: 0.9544 - val_loss: 1.6700 - val_accuracy: 0.8679\n",
            "Epoch 84/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6441 - accuracy: 0.9464\n",
            "Epoch 84: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6434 - accuracy: 0.9502 - val_loss: 1.6671 - val_accuracy: 0.9057\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6391 - accuracy: 0.9668\n",
            "Epoch 85: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6391 - accuracy: 0.9668 - val_loss: 1.6702 - val_accuracy: 0.8679\n",
            "Epoch 86/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6428 - accuracy: 0.9554\n",
            "Epoch 86: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6423 - accuracy: 0.9544 - val_loss: 1.6704 - val_accuracy: 0.8868\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6356 - accuracy: 0.9647\n",
            "Epoch 87: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6356 - accuracy: 0.9647 - val_loss: 1.6661 - val_accuracy: 0.8679\n",
            "Epoch 88/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6380 - accuracy: 0.9621\n",
            "Epoch 88: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6371 - accuracy: 0.9647 - val_loss: 1.6587 - val_accuracy: 0.9057\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6333 - accuracy: 0.9730\n",
            "Epoch 89: val_accuracy improved from 0.92453 to 0.94340, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_9.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.6333 - accuracy: 0.9730 - val_loss: 1.6604 - val_accuracy: 0.9434\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6390 - accuracy: 0.9668\n",
            "Epoch 90: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6390 - accuracy: 0.9668 - val_loss: 1.6647 - val_accuracy: 0.9245\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6368 - accuracy: 0.9481\n",
            "Epoch 91: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6368 - accuracy: 0.9481 - val_loss: 1.6767 - val_accuracy: 0.9057\n",
            "Epoch 92/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6338 - accuracy: 0.9643\n",
            "Epoch 92: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6332 - accuracy: 0.9668 - val_loss: 1.6820 - val_accuracy: 0.8491\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6314 - accuracy: 0.9647\n",
            "Epoch 93: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6314 - accuracy: 0.9647 - val_loss: 1.6725 - val_accuracy: 0.9057\n",
            "Epoch 94/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6322 - accuracy: 0.9643\n",
            "Epoch 94: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6308 - accuracy: 0.9668 - val_loss: 1.6625 - val_accuracy: 0.9057\n",
            "Epoch 95/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6323 - accuracy: 0.9754\n",
            "Epoch 95: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6313 - accuracy: 0.9772 - val_loss: 1.6644 - val_accuracy: 0.8679\n",
            "Epoch 96/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6311 - accuracy: 0.9844\n",
            "Epoch 96: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6312 - accuracy: 0.9834 - val_loss: 1.6687 - val_accuracy: 0.9057\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6285 - accuracy: 0.9813\n",
            "Epoch 97: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.6285 - accuracy: 0.9813 - val_loss: 1.6653 - val_accuracy: 0.8679\n",
            "Epoch 98/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6299 - accuracy: 0.9710\n",
            "Epoch 98: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6299 - accuracy: 0.9710 - val_loss: 1.6629 - val_accuracy: 0.8868\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6305 - accuracy: 0.9730\n",
            "Epoch 99: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6305 - accuracy: 0.9730 - val_loss: 1.6696 - val_accuracy: 0.8868\n",
            "Epoch 100/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6294 - accuracy: 0.9732\n",
            "Epoch 100: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6299 - accuracy: 0.9751 - val_loss: 1.6625 - val_accuracy: 0.8868\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6244 - accuracy: 0.9793\n",
            "Epoch 101: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6244 - accuracy: 0.9793 - val_loss: 1.6559 - val_accuracy: 0.8868\n",
            "Epoch 102/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6248 - accuracy: 0.9754\n",
            "Epoch 102: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6256 - accuracy: 0.9751 - val_loss: 1.6560 - val_accuracy: 0.9057\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6228 - accuracy: 0.9813\n",
            "Epoch 103: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6228 - accuracy: 0.9813 - val_loss: 1.6649 - val_accuracy: 0.8868\n",
            "Epoch 104/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6247 - accuracy: 0.9888\n",
            "Epoch 104: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6242 - accuracy: 0.9896 - val_loss: 1.6779 - val_accuracy: 0.8491\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6243 - accuracy: 0.9730\n",
            "Epoch 105: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6243 - accuracy: 0.9730 - val_loss: 1.6804 - val_accuracy: 0.8491\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6262 - accuracy: 0.9751\n",
            "Epoch 106: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.6262 - accuracy: 0.9751 - val_loss: 1.6759 - val_accuracy: 0.8679\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6245 - accuracy: 0.9813\n",
            "Epoch 107: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6245 - accuracy: 0.9813 - val_loss: 1.6737 - val_accuracy: 0.8679\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6230 - accuracy: 0.9813\n",
            "Epoch 108: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.6230 - accuracy: 0.9813 - val_loss: 1.6681 - val_accuracy: 0.8679\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6238 - accuracy: 0.9772\n",
            "Epoch 109: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6238 - accuracy: 0.9772 - val_loss: 1.6733 - val_accuracy: 0.8491\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6200 - accuracy: 0.9751\n",
            "Epoch 110: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6200 - accuracy: 0.9751 - val_loss: 1.6619 - val_accuracy: 0.9057\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6213 - accuracy: 0.9793\n",
            "Epoch 111: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.6213 - accuracy: 0.9793 - val_loss: 1.6524 - val_accuracy: 0.9245\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6222 - accuracy: 0.9834\n",
            "Epoch 112: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6222 - accuracy: 0.9834 - val_loss: 1.6584 - val_accuracy: 0.8679\n",
            "Epoch 113/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6208 - accuracy: 0.9821\n",
            "Epoch 113: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6220 - accuracy: 0.9813 - val_loss: 1.6571 - val_accuracy: 0.8868\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6202 - accuracy: 0.9855\n",
            "Epoch 114: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6202 - accuracy: 0.9855 - val_loss: 1.6591 - val_accuracy: 0.8868\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6174 - accuracy: 0.9896\n",
            "Epoch 115: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6174 - accuracy: 0.9896 - val_loss: 1.6645 - val_accuracy: 0.8679\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6163 - accuracy: 0.9876\n",
            "Epoch 116: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6163 - accuracy: 0.9876 - val_loss: 1.6613 - val_accuracy: 0.8868\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6153 - accuracy: 0.9938\n",
            "Epoch 117: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6153 - accuracy: 0.9938 - val_loss: 1.6572 - val_accuracy: 0.9245\n",
            "Epoch 118/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6177 - accuracy: 0.9911\n",
            "Epoch 118: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6175 - accuracy: 0.9917 - val_loss: 1.6585 - val_accuracy: 0.9057\n",
            "Epoch 119/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6168 - accuracy: 0.9844\n",
            "Epoch 119: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6177 - accuracy: 0.9834 - val_loss: 1.6594 - val_accuracy: 0.8868\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6150 - accuracy: 0.9896\n",
            "Epoch 120: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6150 - accuracy: 0.9896 - val_loss: 1.6544 - val_accuracy: 0.9434\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6156 - accuracy: 0.9917\n",
            "Epoch 121: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6156 - accuracy: 0.9917 - val_loss: 1.6518 - val_accuracy: 0.9434\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6150 - accuracy: 0.9938\n",
            "Epoch 122: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6150 - accuracy: 0.9938 - val_loss: 1.6564 - val_accuracy: 0.9245\n",
            "Epoch 123/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6128 - accuracy: 0.9955\n",
            "Epoch 123: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6134 - accuracy: 0.9938 - val_loss: 1.6524 - val_accuracy: 0.9245\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6151 - accuracy: 0.9979\n",
            "Epoch 124: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6151 - accuracy: 0.9979 - val_loss: 1.6507 - val_accuracy: 0.9057\n",
            "Epoch 125/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6129 - accuracy: 0.9955\n",
            "Epoch 125: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6121 - accuracy: 0.9938 - val_loss: 1.6516 - val_accuracy: 0.9245\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6129 - accuracy: 0.9917\n",
            "Epoch 126: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6129 - accuracy: 0.9917 - val_loss: 1.6493 - val_accuracy: 0.9245\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6128 - accuracy: 0.9896\n",
            "Epoch 127: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.6128 - accuracy: 0.9896 - val_loss: 1.6546 - val_accuracy: 0.9057\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6136 - accuracy: 0.9959\n",
            "Epoch 128: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6136 - accuracy: 0.9959 - val_loss: 1.6597 - val_accuracy: 0.9057\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6153 - accuracy: 0.9896\n",
            "Epoch 129: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6153 - accuracy: 0.9896 - val_loss: 1.6561 - val_accuracy: 0.9057\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6116 - accuracy: 0.9896\n",
            "Epoch 130: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6116 - accuracy: 0.9896 - val_loss: 1.6631 - val_accuracy: 0.8868\n",
            "Epoch 131/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6087 - accuracy: 0.9978\n",
            "Epoch 131: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6090 - accuracy: 0.9979 - val_loss: 1.6568 - val_accuracy: 0.9245\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6126 - accuracy: 0.9979\n",
            "Epoch 132: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6126 - accuracy: 0.9979 - val_loss: 1.6602 - val_accuracy: 0.9057\n",
            "Epoch 133/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6086 - accuracy: 0.9978\n",
            "Epoch 133: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6092 - accuracy: 0.9979 - val_loss: 1.6524 - val_accuracy: 0.9057\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6093 - accuracy: 0.9917\n",
            "Epoch 134: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6093 - accuracy: 0.9917 - val_loss: 1.6658 - val_accuracy: 0.8868\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6100 - accuracy: 0.9979\n",
            "Epoch 135: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6100 - accuracy: 0.9979 - val_loss: 1.6626 - val_accuracy: 0.8868\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6106 - accuracy: 0.9979\n",
            "Epoch 136: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6106 - accuracy: 0.9979 - val_loss: 1.6634 - val_accuracy: 0.8868\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6075 - accuracy: 1.0000\n",
            "Epoch 137: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6075 - accuracy: 1.0000 - val_loss: 1.6588 - val_accuracy: 0.9057\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6055 - accuracy: 0.9979\n",
            "Epoch 138: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.6055 - accuracy: 0.9979 - val_loss: 1.6564 - val_accuracy: 0.8868\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6087 - accuracy: 0.9938\n",
            "Epoch 139: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.6087 - accuracy: 0.9938 - val_loss: 1.6588 - val_accuracy: 0.8868\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6073 - accuracy: 0.9917\n",
            "Epoch 140: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6073 - accuracy: 0.9917 - val_loss: 1.6521 - val_accuracy: 0.9057\n",
            "Epoch 141/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6071 - accuracy: 0.9955\n",
            "Epoch 141: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6070 - accuracy: 0.9959 - val_loss: 1.6516 - val_accuracy: 0.9434\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6049 - accuracy: 1.0000\n",
            "Epoch 142: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6049 - accuracy: 1.0000 - val_loss: 1.6487 - val_accuracy: 0.9245\n",
            "Epoch 143/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6081 - accuracy: 0.9978\n",
            "Epoch 143: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6090 - accuracy: 0.9979 - val_loss: 1.6475 - val_accuracy: 0.9245\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6058 - accuracy: 0.9979\n",
            "Epoch 144: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6058 - accuracy: 0.9979 - val_loss: 1.6528 - val_accuracy: 0.9245\n",
            "Epoch 145/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6100 - accuracy: 0.9978\n",
            "Epoch 145: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6094 - accuracy: 0.9979 - val_loss: 1.6511 - val_accuracy: 0.9057\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6064 - accuracy: 0.9959\n",
            "Epoch 146: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6064 - accuracy: 0.9959 - val_loss: 1.6583 - val_accuracy: 0.8868\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6077 - accuracy: 0.9917\n",
            "Epoch 147: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6077 - accuracy: 0.9917 - val_loss: 1.6500 - val_accuracy: 0.9057\n",
            "Epoch 148/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6077 - accuracy: 0.9933\n",
            "Epoch 148: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6071 - accuracy: 0.9938 - val_loss: 1.6596 - val_accuracy: 0.9057\n",
            "Epoch 149/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6051 - accuracy: 0.9955\n",
            "Epoch 149: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6044 - accuracy: 0.9959 - val_loss: 1.6640 - val_accuracy: 0.8868\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 1.0000\n",
            "Epoch 150: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6037 - accuracy: 1.0000 - val_loss: 1.6730 - val_accuracy: 0.8679\n",
            "Epoch 151/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6056 - accuracy: 0.9978\n",
            "Epoch 151: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6060 - accuracy: 0.9979 - val_loss: 1.6538 - val_accuracy: 0.9057\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6044 - accuracy: 0.9959\n",
            "Epoch 152: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6044 - accuracy: 0.9959 - val_loss: 1.6469 - val_accuracy: 0.9245\n",
            "Epoch 153/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6062 - accuracy: 1.0000\n",
            "Epoch 153: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6066 - accuracy: 1.0000 - val_loss: 1.6755 - val_accuracy: 0.7736\n",
            "Epoch 154/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6027 - accuracy: 1.0000\n",
            "Epoch 154: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6033 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.9245\n",
            "Epoch 155/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6055 - accuracy: 0.9978\n",
            "Epoch 155: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6059 - accuracy: 0.9979 - val_loss: 1.6502 - val_accuracy: 0.9245\n",
            "Epoch 156/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6040 - accuracy: 1.0000\n",
            "Epoch 156: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6033 - accuracy: 1.0000 - val_loss: 1.6457 - val_accuracy: 0.9245\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6048 - accuracy: 0.9959\n",
            "Epoch 157: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6048 - accuracy: 0.9959 - val_loss: 1.6435 - val_accuracy: 0.9434\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6025 - accuracy: 0.9979\n",
            "Epoch 158: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6025 - accuracy: 0.9979 - val_loss: 1.6551 - val_accuracy: 0.8868\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6011 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6011 - accuracy: 1.0000 - val_loss: 1.6528 - val_accuracy: 0.8679\n",
            "Epoch 160/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6037 - accuracy: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6028 - accuracy: 1.0000 - val_loss: 1.6540 - val_accuracy: 0.9057\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6013 - accuracy: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.6013 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.9057\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6010 - accuracy: 1.0000\n",
            "Epoch 162: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 1.6010 - accuracy: 1.0000 - val_loss: 1.6459 - val_accuracy: 0.9057\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6021 - accuracy: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6021 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.9245\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6003 - accuracy: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6003 - accuracy: 1.0000 - val_loss: 1.6618 - val_accuracy: 0.8679\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6003 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.6003 - accuracy: 1.0000 - val_loss: 1.6536 - val_accuracy: 0.9057\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6030 - accuracy: 0.9959\n",
            "Epoch 166: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.6030 - accuracy: 0.9959 - val_loss: 1.6579 - val_accuracy: 0.9057\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6022 - accuracy: 0.9959\n",
            "Epoch 167: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 1.6022 - accuracy: 0.9959 - val_loss: 1.6518 - val_accuracy: 0.9245\n",
            "Epoch 168/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6038 - accuracy: 0.9978\n",
            "Epoch 168: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6048 - accuracy: 0.9979 - val_loss: 1.6571 - val_accuracy: 0.8679\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6014 - accuracy: 0.9959\n",
            "Epoch 169: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6014 - accuracy: 0.9959 - val_loss: 1.6514 - val_accuracy: 0.9057\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5996 - accuracy: 0.9979\n",
            "Epoch 170: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5996 - accuracy: 0.9979 - val_loss: 1.6505 - val_accuracy: 0.9057\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6036 - accuracy: 0.9959\n",
            "Epoch 171: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6036 - accuracy: 0.9959 - val_loss: 1.6508 - val_accuracy: 0.9057\n",
            "Epoch 172/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5997 - accuracy: 0.9978\n",
            "Epoch 172: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5998 - accuracy: 0.9979 - val_loss: 1.6484 - val_accuracy: 0.9057\n",
            "Epoch 173/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5996 - accuracy: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5995 - accuracy: 1.0000 - val_loss: 1.6549 - val_accuracy: 0.8868\n",
            "Epoch 174/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5996 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6004 - accuracy: 0.9979 - val_loss: 1.6481 - val_accuracy: 0.9245\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6004 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6004 - accuracy: 1.0000 - val_loss: 1.6508 - val_accuracy: 0.9057\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5987 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5987 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.9434\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6002 - accuracy: 0.9979\n",
            "Epoch 177: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6002 - accuracy: 0.9979 - val_loss: 1.6458 - val_accuracy: 0.9245\n",
            "Epoch 178/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5984 - accuracy: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5995 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.9245\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6004 - accuracy: 0.9979\n",
            "Epoch 179: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6004 - accuracy: 0.9979 - val_loss: 1.6490 - val_accuracy: 0.9245\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5983 - accuracy: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5983 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.9245\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5978 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.5978 - accuracy: 1.0000 - val_loss: 1.6510 - val_accuracy: 0.9057\n",
            "Epoch 182/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5967 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5969 - accuracy: 1.0000 - val_loss: 1.6514 - val_accuracy: 0.9434\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5978 - accuracy: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5978 - accuracy: 1.0000 - val_loss: 1.6431 - val_accuracy: 0.9057\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5987 - accuracy: 0.9979\n",
            "Epoch 184: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5987 - accuracy: 0.9979 - val_loss: 1.6416 - val_accuracy: 0.9434\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5987 - accuracy: 0.9979\n",
            "Epoch 185: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5987 - accuracy: 0.9979 - val_loss: 1.6439 - val_accuracy: 0.9434\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5992 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5992 - accuracy: 1.0000 - val_loss: 1.6515 - val_accuracy: 0.9434\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5966 - accuracy: 1.0000 - val_loss: 1.6495 - val_accuracy: 0.9434\n",
            "Epoch 188/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5973 - accuracy: 1.0000\n",
            "Epoch 188: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5979 - accuracy: 0.9979 - val_loss: 1.6467 - val_accuracy: 0.9434\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5964 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.9057\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5971 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5971 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.9245\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5963 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.5963 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.9057\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5969 - accuracy: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5969 - accuracy: 1.0000 - val_loss: 1.6559 - val_accuracy: 0.9057\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5980 - accuracy: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5980 - accuracy: 1.0000 - val_loss: 1.6523 - val_accuracy: 0.9057\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5967 - accuracy: 0.9979\n",
            "Epoch 194: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.5967 - accuracy: 0.9979 - val_loss: 1.6527 - val_accuracy: 0.9057\n",
            "Epoch 195/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5991 - accuracy: 0.9955\n",
            "Epoch 195: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 1.5988 - accuracy: 0.9959 - val_loss: 1.6485 - val_accuracy: 0.9057\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5963 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5963 - accuracy: 1.0000 - val_loss: 1.6537 - val_accuracy: 0.9057\n",
            "Epoch 197/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5958 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5955 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.9245\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5969 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5969 - accuracy: 1.0000 - val_loss: 1.6501 - val_accuracy: 0.9057\n",
            "Epoch 199/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5957 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5960 - accuracy: 1.0000 - val_loss: 1.6466 - val_accuracy: 0.9245\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5956 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5956 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.9245\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.9979\n",
            "Epoch 201: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5990 - accuracy: 0.9979 - val_loss: 1.6584 - val_accuracy: 0.9245\n",
            "Epoch 202/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5972 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5975 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.9057\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5953 - accuracy: 1.0000\n",
            "Epoch 203: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5953 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.9245\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5965 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5965 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.9245\n",
            "Epoch 205/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5943 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5947 - accuracy: 1.0000 - val_loss: 1.6489 - val_accuracy: 0.9434\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5957 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5957 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.9434\n",
            "Epoch 207/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5952 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5947 - accuracy: 1.0000 - val_loss: 1.6451 - val_accuracy: 0.9245\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5974 - accuracy: 0.9979\n",
            "Epoch 208: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5974 - accuracy: 0.9979 - val_loss: 1.6461 - val_accuracy: 0.9434\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5954 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5954 - accuracy: 1.0000 - val_loss: 1.6497 - val_accuracy: 0.9245\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5952 - accuracy: 0.9979\n",
            "Epoch 210: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5952 - accuracy: 0.9979 - val_loss: 1.6428 - val_accuracy: 0.9434\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5972 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5972 - accuracy: 1.0000 - val_loss: 1.6501 - val_accuracy: 0.9434\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5948 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5948 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.9434\n",
            "Epoch 213/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5922 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5919 - accuracy: 1.0000 - val_loss: 1.6481 - val_accuracy: 0.9434\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5924 - accuracy: 0.9979\n",
            "Epoch 214: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5924 - accuracy: 0.9979 - val_loss: 1.6497 - val_accuracy: 0.9434\n",
            "Epoch 215/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5967 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5967 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.9057\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5955 - accuracy: 0.9979\n",
            "Epoch 216: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5955 - accuracy: 0.9979 - val_loss: 1.6492 - val_accuracy: 0.9434\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5944 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.5944 - accuracy: 1.0000 - val_loss: 1.6598 - val_accuracy: 0.9057\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5975 - accuracy: 1.0000\n",
            "Epoch 218: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5975 - accuracy: 1.0000 - val_loss: 1.6543 - val_accuracy: 0.9245\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5972 - accuracy: 0.9979\n",
            "Epoch 219: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5972 - accuracy: 0.9979 - val_loss: 1.6416 - val_accuracy: 0.9245\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5927 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.9434\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5956 - accuracy: 1.0000\n",
            "Epoch 221: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5956 - accuracy: 1.0000 - val_loss: 1.6542 - val_accuracy: 0.9245\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5944 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.5944 - accuracy: 1.0000 - val_loss: 1.6472 - val_accuracy: 0.9434\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5935 - accuracy: 0.9979\n",
            "Epoch 223: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 61ms/step - loss: 1.5935 - accuracy: 0.9979 - val_loss: 1.6433 - val_accuracy: 0.9245\n",
            "Epoch 224/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5930 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5937 - accuracy: 1.0000 - val_loss: 1.6437 - val_accuracy: 0.9245\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5953 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5953 - accuracy: 1.0000 - val_loss: 1.6424 - val_accuracy: 0.9245\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5928 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5928 - accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 0.8868\n",
            "Epoch 227/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5928 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5929 - accuracy: 1.0000 - val_loss: 1.6521 - val_accuracy: 0.8679\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5932 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5932 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.9057\n",
            "Epoch 229/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5919 - accuracy: 1.0000\n",
            "Epoch 229: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5924 - accuracy: 1.0000 - val_loss: 1.6534 - val_accuracy: 0.8868\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5940 - accuracy: 0.9979\n",
            "Epoch 230: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5940 - accuracy: 0.9979 - val_loss: 1.6497 - val_accuracy: 0.9245\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5931 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5931 - accuracy: 1.0000 - val_loss: 1.6516 - val_accuracy: 0.9245\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5933 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5933 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.9245\n",
            "Epoch 233/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5912 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5917 - accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 0.9245\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5928 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5928 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.9245\n",
            "Epoch 235/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5932 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5938 - accuracy: 1.0000 - val_loss: 1.6456 - val_accuracy: 0.9245\n",
            "Epoch 236/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5931 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5937 - accuracy: 1.0000 - val_loss: 1.6531 - val_accuracy: 0.8868\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5921 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5921 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.9057\n",
            "Epoch 238/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5938 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5931 - accuracy: 1.0000 - val_loss: 1.6508 - val_accuracy: 0.8868\n",
            "Epoch 239/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5918 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5915 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.9434\n",
            "Epoch 240/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5917 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5922 - accuracy: 1.0000 - val_loss: 1.6405 - val_accuracy: 0.9245\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5922 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5922 - accuracy: 1.0000 - val_loss: 1.6406 - val_accuracy: 0.9245\n",
            "Epoch 242/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5909 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5905 - accuracy: 1.0000 - val_loss: 1.6462 - val_accuracy: 0.9057\n",
            "Epoch 243/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5913 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5908 - accuracy: 1.0000 - val_loss: 1.6474 - val_accuracy: 0.9245\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5911 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5911 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.9245\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5925 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 1.5925 - accuracy: 1.0000 - val_loss: 1.6532 - val_accuracy: 0.9057\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5903 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5903 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.9245\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5915 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.5915 - accuracy: 1.0000 - val_loss: 1.6467 - val_accuracy: 0.9245\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5920 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.5920 - accuracy: 1.0000 - val_loss: 1.6551 - val_accuracy: 0.8868\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5891 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 1.5891 - accuracy: 1.0000 - val_loss: 1.6528 - val_accuracy: 0.8679\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5900 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5900 - accuracy: 1.0000 - val_loss: 1.6515 - val_accuracy: 0.9057\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5905 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 1.5905 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.9245\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5913 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5913 - accuracy: 1.0000 - val_loss: 1.6460 - val_accuracy: 0.9245\n",
            "Epoch 253/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5901 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5904 - accuracy: 1.0000 - val_loss: 1.6479 - val_accuracy: 0.9057\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5912 - accuracy: 0.9979\n",
            "Epoch 254: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5912 - accuracy: 0.9979 - val_loss: 1.6429 - val_accuracy: 0.8868\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5912 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5912 - accuracy: 1.0000 - val_loss: 1.6505 - val_accuracy: 0.9057\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5915 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5915 - accuracy: 1.0000 - val_loss: 1.6444 - val_accuracy: 0.9245\n",
            "Epoch 257/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5915 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5915 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.9245\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5912 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5912 - accuracy: 1.0000 - val_loss: 1.6450 - val_accuracy: 0.9434\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5892 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5892 - accuracy: 1.0000 - val_loss: 1.6464 - val_accuracy: 0.9434\n",
            "Epoch 260/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5909 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5909 - accuracy: 1.0000 - val_loss: 1.6463 - val_accuracy: 0.9057\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5904 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.9057\n",
            "Epoch 262/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5906 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5903 - accuracy: 1.0000 - val_loss: 1.6444 - val_accuracy: 0.9057\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5888 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5888 - accuracy: 1.0000 - val_loss: 1.6456 - val_accuracy: 0.9057\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5904 - accuracy: 1.0000 - val_loss: 1.6517 - val_accuracy: 0.9057\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5892 - accuracy: 1.0000\n",
            "Epoch 265: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5892 - accuracy: 1.0000 - val_loss: 1.6443 - val_accuracy: 0.9245\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5917 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5917 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.9434\n",
            "Epoch 267/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5902 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5897 - accuracy: 1.0000 - val_loss: 1.6446 - val_accuracy: 0.9245\n",
            "Epoch 268/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5910 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5904 - accuracy: 1.0000 - val_loss: 1.6436 - val_accuracy: 0.9057\n",
            "Epoch 269/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5906 - accuracy: 0.9978\n",
            "Epoch 269: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5906 - accuracy: 0.9979 - val_loss: 1.6400 - val_accuracy: 0.9057\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5893 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.5893 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.9434\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5899 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.9434\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 0.9979\n",
            "Epoch 272: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5896 - accuracy: 0.9979 - val_loss: 1.6468 - val_accuracy: 0.9245\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.5898 - accuracy: 1.0000 - val_loss: 1.6401 - val_accuracy: 0.9057\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5892 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.5892 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.9434\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.5898 - accuracy: 1.0000 - val_loss: 1.6446 - val_accuracy: 0.9245\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.5896 - accuracy: 1.0000 - val_loss: 1.6427 - val_accuracy: 0.9057\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5904 - accuracy: 1.0000 - val_loss: 1.6500 - val_accuracy: 0.9057\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.5896 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.9057\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5896 - accuracy: 1.0000 - val_loss: 1.6446 - val_accuracy: 0.9057\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5881 - accuracy: 1.0000 - val_loss: 1.6456 - val_accuracy: 0.8868\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5890 - accuracy: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.9245\n",
            "Epoch 282/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5892 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5888 - accuracy: 1.0000 - val_loss: 1.6505 - val_accuracy: 0.9057\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5879 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5879 - accuracy: 1.0000 - val_loss: 1.6462 - val_accuracy: 0.9057\n",
            "Epoch 284/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5892 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5890 - accuracy: 1.0000 - val_loss: 1.6519 - val_accuracy: 0.8868\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5888 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5888 - accuracy: 1.0000 - val_loss: 1.6389 - val_accuracy: 0.9245\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5885 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5885 - accuracy: 1.0000 - val_loss: 1.6451 - val_accuracy: 0.8868\n",
            "Epoch 287/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5892 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5889 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.9057\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5902 - accuracy: 0.9979\n",
            "Epoch 288: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5902 - accuracy: 0.9979 - val_loss: 1.6457 - val_accuracy: 0.9057\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5894 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5894 - accuracy: 1.0000 - val_loss: 1.6452 - val_accuracy: 0.9245\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5895 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.5895 - accuracy: 1.0000 - val_loss: 1.6389 - val_accuracy: 0.9245\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5878 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.5878 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.9245\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5878 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5878 - accuracy: 1.0000 - val_loss: 1.6463 - val_accuracy: 0.9245\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5871 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.9245\n",
            "Epoch 294/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5885 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5883 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.9245\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5885 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5885 - accuracy: 1.0000 - val_loss: 1.6418 - val_accuracy: 0.9245\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5882 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.5882 - accuracy: 1.0000 - val_loss: 1.6387 - val_accuracy: 0.9245\n",
            "Epoch 297/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5902 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.5899 - accuracy: 1.0000 - val_loss: 1.6400 - val_accuracy: 0.9245\n",
            "Epoch 298/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5884 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5884 - accuracy: 1.0000 - val_loss: 1.6425 - val_accuracy: 0.9057\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.5877 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5877 - accuracy: 1.0000 - val_loss: 1.6443 - val_accuracy: 0.8868\n",
            "Epoch 300/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.5873 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5874 - accuracy: 1.0000 - val_loss: 1.6487 - val_accuracy: 0.9057\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6604 - accuracy: 0.9434\n",
            "9_Model evaluation:  [1.660438060760498, 0.9433962106704712]    Now ACC: 92.74\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        11\n",
            "     boredom       0.86      1.00      0.92         6\n",
            "     disgust       1.00      0.75      0.86         4\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       1.00      1.00      1.00        13\n",
            "     neutral       0.75      0.86      0.80         7\n",
            "         sad       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.94        53\n",
            "   macro avg       0.94      0.92      0.93        53\n",
            "weighted avg       0.95      0.94      0.94        53\n",
            "\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "Epoch 1/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.9623 - accuracy: 0.2098\n",
            "Epoch 1: val_accuracy improved from -inf to 0.22642, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 35s 335ms/step - loss: 1.9607 - accuracy: 0.2158 - val_loss: 2.0848 - val_accuracy: 0.2264\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.9210 - accuracy: 0.3548\n",
            "Epoch 2: val_accuracy did not improve from 0.22642\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.9210 - accuracy: 0.3548 - val_loss: 2.2964 - val_accuracy: 0.2264\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8966 - accuracy: 0.3797\n",
            "Epoch 3: val_accuracy did not improve from 0.22642\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.8966 - accuracy: 0.3797 - val_loss: 2.4793 - val_accuracy: 0.2264\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8855 - accuracy: 0.4025\n",
            "Epoch 4: val_accuracy improved from 0.22642 to 0.32075, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.8855 - accuracy: 0.4025 - val_loss: 2.3585 - val_accuracy: 0.3208\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8718 - accuracy: 0.4564\n",
            "Epoch 5: val_accuracy improved from 0.32075 to 0.39623, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.8718 - accuracy: 0.4564 - val_loss: 2.2613 - val_accuracy: 0.3962\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8607 - accuracy: 0.4689\n",
            "Epoch 6: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.8607 - accuracy: 0.4689 - val_loss: 2.3478 - val_accuracy: 0.3019\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8515 - accuracy: 0.5166\n",
            "Epoch 7: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.8515 - accuracy: 0.5166 - val_loss: 2.4078 - val_accuracy: 0.3019\n",
            "Epoch 8/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8397 - accuracy: 0.5714\n",
            "Epoch 8: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.8392 - accuracy: 0.5726 - val_loss: 2.3865 - val_accuracy: 0.2453\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8363 - accuracy: 0.5830\n",
            "Epoch 9: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.8363 - accuracy: 0.5830 - val_loss: 2.3432 - val_accuracy: 0.2453\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8253 - accuracy: 0.5934\n",
            "Epoch 10: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.8253 - accuracy: 0.5934 - val_loss: 2.3099 - val_accuracy: 0.2453\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8216 - accuracy: 0.6224\n",
            "Epoch 11: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.8216 - accuracy: 0.6224 - val_loss: 2.2835 - val_accuracy: 0.2453\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8182 - accuracy: 0.6245\n",
            "Epoch 12: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.8182 - accuracy: 0.6245 - val_loss: 2.1724 - val_accuracy: 0.3396\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.8061 - accuracy: 0.6452\n",
            "Epoch 13: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.8061 - accuracy: 0.6452 - val_loss: 2.1761 - val_accuracy: 0.3396\n",
            "Epoch 14/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.8017 - accuracy: 0.6853\n",
            "Epoch 14: val_accuracy did not improve from 0.39623\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.8013 - accuracy: 0.6888 - val_loss: 2.1062 - val_accuracy: 0.3774\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7997 - accuracy: 0.6556\n",
            "Epoch 15: val_accuracy improved from 0.39623 to 0.43396, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7997 - accuracy: 0.6556 - val_loss: 2.0780 - val_accuracy: 0.4340\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7945 - accuracy: 0.6826\n",
            "Epoch 16: val_accuracy improved from 0.43396 to 0.50943, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 1.7945 - accuracy: 0.6826 - val_loss: 2.0448 - val_accuracy: 0.5094\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7865 - accuracy: 0.7241\n",
            "Epoch 17: val_accuracy did not improve from 0.50943\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.7865 - accuracy: 0.7241 - val_loss: 2.0256 - val_accuracy: 0.4906\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7785 - accuracy: 0.7386\n",
            "Epoch 18: val_accuracy did not improve from 0.50943\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.7785 - accuracy: 0.7386 - val_loss: 1.9451 - val_accuracy: 0.5094\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7752 - accuracy: 0.7469\n",
            "Epoch 19: val_accuracy improved from 0.50943 to 0.52830, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.7752 - accuracy: 0.7469 - val_loss: 1.8916 - val_accuracy: 0.5283\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7719 - accuracy: 0.7656\n",
            "Epoch 20: val_accuracy did not improve from 0.52830\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7719 - accuracy: 0.7656 - val_loss: 1.8814 - val_accuracy: 0.5283\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7639 - accuracy: 0.7739\n",
            "Epoch 21: val_accuracy improved from 0.52830 to 0.60377, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.7639 - accuracy: 0.7739 - val_loss: 1.8493 - val_accuracy: 0.6038\n",
            "Epoch 22/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7691 - accuracy: 0.7634\n",
            "Epoch 22: val_accuracy did not improve from 0.60377\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7675 - accuracy: 0.7676 - val_loss: 1.8356 - val_accuracy: 0.5660\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7597 - accuracy: 0.7842\n",
            "Epoch 23: val_accuracy did not improve from 0.60377\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7597 - accuracy: 0.7842 - val_loss: 1.8434 - val_accuracy: 0.5472\n",
            "Epoch 24/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7559 - accuracy: 0.8170\n",
            "Epoch 24: val_accuracy did not improve from 0.60377\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7550 - accuracy: 0.8174 - val_loss: 1.8128 - val_accuracy: 0.5849\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7520 - accuracy: 0.8154\n",
            "Epoch 25: val_accuracy improved from 0.60377 to 0.67925, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7520 - accuracy: 0.8154 - val_loss: 1.7984 - val_accuracy: 0.6792\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7489 - accuracy: 0.8278\n",
            "Epoch 26: val_accuracy did not improve from 0.67925\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7489 - accuracy: 0.8278 - val_loss: 1.7937 - val_accuracy: 0.6604\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7510 - accuracy: 0.8278\n",
            "Epoch 27: val_accuracy improved from 0.67925 to 0.71698, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7510 - accuracy: 0.8278 - val_loss: 1.8055 - val_accuracy: 0.7170\n",
            "Epoch 28/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7427 - accuracy: 0.8594\n",
            "Epoch 28: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7422 - accuracy: 0.8589 - val_loss: 1.8207 - val_accuracy: 0.6981\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7411 - accuracy: 0.8361\n",
            "Epoch 29: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.7411 - accuracy: 0.8361 - val_loss: 1.7902 - val_accuracy: 0.6981\n",
            "Epoch 30/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7349 - accuracy: 0.8527\n",
            "Epoch 30: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7347 - accuracy: 0.8568 - val_loss: 1.7947 - val_accuracy: 0.6415\n",
            "Epoch 31/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7324 - accuracy: 0.8594\n",
            "Epoch 31: val_accuracy did not improve from 0.71698\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7321 - accuracy: 0.8568 - val_loss: 1.8206 - val_accuracy: 0.6226\n",
            "Epoch 32/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7325 - accuracy: 0.8772\n",
            "Epoch 32: val_accuracy improved from 0.71698 to 0.73585, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7330 - accuracy: 0.8714 - val_loss: 1.7918 - val_accuracy: 0.7358\n",
            "Epoch 33/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7330 - accuracy: 0.8683\n",
            "Epoch 33: val_accuracy did not improve from 0.73585\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.7331 - accuracy: 0.8672 - val_loss: 1.7835 - val_accuracy: 0.6415\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7278 - accuracy: 0.8714\n",
            "Epoch 34: val_accuracy improved from 0.73585 to 0.75472, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7278 - accuracy: 0.8714 - val_loss: 1.7687 - val_accuracy: 0.7547\n",
            "Epoch 35/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7232 - accuracy: 0.8929\n",
            "Epoch 35: val_accuracy did not improve from 0.75472\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7252 - accuracy: 0.8900 - val_loss: 1.7630 - val_accuracy: 0.7358\n",
            "Epoch 36/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7258 - accuracy: 0.8839\n",
            "Epoch 36: val_accuracy improved from 0.75472 to 0.77358, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7252 - accuracy: 0.8880 - val_loss: 1.7815 - val_accuracy: 0.7736\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7204 - accuracy: 0.8880\n",
            "Epoch 37: val_accuracy improved from 0.77358 to 0.79245, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7204 - accuracy: 0.8880 - val_loss: 1.7577 - val_accuracy: 0.7925\n",
            "Epoch 38/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7163 - accuracy: 0.9085\n",
            "Epoch 38: val_accuracy improved from 0.79245 to 0.81132, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.7175 - accuracy: 0.9025 - val_loss: 1.7482 - val_accuracy: 0.8113\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7235 - accuracy: 0.8714\n",
            "Epoch 39: val_accuracy improved from 0.81132 to 0.83019, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.7235 - accuracy: 0.8714 - val_loss: 1.7448 - val_accuracy: 0.8302\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7170 - accuracy: 0.8900\n",
            "Epoch 40: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.7170 - accuracy: 0.8900 - val_loss: 1.7454 - val_accuracy: 0.8302\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7161 - accuracy: 0.9087\n",
            "Epoch 41: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7161 - accuracy: 0.9087 - val_loss: 1.7479 - val_accuracy: 0.8302\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7164 - accuracy: 0.9066\n",
            "Epoch 42: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.7164 - accuracy: 0.9066 - val_loss: 1.7570 - val_accuracy: 0.7547\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7123 - accuracy: 0.9191\n",
            "Epoch 43: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.7123 - accuracy: 0.9191 - val_loss: 1.7474 - val_accuracy: 0.8302\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7118 - accuracy: 0.9315\n",
            "Epoch 44: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.7118 - accuracy: 0.9315 - val_loss: 1.7455 - val_accuracy: 0.8302\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7142 - accuracy: 0.8963\n",
            "Epoch 45: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.7142 - accuracy: 0.8963 - val_loss: 1.7596 - val_accuracy: 0.7358\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7084 - accuracy: 0.9274\n",
            "Epoch 46: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.7084 - accuracy: 0.9274 - val_loss: 1.7669 - val_accuracy: 0.7358\n",
            "Epoch 47/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7099 - accuracy: 0.9152\n",
            "Epoch 47: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7101 - accuracy: 0.9191 - val_loss: 1.7713 - val_accuracy: 0.7170\n",
            "Epoch 48/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7061 - accuracy: 0.9308\n",
            "Epoch 48: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7069 - accuracy: 0.9274 - val_loss: 1.7845 - val_accuracy: 0.6415\n",
            "Epoch 49/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7002 - accuracy: 0.9554\n",
            "Epoch 49: val_accuracy did not improve from 0.83019\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.7014 - accuracy: 0.9502 - val_loss: 1.7527 - val_accuracy: 0.7925\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7097 - accuracy: 0.9232\n",
            "Epoch 50: val_accuracy improved from 0.83019 to 0.84906, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.7097 - accuracy: 0.9232 - val_loss: 1.7331 - val_accuracy: 0.8491\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7016 - accuracy: 0.9502\n",
            "Epoch 51: val_accuracy did not improve from 0.84906\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 1.7016 - accuracy: 0.9502 - val_loss: 1.7564 - val_accuracy: 0.7547\n",
            "Epoch 52/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7022 - accuracy: 0.9464\n",
            "Epoch 52: val_accuracy improved from 0.84906 to 0.86792, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.7013 - accuracy: 0.9461 - val_loss: 1.7267 - val_accuracy: 0.8679\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7023 - accuracy: 0.9170\n",
            "Epoch 53: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.7023 - accuracy: 0.9170 - val_loss: 1.7241 - val_accuracy: 0.8491\n",
            "Epoch 54/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.7020 - accuracy: 0.9442\n",
            "Epoch 54: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.7016 - accuracy: 0.9481 - val_loss: 1.7285 - val_accuracy: 0.8679\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6982 - accuracy: 0.9398\n",
            "Epoch 55: val_accuracy did not improve from 0.86792\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6982 - accuracy: 0.9398 - val_loss: 1.7390 - val_accuracy: 0.8113\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6992 - accuracy: 0.9398\n",
            "Epoch 56: val_accuracy improved from 0.86792 to 0.88679, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6992 - accuracy: 0.9398 - val_loss: 1.7272 - val_accuracy: 0.8868\n",
            "Epoch 57/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6950 - accuracy: 0.9576\n",
            "Epoch 57: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6949 - accuracy: 0.9564 - val_loss: 1.7264 - val_accuracy: 0.8491\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.7004 - accuracy: 0.9274\n",
            "Epoch 58: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.7004 - accuracy: 0.9274 - val_loss: 1.7389 - val_accuracy: 0.8491\n",
            "Epoch 59/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6952 - accuracy: 0.9509\n",
            "Epoch 59: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6951 - accuracy: 0.9502 - val_loss: 1.7398 - val_accuracy: 0.8679\n",
            "Epoch 60/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6910 - accuracy: 0.9665\n",
            "Epoch 60: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6916 - accuracy: 0.9647 - val_loss: 1.7423 - val_accuracy: 0.8679\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6922 - accuracy: 0.9523\n",
            "Epoch 61: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6922 - accuracy: 0.9523 - val_loss: 1.7428 - val_accuracy: 0.7925\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6933 - accuracy: 0.9564\n",
            "Epoch 62: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6933 - accuracy: 0.9564 - val_loss: 1.7408 - val_accuracy: 0.7736\n",
            "Epoch 63/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6879 - accuracy: 0.9665\n",
            "Epoch 63: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6889 - accuracy: 0.9647 - val_loss: 1.7509 - val_accuracy: 0.7925\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6888 - accuracy: 0.9627\n",
            "Epoch 64: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6888 - accuracy: 0.9627 - val_loss: 1.7573 - val_accuracy: 0.7170\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6865 - accuracy: 0.9751\n",
            "Epoch 65: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6865 - accuracy: 0.9751 - val_loss: 1.7419 - val_accuracy: 0.8113\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6886 - accuracy: 0.9772\n",
            "Epoch 66: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6886 - accuracy: 0.9772 - val_loss: 1.7432 - val_accuracy: 0.8113\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6864 - accuracy: 0.9647\n",
            "Epoch 67: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6864 - accuracy: 0.9647 - val_loss: 1.7281 - val_accuracy: 0.8868\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6851 - accuracy: 0.9647\n",
            "Epoch 68: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6851 - accuracy: 0.9647 - val_loss: 1.7429 - val_accuracy: 0.7736\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6844 - accuracy: 0.9772\n",
            "Epoch 69: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.6844 - accuracy: 0.9772 - val_loss: 1.7395 - val_accuracy: 0.8302\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6857 - accuracy: 0.9710\n",
            "Epoch 70: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 1.6857 - accuracy: 0.9710 - val_loss: 1.7340 - val_accuracy: 0.8302\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6842 - accuracy: 0.9751\n",
            "Epoch 71: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6842 - accuracy: 0.9751 - val_loss: 1.7299 - val_accuracy: 0.8302\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6833 - accuracy: 0.9751\n",
            "Epoch 72: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6833 - accuracy: 0.9751 - val_loss: 1.7445 - val_accuracy: 0.8113\n",
            "Epoch 73/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6818 - accuracy: 0.9777\n",
            "Epoch 73: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6821 - accuracy: 0.9751 - val_loss: 1.7278 - val_accuracy: 0.8868\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6799 - accuracy: 0.9710\n",
            "Epoch 74: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6799 - accuracy: 0.9710 - val_loss: 1.7308 - val_accuracy: 0.8491\n",
            "Epoch 75/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6807 - accuracy: 0.9754\n",
            "Epoch 75: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6811 - accuracy: 0.9751 - val_loss: 1.7315 - val_accuracy: 0.8302\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6798 - accuracy: 0.9751\n",
            "Epoch 76: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6798 - accuracy: 0.9751 - val_loss: 1.7285 - val_accuracy: 0.8679\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6764 - accuracy: 0.9855\n",
            "Epoch 77: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6764 - accuracy: 0.9855 - val_loss: 1.7230 - val_accuracy: 0.8868\n",
            "Epoch 78/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6798 - accuracy: 0.9799\n",
            "Epoch 78: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6803 - accuracy: 0.9793 - val_loss: 1.7249 - val_accuracy: 0.8679\n",
            "Epoch 79/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6813 - accuracy: 0.9754\n",
            "Epoch 79: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6801 - accuracy: 0.9772 - val_loss: 1.7266 - val_accuracy: 0.8679\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6798 - accuracy: 0.9689\n",
            "Epoch 80: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6798 - accuracy: 0.9689 - val_loss: 1.7321 - val_accuracy: 0.8302\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6782 - accuracy: 0.9813\n",
            "Epoch 81: val_accuracy did not improve from 0.88679\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6782 - accuracy: 0.9813 - val_loss: 1.7386 - val_accuracy: 0.8113\n",
            "Epoch 82/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6800 - accuracy: 0.9799\n",
            "Epoch 82: val_accuracy improved from 0.88679 to 0.90566, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6794 - accuracy: 0.9813 - val_loss: 1.7183 - val_accuracy: 0.9057\n",
            "Epoch 83/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6735 - accuracy: 0.9955\n",
            "Epoch 83: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6742 - accuracy: 0.9917 - val_loss: 1.7166 - val_accuracy: 0.8868\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6762 - accuracy: 0.9834\n",
            "Epoch 84: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6762 - accuracy: 0.9834 - val_loss: 1.7160 - val_accuracy: 0.8868\n",
            "Epoch 85/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6736 - accuracy: 0.9866\n",
            "Epoch 85: val_accuracy did not improve from 0.90566\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6739 - accuracy: 0.9855 - val_loss: 1.7179 - val_accuracy: 0.9057\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6767 - accuracy: 0.9793\n",
            "Epoch 86: val_accuracy improved from 0.90566 to 0.92453, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.6767 - accuracy: 0.9793 - val_loss: 1.7196 - val_accuracy: 0.9245\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6746 - accuracy: 0.9896\n",
            "Epoch 87: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6746 - accuracy: 0.9896 - val_loss: 1.7160 - val_accuracy: 0.8868\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6747 - accuracy: 0.9855\n",
            "Epoch 88: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6747 - accuracy: 0.9855 - val_loss: 1.7290 - val_accuracy: 0.8491\n",
            "Epoch 89/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6713 - accuracy: 0.9933\n",
            "Epoch 89: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6723 - accuracy: 0.9917 - val_loss: 1.7166 - val_accuracy: 0.9245\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6721 - accuracy: 0.9917\n",
            "Epoch 90: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6721 - accuracy: 0.9917 - val_loss: 1.7170 - val_accuracy: 0.9057\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6725 - accuracy: 0.9896\n",
            "Epoch 91: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6725 - accuracy: 0.9896 - val_loss: 1.7155 - val_accuracy: 0.8868\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6704 - accuracy: 0.9917\n",
            "Epoch 92: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6704 - accuracy: 0.9917 - val_loss: 1.7101 - val_accuracy: 0.9057\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6722 - accuracy: 0.9917\n",
            "Epoch 93: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.6722 - accuracy: 0.9917 - val_loss: 1.7141 - val_accuracy: 0.9057\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6672 - accuracy: 0.9917\n",
            "Epoch 94: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.6672 - accuracy: 0.9917 - val_loss: 1.7208 - val_accuracy: 0.8868\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6688 - accuracy: 0.9938\n",
            "Epoch 95: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6688 - accuracy: 0.9938 - val_loss: 1.7149 - val_accuracy: 0.8868\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6700 - accuracy: 0.9896\n",
            "Epoch 96: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6700 - accuracy: 0.9896 - val_loss: 1.7147 - val_accuracy: 0.8491\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6696 - accuracy: 0.9876\n",
            "Epoch 97: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6696 - accuracy: 0.9876 - val_loss: 1.7156 - val_accuracy: 0.8679\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6701 - accuracy: 0.9917\n",
            "Epoch 98: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6701 - accuracy: 0.9917 - val_loss: 1.7121 - val_accuracy: 0.8868\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6707 - accuracy: 0.9917\n",
            "Epoch 99: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 1.6707 - accuracy: 0.9917 - val_loss: 1.7109 - val_accuracy: 0.8491\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6691 - accuracy: 0.9979\n",
            "Epoch 100: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6691 - accuracy: 0.9979 - val_loss: 1.7225 - val_accuracy: 0.8491\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6682 - accuracy: 0.9917\n",
            "Epoch 101: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6682 - accuracy: 0.9917 - val_loss: 1.7124 - val_accuracy: 0.8491\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6679 - accuracy: 0.9917\n",
            "Epoch 102: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6679 - accuracy: 0.9917 - val_loss: 1.7059 - val_accuracy: 0.8491\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6686 - accuracy: 0.9917\n",
            "Epoch 103: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.6686 - accuracy: 0.9917 - val_loss: 1.7038 - val_accuracy: 0.9057\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6660 - accuracy: 0.9917\n",
            "Epoch 104: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6660 - accuracy: 0.9917 - val_loss: 1.7063 - val_accuracy: 0.9245\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6643 - accuracy: 0.9959\n",
            "Epoch 105: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6643 - accuracy: 0.9959 - val_loss: 1.7073 - val_accuracy: 0.9057\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6670 - accuracy: 0.9959\n",
            "Epoch 106: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6670 - accuracy: 0.9959 - val_loss: 1.7146 - val_accuracy: 0.8868\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6651 - accuracy: 0.9917\n",
            "Epoch 107: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6651 - accuracy: 0.9917 - val_loss: 1.7159 - val_accuracy: 0.8679\n",
            "Epoch 108/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6668 - accuracy: 0.9955\n",
            "Epoch 108: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6666 - accuracy: 0.9959 - val_loss: 1.7123 - val_accuracy: 0.8491\n",
            "Epoch 109/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6643 - accuracy: 0.9955\n",
            "Epoch 109: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6648 - accuracy: 0.9959 - val_loss: 1.7109 - val_accuracy: 0.8679\n",
            "Epoch 110/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6646 - accuracy: 0.9933\n",
            "Epoch 110: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6644 - accuracy: 0.9938 - val_loss: 1.7116 - val_accuracy: 0.8868\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6654 - accuracy: 0.9979\n",
            "Epoch 111: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.6654 - accuracy: 0.9979 - val_loss: 1.7088 - val_accuracy: 0.8868\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6655 - accuracy: 0.9959\n",
            "Epoch 112: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6655 - accuracy: 0.9959 - val_loss: 1.7049 - val_accuracy: 0.9245\n",
            "Epoch 113/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6628 - accuracy: 1.0000\n",
            "Epoch 113: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6636 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.9057\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6614 - accuracy: 1.0000\n",
            "Epoch 114: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.6614 - accuracy: 1.0000 - val_loss: 1.7157 - val_accuracy: 0.8679\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6638 - accuracy: 0.9959\n",
            "Epoch 115: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6638 - accuracy: 0.9959 - val_loss: 1.7140 - val_accuracy: 0.8302\n",
            "Epoch 116/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6607 - accuracy: 0.9978\n",
            "Epoch 116: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6609 - accuracy: 0.9979 - val_loss: 1.7101 - val_accuracy: 0.8679\n",
            "Epoch 117/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6625 - accuracy: 1.0000\n",
            "Epoch 117: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6627 - accuracy: 1.0000 - val_loss: 1.7074 - val_accuracy: 0.8868\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6620 - accuracy: 0.9938\n",
            "Epoch 118: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6620 - accuracy: 0.9938 - val_loss: 1.7083 - val_accuracy: 0.8491\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6619 - accuracy: 0.9979\n",
            "Epoch 119: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6619 - accuracy: 0.9979 - val_loss: 1.7141 - val_accuracy: 0.9245\n",
            "Epoch 120/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6604 - accuracy: 0.9978\n",
            "Epoch 120: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6610 - accuracy: 0.9979 - val_loss: 1.7040 - val_accuracy: 0.9057\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6612 - accuracy: 0.9979\n",
            "Epoch 121: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6612 - accuracy: 0.9979 - val_loss: 1.7119 - val_accuracy: 0.8868\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6599 - accuracy: 0.9979\n",
            "Epoch 122: val_accuracy did not improve from 0.92453\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6599 - accuracy: 0.9979 - val_loss: 1.7065 - val_accuracy: 0.9245\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6606 - accuracy: 0.9979\n",
            "Epoch 123: val_accuracy improved from 0.92453 to 0.94340, saving model to ./Models/EMODB_46_2023-07-09_18-38-39/10-fold_weights_best_10.hdf5\n",
            "8/8 [==============================] - 1s 112ms/step - loss: 1.6606 - accuracy: 0.9979 - val_loss: 1.7031 - val_accuracy: 0.9434\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6605 - accuracy: 1.0000\n",
            "Epoch 124: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6605 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.9057\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6608 - accuracy: 0.9979\n",
            "Epoch 125: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 1.6608 - accuracy: 0.9979 - val_loss: 1.7058 - val_accuracy: 0.8679\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6584 - accuracy: 0.9979\n",
            "Epoch 126: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6584 - accuracy: 0.9979 - val_loss: 1.7071 - val_accuracy: 0.8679\n",
            "Epoch 127/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6598 - accuracy: 1.0000\n",
            "Epoch 127: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6598 - accuracy: 1.0000 - val_loss: 1.7059 - val_accuracy: 0.8868\n",
            "Epoch 128/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6621 - accuracy: 1.0000\n",
            "Epoch 128: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6624 - accuracy: 0.9979 - val_loss: 1.7085 - val_accuracy: 0.9057\n",
            "Epoch 129/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6599 - accuracy: 0.9955\n",
            "Epoch 129: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6599 - accuracy: 0.9938 - val_loss: 1.7029 - val_accuracy: 0.9057\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6583 - accuracy: 1.0000\n",
            "Epoch 130: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6583 - accuracy: 1.0000 - val_loss: 1.7102 - val_accuracy: 0.9057\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6577 - accuracy: 1.0000\n",
            "Epoch 131: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6577 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.9057\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6573 - accuracy: 0.9979\n",
            "Epoch 132: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6573 - accuracy: 0.9979 - val_loss: 1.7052 - val_accuracy: 0.9245\n",
            "Epoch 133/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6577 - accuracy: 1.0000\n",
            "Epoch 133: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6584 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.9245\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6555 - accuracy: 1.0000\n",
            "Epoch 134: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6555 - accuracy: 1.0000 - val_loss: 1.7025 - val_accuracy: 0.8868\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6587 - accuracy: 0.9959\n",
            "Epoch 135: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6587 - accuracy: 0.9959 - val_loss: 1.7089 - val_accuracy: 0.8679\n",
            "Epoch 136/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6585 - accuracy: 0.9955\n",
            "Epoch 136: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6579 - accuracy: 0.9959 - val_loss: 1.7067 - val_accuracy: 0.8679\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6577 - accuracy: 0.9959\n",
            "Epoch 137: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6577 - accuracy: 0.9959 - val_loss: 1.6995 - val_accuracy: 0.9434\n",
            "Epoch 138/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6577 - accuracy: 0.9955\n",
            "Epoch 138: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6577 - accuracy: 0.9959 - val_loss: 1.7035 - val_accuracy: 0.8868\n",
            "Epoch 139/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6581 - accuracy: 0.9978\n",
            "Epoch 139: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6579 - accuracy: 0.9979 - val_loss: 1.7036 - val_accuracy: 0.9434\n",
            "Epoch 140/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6580 - accuracy: 1.0000\n",
            "Epoch 140: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6578 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.9245\n",
            "Epoch 141/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6567 - accuracy: 0.9978\n",
            "Epoch 141: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6566 - accuracy: 0.9979 - val_loss: 1.7045 - val_accuracy: 0.9057\n",
            "Epoch 142/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6562 - accuracy: 0.9978\n",
            "Epoch 142: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6566 - accuracy: 0.9979 - val_loss: 1.7009 - val_accuracy: 0.9057\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6565 - accuracy: 0.9979\n",
            "Epoch 143: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.6565 - accuracy: 0.9979 - val_loss: 1.6990 - val_accuracy: 0.8868\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6563 - accuracy: 0.9979\n",
            "Epoch 144: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6563 - accuracy: 0.9979 - val_loss: 1.7010 - val_accuracy: 0.9245\n",
            "Epoch 145/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6567 - accuracy: 0.9978\n",
            "Epoch 145: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6570 - accuracy: 0.9979 - val_loss: 1.7030 - val_accuracy: 0.8491\n",
            "Epoch 146/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6540 - accuracy: 1.0000\n",
            "Epoch 146: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6547 - accuracy: 1.0000 - val_loss: 1.7065 - val_accuracy: 0.9434\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6549 - accuracy: 1.0000\n",
            "Epoch 147: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6549 - accuracy: 1.0000 - val_loss: 1.7061 - val_accuracy: 0.8868\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6556 - accuracy: 1.0000\n",
            "Epoch 148: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6556 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.9245\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6556 - accuracy: 1.0000\n",
            "Epoch 149: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.6556 - accuracy: 1.0000 - val_loss: 1.7042 - val_accuracy: 0.9057\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6543 - accuracy: 0.9979\n",
            "Epoch 150: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6543 - accuracy: 0.9979 - val_loss: 1.7063 - val_accuracy: 0.8491\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6541 - accuracy: 1.0000\n",
            "Epoch 151: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6541 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.9245\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6523 - accuracy: 1.0000\n",
            "Epoch 152: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6523 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.8679\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 1.0000\n",
            "Epoch 153: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6544 - accuracy: 1.0000 - val_loss: 1.7022 - val_accuracy: 0.9245\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6531 - accuracy: 1.0000\n",
            "Epoch 154: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6531 - accuracy: 1.0000 - val_loss: 1.6999 - val_accuracy: 0.9057\n",
            "Epoch 155/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6532 - accuracy: 1.0000\n",
            "Epoch 155: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.6535 - accuracy: 1.0000 - val_loss: 1.7028 - val_accuracy: 0.9245\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6514 - accuracy: 1.0000\n",
            "Epoch 156: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6514 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.9057\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6550 - accuracy: 0.9979\n",
            "Epoch 157: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6550 - accuracy: 0.9979 - val_loss: 1.7105 - val_accuracy: 0.9057\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6538 - accuracy: 1.0000\n",
            "Epoch 158: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6538 - accuracy: 1.0000 - val_loss: 1.7049 - val_accuracy: 0.9245\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6536 - accuracy: 1.0000\n",
            "Epoch 159: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6536 - accuracy: 1.0000 - val_loss: 1.7061 - val_accuracy: 0.8868\n",
            "Epoch 160/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6528 - accuracy: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6530 - accuracy: 1.0000 - val_loss: 1.7035 - val_accuracy: 0.9057\n",
            "Epoch 161/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6530 - accuracy: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6532 - accuracy: 1.0000 - val_loss: 1.7020 - val_accuracy: 0.9245\n",
            "Epoch 162/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6523 - accuracy: 1.0000\n",
            "Epoch 162: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6529 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.9057\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6527 - accuracy: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6527 - accuracy: 1.0000 - val_loss: 1.7032 - val_accuracy: 0.9057\n",
            "Epoch 164/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6541 - accuracy: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6540 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.9245\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6524 - accuracy: 1.0000\n",
            "Epoch 165: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6524 - accuracy: 1.0000 - val_loss: 1.7063 - val_accuracy: 0.9057\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6534 - accuracy: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6534 - accuracy: 1.0000 - val_loss: 1.7075 - val_accuracy: 0.8302\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6527 - accuracy: 0.9979\n",
            "Epoch 167: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6527 - accuracy: 0.9979 - val_loss: 1.7026 - val_accuracy: 0.9057\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6525 - accuracy: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6525 - accuracy: 1.0000 - val_loss: 1.7049 - val_accuracy: 0.9245\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6522 - accuracy: 1.0000\n",
            "Epoch 169: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6522 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.9057\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6504 - accuracy: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6504 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9057\n",
            "Epoch 171/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6515 - accuracy: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6518 - accuracy: 1.0000 - val_loss: 1.7019 - val_accuracy: 0.9245\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6524 - accuracy: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6524 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.9057\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6518 - accuracy: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.6518 - accuracy: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.8491\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6526 - accuracy: 1.0000\n",
            "Epoch 174: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6526 - accuracy: 1.0000 - val_loss: 1.7015 - val_accuracy: 0.9057\n",
            "Epoch 175/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6507 - accuracy: 1.0000\n",
            "Epoch 175: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6507 - accuracy: 1.0000 - val_loss: 1.7028 - val_accuracy: 0.9057\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.9245\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6502 - accuracy: 1.0000\n",
            "Epoch 177: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6502 - accuracy: 1.0000 - val_loss: 1.7059 - val_accuracy: 0.9245\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.9245\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.6511 - accuracy: 1.0000 - val_loss: 1.7028 - val_accuracy: 0.9057\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 0.9979\n",
            "Epoch 180: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 1.6511 - accuracy: 0.9979 - val_loss: 1.7007 - val_accuracy: 0.9057\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 1.0000\n",
            "Epoch 181: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.6511 - accuracy: 1.0000 - val_loss: 1.6950 - val_accuracy: 0.9245\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.9245\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6512 - accuracy: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6512 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.9057\n",
            "Epoch 184/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6492 - accuracy: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6496 - accuracy: 1.0000 - val_loss: 1.7066 - val_accuracy: 0.9245\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6507 - accuracy: 1.0000\n",
            "Epoch 185: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6507 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.9245\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6502 - accuracy: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6502 - accuracy: 1.0000 - val_loss: 1.7001 - val_accuracy: 0.8868\n",
            "Epoch 187/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6510 - accuracy: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6510 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.9057\n",
            "Epoch 188/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6515 - accuracy: 1.0000\n",
            "Epoch 188: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.6515 - accuracy: 1.0000 - val_loss: 1.7074 - val_accuracy: 0.8679\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6511 - accuracy: 1.0000 - val_loss: 1.7032 - val_accuracy: 0.8491\n",
            "Epoch 190/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6499 - accuracy: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6507 - accuracy: 1.0000 - val_loss: 1.7050 - val_accuracy: 0.8868\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6506 - accuracy: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6506 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.9245\n",
            "Epoch 192/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6509 - accuracy: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6507 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.9057\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6489 - accuracy: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6489 - accuracy: 1.0000 - val_loss: 1.6998 - val_accuracy: 0.9057\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6506 - accuracy: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6506 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.8868\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6482 - accuracy: 1.0000\n",
            "Epoch 195: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6482 - accuracy: 1.0000 - val_loss: 1.7061 - val_accuracy: 0.8868\n",
            "Epoch 196/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6494 - accuracy: 1.0000\n",
            "Epoch 196: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6493 - accuracy: 1.0000 - val_loss: 1.7046 - val_accuracy: 0.9057\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6482 - accuracy: 1.0000\n",
            "Epoch 197: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6482 - accuracy: 1.0000 - val_loss: 1.7113 - val_accuracy: 0.9057\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6488 - accuracy: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6488 - accuracy: 1.0000 - val_loss: 1.7088 - val_accuracy: 0.9057\n",
            "Epoch 199/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6471 - accuracy: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6471 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.9245\n",
            "Epoch 200/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6485 - accuracy: 1.0000\n",
            "Epoch 200: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6488 - accuracy: 1.0000 - val_loss: 1.7048 - val_accuracy: 0.9057\n",
            "Epoch 201/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6500 - accuracy: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6501 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.9057\n",
            "Epoch 202/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6486 - accuracy: 1.0000\n",
            "Epoch 202: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6487 - accuracy: 1.0000 - val_loss: 1.6999 - val_accuracy: 0.9057\n",
            "Epoch 203/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6484 - accuracy: 1.0000\n",
            "Epoch 203: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6484 - accuracy: 1.0000 - val_loss: 1.7028 - val_accuracy: 0.9057\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6483 - accuracy: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6483 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.9245\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6469 - accuracy: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6469 - accuracy: 1.0000 - val_loss: 1.7048 - val_accuracy: 0.9057\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6479 - accuracy: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.6479 - accuracy: 1.0000 - val_loss: 1.7065 - val_accuracy: 0.8868\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6472 - accuracy: 1.0000\n",
            "Epoch 207: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6472 - accuracy: 1.0000 - val_loss: 1.7031 - val_accuracy: 0.9057\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6489 - accuracy: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6489 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.9057\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6468 - accuracy: 1.0000\n",
            "Epoch 209: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6468 - accuracy: 1.0000 - val_loss: 1.7019 - val_accuracy: 0.8868\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6478 - accuracy: 1.0000\n",
            "Epoch 210: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.6478 - accuracy: 1.0000 - val_loss: 1.7100 - val_accuracy: 0.8679\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6497 - accuracy: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6497 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.8868\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6488 - accuracy: 1.0000\n",
            "Epoch 212: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6488 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.9057\n",
            "Epoch 213/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6465 - accuracy: 1.0000\n",
            "Epoch 213: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6468 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.8679\n",
            "Epoch 214/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6490 - accuracy: 0.9978\n",
            "Epoch 214: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6488 - accuracy: 0.9979 - val_loss: 1.6943 - val_accuracy: 0.9057\n",
            "Epoch 215/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6475 - accuracy: 1.0000\n",
            "Epoch 215: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6476 - accuracy: 1.0000 - val_loss: 1.6947 - val_accuracy: 0.9434\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6473 - accuracy: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6473 - accuracy: 1.0000 - val_loss: 1.6969 - val_accuracy: 0.9057\n",
            "Epoch 217/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6477 - accuracy: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6478 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.8868\n",
            "Epoch 218/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6477 - accuracy: 1.0000\n",
            "Epoch 218: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6478 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.9245\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6477 - accuracy: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6477 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.9057\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6479 - accuracy: 1.0000\n",
            "Epoch 220: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6479 - accuracy: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.9057\n",
            "Epoch 221/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6480 - accuracy: 0.9978\n",
            "Epoch 221: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6480 - accuracy: 0.9979 - val_loss: 1.7039 - val_accuracy: 0.9057\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6478 - accuracy: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6478 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.8868\n",
            "Epoch 223/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6471 - accuracy: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6475 - accuracy: 1.0000 - val_loss: 1.6998 - val_accuracy: 0.9057\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6473 - accuracy: 1.0000\n",
            "Epoch 224: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6473 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.8868\n",
            "Epoch 225/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 225: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.7022 - val_accuracy: 0.9057\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6466 - accuracy: 1.0000\n",
            "Epoch 226: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6466 - accuracy: 1.0000 - val_loss: 1.7000 - val_accuracy: 0.8868\n",
            "Epoch 227/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6467 - accuracy: 1.0000\n",
            "Epoch 227: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6469 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.8868\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6470 - accuracy: 1.0000\n",
            "Epoch 228: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.6470 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.9057\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6475 - accuracy: 0.9979\n",
            "Epoch 229: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6475 - accuracy: 0.9979 - val_loss: 1.7024 - val_accuracy: 0.9057\n",
            "Epoch 230/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6460 - accuracy: 1.0000\n",
            "Epoch 230: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6463 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.8868\n",
            "Epoch 231/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6466 - accuracy: 1.0000\n",
            "Epoch 231: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6468 - accuracy: 1.0000 - val_loss: 1.7054 - val_accuracy: 0.8491\n",
            "Epoch 232/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6458 - accuracy: 1.0000\n",
            "Epoch 232: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6461 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.8491\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6459 - accuracy: 1.0000\n",
            "Epoch 233: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.8868\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6464 - accuracy: 1.0000\n",
            "Epoch 234: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.6464 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.8679\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6467 - accuracy: 1.0000\n",
            "Epoch 235: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 1.6467 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.8868\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6461 - accuracy: 1.0000\n",
            "Epoch 236: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6461 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.8868\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6461 - accuracy: 1.0000\n",
            "Epoch 237: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6461 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.9057\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 238: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.6983 - val_accuracy: 0.9245\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6465 - accuracy: 1.0000\n",
            "Epoch 239: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6465 - accuracy: 1.0000 - val_loss: 1.7036 - val_accuracy: 0.9057\n",
            "Epoch 240/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6473 - accuracy: 1.0000\n",
            "Epoch 240: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6473 - accuracy: 1.0000 - val_loss: 1.6992 - val_accuracy: 0.8868\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 241: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6457 - accuracy: 1.0000 - val_loss: 1.7060 - val_accuracy: 0.8868\n",
            "Epoch 242/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6462 - accuracy: 1.0000\n",
            "Epoch 242: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6462 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.8868\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6442 - accuracy: 1.0000\n",
            "Epoch 243: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6442 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.9057\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 244: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.8868\n",
            "Epoch 245/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 245: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6452 - accuracy: 1.0000 - val_loss: 1.6958 - val_accuracy: 0.8868\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6458 - accuracy: 1.0000\n",
            "Epoch 246: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6458 - accuracy: 1.0000 - val_loss: 1.6941 - val_accuracy: 0.9245\n",
            "Epoch 247/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6439 - accuracy: 1.0000\n",
            "Epoch 247: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6446 - accuracy: 1.0000 - val_loss: 1.6957 - val_accuracy: 0.8868\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 248: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.9057\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6466 - accuracy: 1.0000\n",
            "Epoch 249: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6466 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.8868\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 250: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6451 - accuracy: 1.0000 - val_loss: 1.7038 - val_accuracy: 0.8491\n",
            "Epoch 251/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6453 - accuracy: 1.0000\n",
            "Epoch 251: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6450 - accuracy: 1.0000 - val_loss: 1.7022 - val_accuracy: 0.9057\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6462 - accuracy: 1.0000\n",
            "Epoch 252: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6462 - accuracy: 1.0000 - val_loss: 1.7015 - val_accuracy: 0.8868\n",
            "Epoch 253/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6449 - accuracy: 1.0000\n",
            "Epoch 253: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6450 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.9245\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6448 - accuracy: 1.0000\n",
            "Epoch 254: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6448 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.9057\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 255: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6457 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.8491\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 1.0000\n",
            "Epoch 256: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6452 - accuracy: 1.0000 - val_loss: 1.7038 - val_accuracy: 0.8679\n",
            "Epoch 257/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 257: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.8679\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6457 - accuracy: 1.0000\n",
            "Epoch 258: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6457 - accuracy: 1.0000 - val_loss: 1.7032 - val_accuracy: 0.8679\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 1.0000\n",
            "Epoch 259: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6452 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.8302\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 260: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.9057\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6444 - accuracy: 1.0000\n",
            "Epoch 261: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6444 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.9057\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 262: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6451 - accuracy: 1.0000 - val_loss: 1.6955 - val_accuracy: 0.9057\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6441 - accuracy: 1.0000\n",
            "Epoch 263: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 1.6441 - accuracy: 1.0000 - val_loss: 1.7005 - val_accuracy: 0.8868\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 264: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6451 - accuracy: 1.0000 - val_loss: 1.6950 - val_accuracy: 0.9245\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 265: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6976 - val_accuracy: 0.9057\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6448 - accuracy: 1.0000\n",
            "Epoch 266: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.6448 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.9245\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 267: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.9434\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 268: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.7002 - val_accuracy: 0.9057\n",
            "Epoch 269/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6444 - accuracy: 1.0000\n",
            "Epoch 269: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9057\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6438 - accuracy: 1.0000\n",
            "Epoch 270: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.6438 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.8868\n",
            "Epoch 271/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 271: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6454 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.9057\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6444 - accuracy: 1.0000\n",
            "Epoch 272: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6444 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.9434\n",
            "Epoch 273/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6442 - accuracy: 1.0000\n",
            "Epoch 273: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6441 - accuracy: 1.0000 - val_loss: 1.7015 - val_accuracy: 0.8868\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6445 - accuracy: 1.0000\n",
            "Epoch 274: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6445 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.9245\n",
            "Epoch 275/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6442 - accuracy: 1.0000\n",
            "Epoch 275: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6441 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.9057\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
            "Epoch 276: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.9057\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6444 - accuracy: 1.0000\n",
            "Epoch 277: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6444 - accuracy: 1.0000 - val_loss: 1.7002 - val_accuracy: 0.9434\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 1.0000\n",
            "Epoch 278: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.6456 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.8868\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6451 - accuracy: 1.0000\n",
            "Epoch 279: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6451 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.9057\n",
            "Epoch 280/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6439 - accuracy: 1.0000\n",
            "Epoch 280: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.6440 - accuracy: 1.0000 - val_loss: 1.7028 - val_accuracy: 0.9057\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6442 - accuracy: 1.0000\n",
            "Epoch 281: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6442 - accuracy: 1.0000 - val_loss: 1.7024 - val_accuracy: 0.8868\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6446 - accuracy: 1.0000\n",
            "Epoch 282: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6446 - accuracy: 1.0000 - val_loss: 1.6987 - val_accuracy: 0.8868\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 283: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.9057\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
            "Epoch 284: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 1.7013 - val_accuracy: 0.9057\n",
            "Epoch 285/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6439 - accuracy: 1.0000\n",
            "Epoch 285: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6439 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.9057\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6437 - accuracy: 1.0000\n",
            "Epoch 286: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6437 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.9434\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
            "Epoch 287: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 1.6943 - val_accuracy: 0.8868\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6439 - accuracy: 1.0000\n",
            "Epoch 288: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6439 - accuracy: 1.0000 - val_loss: 1.6971 - val_accuracy: 0.8868\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6438 - accuracy: 1.0000\n",
            "Epoch 289: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6438 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.8868\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 1.0000\n",
            "Epoch 290: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 1.6443 - accuracy: 1.0000 - val_loss: 1.6944 - val_accuracy: 0.8679\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6438 - accuracy: 1.0000\n",
            "Epoch 291: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6438 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.8868\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6441 - accuracy: 1.0000\n",
            "Epoch 292: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6441 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.9434\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6442 - accuracy: 1.0000\n",
            "Epoch 293: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 1.6442 - accuracy: 1.0000 - val_loss: 1.7012 - val_accuracy: 0.8868\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6435 - accuracy: 1.0000\n",
            "Epoch 294: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 1.6435 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.9057\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6429 - accuracy: 1.0000\n",
            "Epoch 295: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 1.6429 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.9057\n",
            "Epoch 296/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6433 - accuracy: 1.0000\n",
            "Epoch 296: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6433 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.9057\n",
            "Epoch 297/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6434 - accuracy: 1.0000\n",
            "Epoch 297: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.6435 - accuracy: 1.0000 - val_loss: 1.6962 - val_accuracy: 0.9245\n",
            "Epoch 298/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6426 - accuracy: 1.0000\n",
            "Epoch 298: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.6426 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.8868\n",
            "Epoch 299/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6435 - accuracy: 1.0000\n",
            "Epoch 299: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6437 - accuracy: 1.0000 - val_loss: 1.6971 - val_accuracy: 0.8868\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6428 - accuracy: 1.0000\n",
            "Epoch 300: val_accuracy did not improve from 0.94340\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.6428 - accuracy: 1.0000 - val_loss: 1.7012 - val_accuracy: 0.8679\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7031 - accuracy: 0.9434\n",
            "10_Model evaluation:  [1.7031278610229492, 0.9433962106704712]    Now ACC: 92.9\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      1.00      0.96        12\n",
            "     boredom       0.83      1.00      0.91        10\n",
            "     disgust       1.00      0.83      0.91         6\n",
            "        fear       1.00      1.00      1.00         4\n",
            "       happy       1.00      0.86      0.92         7\n",
            "     neutral       1.00      0.91      0.95        11\n",
            "         sad       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.94        53\n",
            "   macro avg       0.97      0.94      0.95        53\n",
            "weighted avg       0.95      0.94      0.94        53\n",
            "\n",
            "Average ACC: 0.9290006935596467\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n",
            "/content/TIM-Net_SER/Code/Model.py:138: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  writer.save()\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode train --data EMODB --split_fold 10 --random_seed 46 --epoch 300 --gpu 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXav2FXf501z"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CfV8Qy0pSOI",
        "outputId": "e0e6bc2b-8a16-4032-fb72-bd7d374fe597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-09 19:13:59.597743: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 19:14:00.468851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-09 19:14:03.274227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:03.316683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:03.317055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:03.318232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:03.318532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:03.318767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.734654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.734983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.735216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.735381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "###gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TIMNET MODEL SHAPE: (254, 39)\n",
            "2023-07-09 19:14:04.759047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.759408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.759695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.760017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.760302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:14:04.760491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:14:09.522759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
            "2/2 [==============================] - 4s 280ms/step - loss: 0.5438 - accuracy: 0.8750\n",
            "1_Model evaluation:  [0.5437782406806946, 0.875]    Now ACC: 87.5\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.75      1.00      0.86         3\n",
            "     disgust       1.00      0.50      0.67         8\n",
            "        fear       0.78      0.88      0.82         8\n",
            "       happy       0.75      1.00      0.86         3\n",
            "     neutral       0.88      1.00      0.93        14\n",
            "         sad       1.00      0.80      0.89         5\n",
            "    surprise       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.88        48\n",
            "   macro avg       0.88      0.88      0.86        48\n",
            "weighted avg       0.90      0.88      0.87        48\n",
            "\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 4s 13ms/step - loss: 0.6559 - accuracy: 0.8750\n",
            "2_Model evaluation:  [0.6559339761734009, 0.875]    Now ACC: 87.5\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      1.00      0.80         6\n",
            "     disgust       1.00      0.67      0.80         6\n",
            "        fear       0.75      0.60      0.67         5\n",
            "       happy       1.00      0.88      0.93         8\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      0.86      0.92         7\n",
            "    surprise       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.88        48\n",
            "   macro avg       0.88      0.86      0.86        48\n",
            "weighted avg       0.90      0.88      0.87        48\n",
            "\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 0.8832 - accuracy: 0.8333\n",
            "3_Model evaluation:  [0.883187472820282, 0.8333333134651184]    Now ACC: 86.11\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07083336d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.83      0.91         6\n",
            "     disgust       0.71      0.83      0.77         6\n",
            "        fear       0.83      0.62      0.71         8\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       0.86      1.00      0.92        12\n",
            "         sad       1.00      0.67      0.80         3\n",
            "    surprise       0.67      0.86      0.75         7\n",
            "\n",
            "    accuracy                           0.83        48\n",
            "   macro avg       0.87      0.81      0.82        48\n",
            "weighted avg       0.85      0.83      0.83        48\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06fc510040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 12ms/step - loss: 0.6446 - accuracy: 0.9167\n",
            "4_Model evaluation:  [0.6445936560630798, 0.9166666865348816]    Now ACC: 87.5\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         8\n",
            "     disgust       0.67      0.67      0.67         3\n",
            "        fear       0.67      0.67      0.67         3\n",
            "       happy       1.00      0.67      0.80         3\n",
            "     neutral       1.00      0.94      0.97        17\n",
            "         sad       1.00      1.00      1.00         9\n",
            "    surprise       0.71      1.00      0.83         5\n",
            "\n",
            "    accuracy                           0.92        48\n",
            "   macro avg       0.86      0.85      0.85        48\n",
            "weighted avg       0.93      0.92      0.92        48\n",
            "\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0712093370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 12ms/step - loss: 0.8626 - accuracy: 0.9583\n",
            "5_Model evaluation:  [0.8626158833503723, 0.9583333134651184]    Now ACC: 89.166\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         3\n",
            "     disgust       0.88      1.00      0.93         7\n",
            "        fear       1.00      0.80      0.89         5\n",
            "       happy       1.00      0.89      0.94         9\n",
            "     neutral       1.00      1.00      1.00        13\n",
            "         sad       1.00      1.00      1.00         7\n",
            "    surprise       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.96        48\n",
            "   macro avg       0.95      0.96      0.95        48\n",
            "weighted avg       0.97      0.96      0.96        48\n",
            "\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0708332710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 13ms/step - loss: 0.8891 - accuracy: 0.8542\n",
            "6_Model evaluation:  [0.8891065120697021, 0.8541666865348816]    Now ACC: 88.54166666666667\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.89      0.89         9\n",
            "     disgust       0.71      1.00      0.83         5\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       0.75      0.43      0.55         7\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      0.75      0.86         4\n",
            "    surprise       0.62      0.83      0.71         6\n",
            "\n",
            "    accuracy                           0.85        48\n",
            "   macro avg       0.85      0.84      0.83        48\n",
            "weighted avg       0.87      0.85      0.85        48\n",
            "\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 12ms/step - loss: 1.0026 - accuracy: 0.8542\n",
            "7_Model evaluation:  [1.002595067024231, 0.8541666865348816]    Now ACC: 88.09571428571428\n",
            "2/2 [==============================] - 2s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.67      0.73         6\n",
            "     disgust       1.00      1.00      1.00         5\n",
            "        fear       1.00      0.75      0.86         8\n",
            "       happy       0.50      0.67      0.57         3\n",
            "     neutral       0.89      1.00      0.94         8\n",
            "         sad       0.78      0.88      0.82         8\n",
            "    surprise       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.85        48\n",
            "   macro avg       0.84      0.84      0.83        48\n",
            "weighted avg       0.87      0.85      0.86        48\n",
            "\n",
            "2/2 [==============================] - 2s 10ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 1.0870 - accuracy: 0.8333\n",
            "8_Model evaluation:  [1.087006688117981, 0.8333333134651184]    Now ACC: 87.5\n",
            "2/2 [==============================] - 1s 13ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      1.00      0.89         4\n",
            "     disgust       1.00      0.50      0.67         4\n",
            "        fear       0.55      0.75      0.63         8\n",
            "       happy       0.89      0.73      0.80        11\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      1.00      1.00         4\n",
            "    surprise       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.83        48\n",
            "   macro avg       0.87      0.83      0.83        48\n",
            "weighted avg       0.86      0.83      0.83        48\n",
            "\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 14ms/step - loss: 1.0964 - accuracy: 0.8750\n",
            "9_Model evaluation:  [1.0964232683181763, 0.875]    Now ACC: 87.5\n",
            "2/2 [==============================] - 2s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.80      0.89        10\n",
            "     disgust       0.88      1.00      0.93         7\n",
            "        fear       1.00      0.80      0.89         5\n",
            "       happy       0.60      0.75      0.67         4\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      0.88      0.93         8\n",
            "    surprise       0.50      0.67      0.57         3\n",
            "\n",
            "    accuracy                           0.88        48\n",
            "   macro avg       0.84      0.84      0.83        48\n",
            "weighted avg       0.90      0.88      0.88        48\n",
            "\n",
            "2/2 [==============================] - 2s 10ms/step\n",
            "Input Shape= (None, 254, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 12ms/step - loss: 1.0726 - accuracy: 0.8958\n",
            "10_Model evaluation:  [1.0726256370544434, 0.8958333134651184]    Now ACC: 87.708\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.80      0.80         5\n",
            "     disgust       0.90      1.00      0.95         9\n",
            "        fear       1.00      0.50      0.67         4\n",
            "       happy       0.83      0.83      0.83         6\n",
            "     neutral       1.00      1.00      1.00        12\n",
            "         sad       1.00      1.00      1.00         5\n",
            "    surprise       0.75      0.86      0.80         7\n",
            "\n",
            "    accuracy                           0.90        48\n",
            "   macro avg       0.90      0.86      0.86        48\n",
            "weighted avg       0.90      0.90      0.89        48\n",
            "\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "Average ACC: 0.8770833313465118\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode test --data SAVEE  --test_path ./Test_Models/SAVEE_44 --split_fold 10 --random_seed 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz0N89tTpgmI",
        "outputId": "90579122-0bea-4374-ef2c-3ab73ba7620c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-09 19:15:20.019017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 19:15:20.888576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-09 19:15:23.496191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:23.536865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:23.537278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:23.539274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:23.539585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:23.539824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:24.980218: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:24.980625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:24.980885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:24.981123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "###gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TIMNET MODEL SHAPE: (172, 39)\n",
            "2023-07-09 19:15:25.014388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:25.014801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:25.015070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:25.015385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:25.015639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:15:25.015826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:15:30.044349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
            "4/4 [==============================] - 4s 87ms/step - loss: 1.0349 - accuracy: 0.9583\n",
            "1_Model evaluation:  [1.0348997116088867, 0.9583333134651184]    Now ACC: 95.83\n",
            "4/4 [==============================] - 1s 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        20\n",
            "        fear       1.00      0.93      0.96        28\n",
            "       happy       0.92      0.96      0.94        23\n",
            "     neutral       1.00      1.00      1.00        14\n",
            "         sad       0.85      0.92      0.88        12\n",
            "    surprise       0.96      0.96      0.96        23\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.95      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "4/4 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 4s 14ms/step - loss: 0.9250 - accuracy: 0.9667\n",
            "2_Model evaluation:  [0.9249677062034607, 0.9666666388511658]    Now ACC: 96.25\n",
            "4/4 [==============================] - 1s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.96      0.98        26\n",
            "        fear       1.00      0.95      0.97        19\n",
            "       happy       0.95      0.90      0.93        21\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      1.00      1.00        21\n",
            "    surprise       0.88      1.00      0.94        22\n",
            "\n",
            "    accuracy                           0.97       120\n",
            "   macro avg       0.97      0.97      0.97       120\n",
            "weighted avg       0.97      0.97      0.97       120\n",
            "\n",
            "4/4 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 2s 12ms/step - loss: 0.9862 - accuracy: 0.9833\n",
            "3_Model evaluation:  [0.9861561059951782, 0.9833333492279053]    Now ACC: 96.94333333333333\n",
            "4/4 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.96      1.00      0.98        22\n",
            "        fear       0.95      1.00      0.98        21\n",
            "       happy       1.00      0.95      0.98        21\n",
            "     neutral       1.00      1.00      1.00        23\n",
            "         sad       1.00      0.95      0.97        20\n",
            "    surprise       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           0.98       120\n",
            "   macro avg       0.99      0.98      0.98       120\n",
            "weighted avg       0.98      0.98      0.98       120\n",
            "\n",
            "4/4 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 3s 12ms/step - loss: 1.1194 - accuracy: 0.9333\n",
            "4_Model evaluation:  [1.119413137435913, 0.9333333373069763]    Now ACC: 96.0425\n",
            "4/4 [==============================] - 1s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.90      1.00      0.95        18\n",
            "        fear       0.93      0.82      0.87        17\n",
            "       happy       0.93      0.88      0.90        16\n",
            "     neutral       1.00      0.96      0.98        24\n",
            "         sad       0.93      0.96      0.94        26\n",
            "    surprise       0.90      0.95      0.92        19\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n",
            "4/4 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 2s 12ms/step - loss: 1.1704 - accuracy: 0.9417\n",
            "5_Model evaluation:  [1.1703927516937256, 0.9416666626930237]    Now ACC: 95.666\n",
            "4/4 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      0.92      0.92        13\n",
            "        fear       0.88      0.93      0.90        15\n",
            "       happy       1.00      0.90      0.95        20\n",
            "     neutral       0.91      1.00      0.95        20\n",
            "         sad       0.95      0.90      0.93        21\n",
            "    surprise       0.97      0.97      0.97        31\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n",
            "4/4 [==============================] - 2s 10ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 2s 13ms/step - loss: 1.1895 - accuracy: 0.9583\n",
            "6_Model evaluation:  [1.189495325088501, 0.9583333134651184]    Now ACC: 95.695\n",
            "4/4 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.90      0.95      0.92        19\n",
            "        fear       0.95      1.00      0.97        18\n",
            "       happy       0.86      0.86      0.86        14\n",
            "     neutral       1.00      0.96      0.98        28\n",
            "         sad       1.00      1.00      1.00        20\n",
            "    surprise       1.00      0.95      0.98        21\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.95      0.95      0.95       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "4/4 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 2s 12ms/step - loss: 1.2821 - accuracy: 0.9167\n",
            "7_Model evaluation:  [1.2820823192596436, 0.9166666865348816]    Now ACC: 95.11857142857143\n",
            "4/4 [==============================] - 2s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      0.92      0.92        24\n",
            "        fear       0.76      0.90      0.83        21\n",
            "       happy       1.00      0.94      0.97        16\n",
            "     neutral       1.00      0.96      0.98        27\n",
            "         sad       1.00      0.83      0.91        18\n",
            "    surprise       0.87      0.93      0.90        14\n",
            "\n",
            "    accuracy                           0.92       120\n",
            "   macro avg       0.92      0.91      0.92       120\n",
            "weighted avg       0.93      0.92      0.92       120\n",
            "\n",
            "4/4 [==============================] - 2s 11ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 2s 12ms/step - loss: 1.2868 - accuracy: 0.9417\n",
            "8_Model evaluation:  [1.286832571029663, 0.9416666626930237]    Now ACC: 95.0\n",
            "4/4 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      1.00      0.94        17\n",
            "        fear       0.95      0.90      0.92        20\n",
            "       happy       1.00      0.94      0.97        18\n",
            "     neutral       0.96      0.96      0.96        25\n",
            "         sad       0.91      0.88      0.89        24\n",
            "    surprise       0.94      1.00      0.97        16\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.95      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n",
            "4/4 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 3s 12ms/step - loss: 1.2969 - accuracy: 0.9333\n",
            "9_Model evaluation:  [1.2969157695770264, 0.9333333373069763]    Now ACC: 94.81444444444445\n",
            "4/4 [==============================] - 2s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.84      1.00      0.91        16\n",
            "        fear       0.86      1.00      0.93        19\n",
            "       happy       0.96      0.88      0.92        25\n",
            "     neutral       0.94      1.00      0.97        15\n",
            "         sad       1.00      0.85      0.92        20\n",
            "    surprise       1.00      0.92      0.96        25\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.94      0.93       120\n",
            "weighted avg       0.94      0.93      0.93       120\n",
            "\n",
            "4/4 [==============================] - 2s 8ms/step\n",
            "Input Shape= (None, 172, 39)\n",
            "Temporal create succes!\n",
            "4/4 [==============================] - 2s 12ms/step - loss: 1.3218 - accuracy: 0.9333\n",
            "10_Model evaluation:  [1.321821689605713, 0.9333333373069763]    Now ACC: 94.667\n",
            "4/4 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        25\n",
            "        fear       0.87      0.91      0.89        22\n",
            "       happy       0.96      0.96      0.96        26\n",
            "     neutral       1.00      0.92      0.96        13\n",
            "         sad       0.88      0.78      0.82        18\n",
            "    surprise       0.89      1.00      0.94        16\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n",
            "4/4 [==============================] - 1s 8ms/step\n",
            "Average ACC: 0.9466666638851166\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode test --data CASIA  --test_path ./Test_Models/CASIA_32 --split_fold 10 --random_seed 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDurluC_phKY",
        "outputId": "5a876609-8c70-472f-d48b-c1b99d0354fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-09 19:16:41.975545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 19:16:42.871325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-09 19:16:45.941272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:45.980517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:45.980856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:45.982095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:45.982390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:45.982622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.201710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.202021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.202246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.202402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "###gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TIMNET MODEL SHAPE: (188, 39)\n",
            "2023-07-09 19:16:47.218254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.218522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.218710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.218937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.219151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:16:47.219294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:16:51.936947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
            "2/2 [==============================] - 4s 416ms/step - loss: 0.2783 - accuracy: 1.0000\n",
            "1_Model evaluation:  [0.27830004692077637, 1.0]    Now ACC: 100.0\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        14\n",
            "     boredom       1.00      1.00      1.00         8\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         4\n",
            "       happy       1.00      1.00      1.00         6\n",
            "     neutral       1.00      1.00      1.00         6\n",
            "         sad       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 13ms/step - loss: 0.3815 - accuracy: 1.0000\n",
            "2_Model evaluation:  [0.38149207830429077, 1.0]    Now ACC: 100.0\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         7\n",
            "     boredom       1.00      1.00      1.00        12\n",
            "     disgust       1.00      1.00      1.00         8\n",
            "        fear       1.00      1.00      1.00         9\n",
            "       happy       1.00      1.00      1.00         6\n",
            "     neutral       1.00      1.00      1.00         5\n",
            "         sad       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 14ms/step - loss: 0.5704 - accuracy: 0.9074\n",
            "3_Model evaluation:  [0.5704226493835449, 0.9074074029922485]    Now ACC: 96.91333333333334\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd29ae576d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.93      1.00      0.96        13\n",
            "     boredom       1.00      0.75      0.86         8\n",
            "     disgust       1.00      0.80      0.89         5\n",
            "        fear       0.89      0.89      0.89         9\n",
            "       happy       0.86      1.00      0.92         6\n",
            "     neutral       0.78      0.88      0.82         8\n",
            "         sad       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.91        54\n",
            "   macro avg       0.92      0.90      0.91        54\n",
            "weighted avg       0.92      0.91      0.91        54\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd2950a4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 13ms/step - loss: 0.6386 - accuracy: 0.9444\n",
            "4_Model evaluation:  [0.6385937929153442, 0.9444444179534912]    Now ACC: 96.2975\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.86      1.00      0.92        12\n",
            "     boredom       0.92      1.00      0.96        11\n",
            "     disgust       1.00      0.83      0.91         6\n",
            "        fear       1.00      1.00      1.00         8\n",
            "       happy       1.00      0.80      0.89         5\n",
            "     neutral       1.00      0.89      0.94         9\n",
            "         sad       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.94        54\n",
            "   macro avg       0.97      0.93      0.95        54\n",
            "weighted avg       0.95      0.94      0.94        54\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd2c2c73370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 0.6638 - accuracy: 0.9444\n",
            "5_Model evaluation:  [0.6637793779373169, 0.9444444179534912]    Now ACC: 95.926\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.94      0.97        18\n",
            "     boredom       1.00      0.86      0.92         7\n",
            "     disgust       1.00      1.00      1.00         2\n",
            "        fear       0.86      1.00      0.92         6\n",
            "       happy       0.89      0.89      0.89         9\n",
            "     neutral       0.86      1.00      0.92         6\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.94        54\n",
            "   macro avg       0.94      0.96      0.95        54\n",
            "weighted avg       0.95      0.94      0.94        54\n",
            "\n",
            "2/2 [==============================] - 2s 13ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd29ae56710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 3s 473ms/step - loss: 0.7663 - accuracy: 0.9623\n",
            "6_Model evaluation:  [0.7662950158119202, 0.9622641801834106]    Now ACC: 95.97666666666667\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      1.00      0.96        12\n",
            "     boredom       1.00      0.80      0.89         5\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         9\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       0.92      1.00      0.96        11\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.96        53\n",
            "   macro avg       0.98      0.95      0.96        53\n",
            "weighted avg       0.97      0.96      0.96        53\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 14ms/step - loss: 0.9478 - accuracy: 0.9057\n",
            "7_Model evaluation:  [0.9477574825286865, 0.9056603908538818]    Now ACC: 95.20285714285714\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.85      1.00      0.92        11\n",
            "     boredom       0.91      1.00      0.95        10\n",
            "     disgust       1.00      0.67      0.80         3\n",
            "        fear       0.88      1.00      0.93         7\n",
            "       happy       0.86      0.67      0.75         9\n",
            "     neutral       1.00      0.86      0.92         7\n",
            "         sad       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.91        53\n",
            "   macro avg       0.93      0.88      0.90        53\n",
            "weighted avg       0.91      0.91      0.90        53\n",
            "\n",
            "2/2 [==============================] - 2s 10ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 16ms/step - loss: 0.8206 - accuracy: 0.9811\n",
            "8_Model evaluation:  [0.8205931782722473, 0.9811320900917053]    Now ACC: 95.5675\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        17\n",
            "     boredom       1.00      0.75      0.86         4\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         7\n",
            "       happy       1.00      1.00      1.00         4\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "         sad       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.98        53\n",
            "   macro avg       0.98      0.96      0.97        53\n",
            "weighted avg       0.98      0.98      0.98        53\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 16ms/step - loss: 0.9167 - accuracy: 0.9434\n",
            "9_Model evaluation:  [0.9166657328605652, 0.9433962106704712]    Now ACC: 95.43\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        11\n",
            "     boredom       0.86      1.00      0.92         6\n",
            "     disgust       1.00      0.75      0.86         4\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       1.00      1.00      1.00        13\n",
            "     neutral       0.78      1.00      0.88         7\n",
            "         sad       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.94        53\n",
            "   macro avg       0.95      0.92      0.92        53\n",
            "weighted avg       0.95      0.94      0.94        53\n",
            "\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 14ms/step - loss: 1.0000 - accuracy: 0.9811\n",
            "10_Model evaluation:  [0.9999573230743408, 0.9811320900917053]    Now ACC: 95.699\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        12\n",
            "     boredom       0.91      1.00      0.95        10\n",
            "     disgust       1.00      1.00      1.00         6\n",
            "        fear       1.00      1.00      1.00         4\n",
            "       happy       1.00      1.00      1.00         7\n",
            "     neutral       1.00      0.91      0.95        11\n",
            "         sad       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.98        53\n",
            "   macro avg       0.99      0.99      0.99        53\n",
            "weighted avg       0.98      0.98      0.98        53\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Average ACC: 0.9569881200790405\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode test --data EMODB  --test_path ./Test_Models/EMODB_46 --split_fold 10 --random_seed 46"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXlLdoUqwb9w",
        "outputId": "5567ac27-5b04-490d-f70f-20bbefe24402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-09 19:18:02.942070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 19:18:03.800644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-09 19:18:06.879205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:06.919597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:06.919940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:06.921162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:06.921444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:06.921674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.136132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.136459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.136679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.136842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "###gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TIMNET MODEL SHAPE: (188, 39)\n",
            "2023-07-09 19:18:08.153272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.153568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.153771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.154039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.154248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:18:08.154396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:18:12.869418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
            "2/2 [==============================] - 4s 124ms/step - loss: 1.0564 - accuracy: 0.9322\n",
            "1_Model evaluation:  [1.0563545227050781, 0.9322034120559692]    Now ACC: 93.22\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.90      0.95        10\n",
            "     disgust       1.00      1.00      1.00        12\n",
            "        fear       0.92      1.00      0.96        11\n",
            "       happy       0.86      0.86      0.86         7\n",
            "     neutral       0.80      1.00      0.89         4\n",
            "         sad       1.00      1.00      1.00         7\n",
            "    surprise       0.86      0.75      0.80         8\n",
            "\n",
            "    accuracy                           0.93        59\n",
            "   macro avg       0.92      0.93      0.92        59\n",
            "weighted avg       0.93      0.93      0.93        59\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 15ms/step - loss: 1.1231 - accuracy: 0.9492\n",
            "2_Model evaluation:  [1.1231091022491455, 0.9491525292396545]    Now ACC: 94.07\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         9\n",
            "     disgust       1.00      1.00      1.00         4\n",
            "        fear       1.00      1.00      1.00         5\n",
            "       happy       1.00      0.62      0.77         8\n",
            "     neutral       0.92      1.00      0.96        12\n",
            "         sad       1.00      1.00      1.00         9\n",
            "    surprise       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.95        59\n",
            "   macro avg       0.97      0.95      0.95        59\n",
            "weighted avg       0.96      0.95      0.94        59\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 14ms/step - loss: 1.2800 - accuracy: 0.9153\n",
            "3_Model evaluation:  [1.2799540758132935, 0.9152542352676392]    Now ACC: 93.22000000000001\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f30a1b236d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.92      0.96        13\n",
            "     disgust       0.67      1.00      0.80         6\n",
            "        fear       1.00      1.00      1.00         6\n",
            "       happy       1.00      0.83      0.91         6\n",
            "     neutral       1.00      1.00      1.00         8\n",
            "         sad       1.00      0.92      0.96        12\n",
            "    surprise       0.75      0.75      0.75         8\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.92      0.92      0.91        59\n",
            "weighted avg       0.93      0.92      0.92        59\n",
            "\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3090fbc040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 14ms/step - loss: 1.2502 - accuracy: 0.9153\n",
            "4_Model evaluation:  [1.25023353099823, 0.9152542352676392]    Now ACC: 92.7975\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.83      1.00      0.91         5\n",
            "     disgust       0.88      0.88      0.88         8\n",
            "        fear       1.00      0.80      0.89         5\n",
            "       happy       1.00      0.91      0.95        11\n",
            "     neutral       1.00      1.00      1.00         6\n",
            "         sad       1.00      1.00      1.00        15\n",
            "    surprise       0.70      0.78      0.74         9\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.92      0.91      0.91        59\n",
            "weighted avg       0.92      0.92      0.92        59\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f30b0cc7370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 1.3857 - accuracy: 0.8136\n",
            "5_Model evaluation:  [1.3856860399246216, 0.8135592937469482]    Now ACC: 90.50800000000001\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      0.67      0.67         9\n",
            "     disgust       1.00      0.80      0.89        10\n",
            "        fear       0.70      0.78      0.74         9\n",
            "       happy       0.43      0.75      0.55         4\n",
            "     neutral       1.00      1.00      1.00        11\n",
            "         sad       1.00      0.86      0.92         7\n",
            "    surprise       0.88      0.78      0.82         9\n",
            "\n",
            "    accuracy                           0.81        59\n",
            "   macro avg       0.81      0.80      0.80        59\n",
            "weighted avg       0.85      0.81      0.82        59\n",
            "\n",
            "2/2 [==============================] - 2s 10ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f30a1b22710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 2s 14ms/step - loss: 1.3537 - accuracy: 0.9153\n",
            "6_Model evaluation:  [1.3537380695343018, 0.9152542352676392]    Now ACC: 90.67833333333334\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      1.00      0.80         2\n",
            "     disgust       1.00      0.91      0.95        11\n",
            "        fear       1.00      0.90      0.95        10\n",
            "       happy       0.89      0.80      0.84        10\n",
            "     neutral       0.89      1.00      0.94         8\n",
            "         sad       1.00      1.00      1.00         9\n",
            "    surprise       0.80      0.89      0.84         9\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.89      0.93      0.90        59\n",
            "weighted avg       0.92      0.92      0.92        59\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 14ms/step - loss: 1.3333 - accuracy: 0.9492\n",
            "7_Model evaluation:  [1.3332915306091309, 0.9491525292396545]    Now ACC: 91.28285714285714\n",
            "2/2 [==============================] - 2s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        13\n",
            "     disgust       1.00      0.80      0.89        10\n",
            "        fear       1.00      1.00      1.00         8\n",
            "       happy       0.91      1.00      0.95        10\n",
            "     neutral       0.86      1.00      0.92         6\n",
            "         sad       0.80      1.00      0.89         4\n",
            "    surprise       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.95        59\n",
            "   macro avg       0.94      0.95      0.94        59\n",
            "weighted avg       0.96      0.95      0.95        59\n",
            "\n",
            "2/2 [==============================] - 2s 11ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 1.3640 - accuracy: 0.9661\n",
            "8_Model evaluation:  [1.363973617553711, 0.9661017060279846]    Now ACC: 91.94875\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00         5\n",
            "     disgust       0.88      1.00      0.93         7\n",
            "        fear       1.00      0.88      0.93        16\n",
            "       happy       1.00      1.00      1.00         9\n",
            "     neutral       1.00      1.00      1.00         8\n",
            "         sad       0.86      1.00      0.92         6\n",
            "    surprise       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.97        59\n",
            "   macro avg       0.96      0.98      0.97        59\n",
            "weighted avg       0.97      0.97      0.97        59\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 3s 336ms/step - loss: 1.4110 - accuracy: 0.9310\n",
            "9_Model evaluation:  [1.4110140800476074, 0.931034505367279]    Now ACC: 92.07777777777778\n",
            "2/2 [==============================] - 2s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      1.00      0.89         8\n",
            "     disgust       1.00      1.00      1.00        10\n",
            "        fear       0.89      0.89      0.89         9\n",
            "       happy       1.00      0.88      0.93         8\n",
            "     neutral       1.00      0.92      0.96        12\n",
            "         sad       1.00      1.00      1.00         5\n",
            "    surprise       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.93        58\n",
            "   macro avg       0.93      0.93      0.93        58\n",
            "weighted avg       0.94      0.93      0.93        58\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 188, 39)\n",
            "Temporal create succes!\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 1.5136 - accuracy: 0.9138\n",
            "10_Model evaluation:  [1.5136208534240723, 0.9137930870056152]    Now ACC: 92.00800000000001\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.90      0.95        10\n",
            "     disgust       0.86      1.00      0.92         6\n",
            "        fear       0.83      1.00      0.91         5\n",
            "       happy       0.77      0.91      0.83        11\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "         sad       1.00      1.00      1.00        10\n",
            "    surprise       1.00      0.57      0.73         7\n",
            "\n",
            "    accuracy                           0.91        58\n",
            "   macro avg       0.92      0.91      0.91        58\n",
            "weighted avg       0.93      0.91      0.91        58\n",
            "\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Average ACC: 0.9200759768486023\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode test --data EMOVO  --test_path ./Test_Models/EMOVO_1 --split_fold 10 --random_seed 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvGV8JQxwYsP",
        "outputId": "f2ae626c-78af-434d-9140-7d5c052fbd7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-09 19:19:24.342157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 19:19:25.212664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-09 19:19:28.372431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:28.414995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:28.415398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:28.416665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:28.416931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:28.417191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.547591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.547917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.548193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.548377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "###gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TIMNET MODEL SHAPE: (606, 39)\n",
            "2023-07-09 19:19:29.838162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.838498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.838706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.838958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.839187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:19:29.839335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:19:31.858277: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 470505672 exceeds 10% of free system memory.\n",
            "2023-07-09 19:19:32.308263: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 470505672 exceeds 10% of free system memory.\n",
            "2023-07-09 19:19:36.438426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
            "18/18 [==============================] - 5s 38ms/step - loss: 0.9190 - accuracy: 0.6895\n",
            "1_Model evaluation:  [0.9190258383750916, 0.6895306706428528]    Now ACC: 68.95\n",
            "18/18 [==============================] - 3s 26ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.70      0.75       122\n",
            "       happy       0.67      0.58      0.62       167\n",
            "     neutral       0.65      0.74      0.69       175\n",
            "         sad       0.67      0.78      0.72        90\n",
            "\n",
            "    accuracy                           0.69       554\n",
            "   macro avg       0.70      0.70      0.70       554\n",
            "weighted avg       0.69      0.69      0.69       554\n",
            "\n",
            "18/18 [==============================] - 2s 21ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:19:45.117310: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 470600208 exceeds 10% of free system memory.\n",
            "2023-07-09 19:19:45.576281: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 470600208 exceeds 10% of free system memory.\n",
            "18/18 [==============================] - 4s 40ms/step - loss: 0.7202 - accuracy: 0.7577\n",
            "2_Model evaluation:  [0.7202247977256775, 0.7576853632926941]    Now ACC: 72.36\n",
            "18/18 [==============================] - 2s 25ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.76      0.73      0.74       117\n",
            "       happy       0.78      0.74      0.76       172\n",
            "     neutral       0.76      0.71      0.73       156\n",
            "         sad       0.72      0.89      0.80       108\n",
            "\n",
            "    accuracy                           0.76       553\n",
            "   macro avg       0.76      0.77      0.76       553\n",
            "weighted avg       0.76      0.76      0.76       553\n",
            "\n",
            "18/18 [==============================] - 3s 19ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:19:57.425580: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 470600208 exceeds 10% of free system memory.\n",
            "18/18 [==============================] - 3s 26ms/step - loss: 0.8038 - accuracy: 0.7143\n",
            "3_Model evaluation:  [0.8038386106491089, 0.7142857313156128]    Now ACC: 72.05\n",
            "18/18 [==============================] - 2s 25ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.68      0.68      0.68        97\n",
            "       happy       0.85      0.53      0.65       165\n",
            "     neutral       0.68      0.82      0.74       185\n",
            "         sad       0.70      0.84      0.76       106\n",
            "\n",
            "    accuracy                           0.71       553\n",
            "   macro avg       0.73      0.72      0.71       553\n",
            "weighted avg       0.73      0.71      0.71       553\n",
            "\n",
            "18/18 [==============================] - 2s 20ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 3s 25ms/step - loss: 0.8555 - accuracy: 0.6998\n",
            "4_Model evaluation:  [0.8554527759552002, 0.6998191475868225]    Now ACC: 71.5325\n",
            "18/18 [==============================] - 2s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.79      0.74      0.77       120\n",
            "       happy       0.69      0.63      0.66       171\n",
            "     neutral       0.61      0.65      0.63       150\n",
            "         sad       0.74      0.83      0.78       112\n",
            "\n",
            "    accuracy                           0.70       553\n",
            "   macro avg       0.71      0.71      0.71       553\n",
            "weighted avg       0.70      0.70      0.70       553\n",
            "\n",
            "18/18 [==============================] - 2s 18ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 3s 25ms/step - loss: 0.8448 - accuracy: 0.7197\n",
            "5_Model evaluation:  [0.8448073267936707, 0.719710648059845]    Now ACC: 71.62\n",
            "18/18 [==============================] - 2s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.74      0.75      0.75       114\n",
            "       happy       0.75      0.66      0.70       176\n",
            "     neutral       0.67      0.72      0.69       166\n",
            "         sad       0.75      0.78      0.76        97\n",
            "\n",
            "    accuracy                           0.72       553\n",
            "   macro avg       0.73      0.73      0.73       553\n",
            "weighted avg       0.72      0.72      0.72       553\n",
            "\n",
            "18/18 [==============================] - 2s 17ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 5s 25ms/step - loss: 0.8684 - accuracy: 0.7288\n",
            "6_Model evaluation:  [0.8684273958206177, 0.7287522554397583]    Now ACC: 71.83\n",
            "18/18 [==============================] - 2s 25ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.71      0.79      0.75       119\n",
            "       happy       0.77      0.61      0.68       157\n",
            "     neutral       0.70      0.75      0.72       167\n",
            "         sad       0.75      0.80      0.78       110\n",
            "\n",
            "    accuracy                           0.73       553\n",
            "   macro avg       0.73      0.74      0.73       553\n",
            "weighted avg       0.73      0.73      0.73       553\n",
            "\n",
            "18/18 [==============================] - 2s 21ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 4s 26ms/step - loss: 0.8847 - accuracy: 0.7161\n",
            "7_Model evaluation:  [0.8847177624702454, 0.7160940170288086]    Now ACC: 71.79857142857142\n",
            "18/18 [==============================] - 2s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.65      0.72       101\n",
            "       happy       0.69      0.66      0.67       175\n",
            "     neutral       0.66      0.80      0.72       161\n",
            "         sad       0.81      0.75      0.78       116\n",
            "\n",
            "    accuracy                           0.72       553\n",
            "   macro avg       0.74      0.71      0.72       553\n",
            "weighted avg       0.72      0.72      0.72       553\n",
            "\n",
            "18/18 [==============================] - 2s 21ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 3s 25ms/step - loss: 0.9215 - accuracy: 0.6998\n",
            "8_Model evaluation:  [0.9214573502540588, 0.6998191475868225]    Now ACC: 71.57125\n",
            "18/18 [==============================] - 3s 27ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.81      0.69      0.74       105\n",
            "       happy       0.62      0.69      0.65       146\n",
            "     neutral       0.73      0.66      0.69       177\n",
            "         sad       0.69      0.78      0.73       125\n",
            "\n",
            "    accuracy                           0.70       553\n",
            "   macro avg       0.71      0.70      0.70       553\n",
            "weighted avg       0.71      0.70      0.70       553\n",
            "\n",
            "18/18 [==============================] - 2s 21ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 4s 26ms/step - loss: 0.9004 - accuracy: 0.7342\n",
            "9_Model evaluation:  [0.9004489183425903, 0.7341772317886353]    Now ACC: 71.77666666666667\n",
            "18/18 [==============================] - 2s 20ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.82      0.82      0.82       103\n",
            "       happy       0.65      0.68      0.66       158\n",
            "     neutral       0.69      0.72      0.70       180\n",
            "         sad       0.87      0.77      0.82       112\n",
            "\n",
            "    accuracy                           0.73       553\n",
            "   macro avg       0.76      0.74      0.75       553\n",
            "weighted avg       0.74      0.73      0.74       553\n",
            "\n",
            "18/18 [==============================] - 3s 21ms/step\n",
            "Input Shape= (None, 606, 39)\n",
            "Temporal create succes!\n",
            "18/18 [==============================] - 3s 26ms/step - loss: 0.9784 - accuracy: 0.7052\n",
            "10_Model evaluation:  [0.9784132838249207, 0.7052441239356995]    Now ACC: 71.651\n",
            "18/18 [==============================] - 2s 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.82      0.72      0.77       105\n",
            "       happy       0.68      0.60      0.64       149\n",
            "     neutral       0.70      0.70      0.70       191\n",
            "         sad       0.65      0.84      0.74       108\n",
            "\n",
            "    accuracy                           0.71       553\n",
            "   macro avg       0.71      0.72      0.71       553\n",
            "weighted avg       0.71      0.71      0.70       553\n",
            "\n",
            "18/18 [==============================] - 2s 21ms/step\n",
            "Average ACC: 0.7165118336677552\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode test --data IEMOCAP  --test_path ./Test_Models/IEMOCAP_16 --split_fold 10 --random_seed 16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDzn4mN7wi31",
        "outputId": "b1563f80-80d5-4a0c-919d-8055e0b0e1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-09 19:21:30.272165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-09 19:21:31.134999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-09 19:21:33.238108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:33.272813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:33.273160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:33.274301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:33.274566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:33.274779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.364626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.364955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.365250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.365441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "###gpus:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TIMNET MODEL SHAPE: (215, 39)\n",
            "2023-07-09 19:21:34.399979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.400321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.400534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.400788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.400995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-09 19:21:34.401149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "2023-07-09 19:21:39.189642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
            "5/5 [==============================] - 5s 137ms/step - loss: 0.4587 - accuracy: 0.9306\n",
            "1_Model evaluation:  [0.45871469378471375, 0.9305555820465088]    Now ACC: 93.06\n",
            "5/5 [==============================] - 2s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      1.00      0.94        24\n",
            "        calm       0.84      1.00      0.91        21\n",
            "     disgust       1.00      1.00      1.00        12\n",
            "        fear       0.94      0.85      0.89        20\n",
            "       happy       1.00      0.94      0.97        18\n",
            "     neutral       0.90      0.75      0.82        12\n",
            "         sad       0.93      0.93      0.93        15\n",
            "    surprise       1.00      0.91      0.95        22\n",
            "\n",
            "    accuracy                           0.93       144\n",
            "   macro avg       0.94      0.92      0.93       144\n",
            "weighted avg       0.94      0.93      0.93       144\n",
            "\n",
            "5/5 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 2s 12ms/step - loss: 0.5150 - accuracy: 0.9444\n",
            "2_Model evaluation:  [0.515026330947876, 0.9444444179534912]    Now ACC: 93.75\n",
            "5/5 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.86      0.95      0.90        19\n",
            "        calm       1.00      1.00      1.00        24\n",
            "     disgust       0.91      0.95      0.93        22\n",
            "        fear       1.00      0.87      0.93        15\n",
            "       happy       1.00      0.89      0.94        18\n",
            "     neutral       1.00      1.00      1.00        10\n",
            "         sad       0.88      0.93      0.90        15\n",
            "    surprise       0.95      0.95      0.95        21\n",
            "\n",
            "    accuracy                           0.94       144\n",
            "   macro avg       0.95      0.94      0.94       144\n",
            "weighted avg       0.95      0.94      0.94       144\n",
            "\n",
            "5/5 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 3s 16ms/step - loss: 0.5885 - accuracy: 0.9306\n",
            "3_Model evaluation:  [0.5884857177734375, 0.9305555820465088]    Now ACC: 93.52\n",
            "5/5 [==============================] - 1s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.94      0.91        17\n",
            "        calm       1.00      0.92      0.96        24\n",
            "     disgust       1.00      0.89      0.94        19\n",
            "        fear       0.92      1.00      0.96        24\n",
            "       happy       0.93      0.81      0.87        16\n",
            "     neutral       0.69      1.00      0.82         9\n",
            "         sad       0.94      0.94      0.94        18\n",
            "    surprise       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.93       144\n",
            "   macro avg       0.92      0.93      0.92       144\n",
            "weighted avg       0.94      0.93      0.93       144\n",
            "\n",
            "5/5 [==============================] - 1s 8ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 3s 13ms/step - loss: 0.5293 - accuracy: 0.9722\n",
            "4_Model evaluation:  [0.5293197631835938, 0.9722222089767456]    Now ACC: 94.445\n",
            "5/5 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      1.00      0.94        17\n",
            "        calm       0.95      1.00      0.97        18\n",
            "     disgust       1.00      0.91      0.95        23\n",
            "        fear       1.00      1.00      1.00        19\n",
            "       happy       0.96      1.00      0.98        24\n",
            "     neutral       1.00      1.00      1.00         4\n",
            "         sad       1.00      0.95      0.98        21\n",
            "    surprise       1.00      0.94      0.97        18\n",
            "\n",
            "    accuracy                           0.97       144\n",
            "   macro avg       0.98      0.98      0.97       144\n",
            "weighted avg       0.97      0.97      0.97       144\n",
            "\n",
            "5/5 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 3s 13ms/step - loss: 0.7704 - accuracy: 0.8889\n",
            "5_Model evaluation:  [0.770395815372467, 0.8888888955116272]    Now ACC: 93.334\n",
            "5/5 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.95      0.95      0.95        19\n",
            "        calm       0.91      1.00      0.95        21\n",
            "     disgust       0.93      0.82      0.87        17\n",
            "        fear       0.88      0.82      0.85        17\n",
            "       happy       0.94      0.85      0.89        20\n",
            "     neutral       0.93      0.76      0.84        17\n",
            "         sad       0.70      1.00      0.83        19\n",
            "    surprise       1.00      0.86      0.92        14\n",
            "\n",
            "    accuracy                           0.89       144\n",
            "   macro avg       0.91      0.88      0.89       144\n",
            "weighted avg       0.90      0.89      0.89       144\n",
            "\n",
            "5/5 [==============================] - 2s 9ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 2s 12ms/step - loss: 0.8476 - accuracy: 0.9167\n",
            "6_Model evaluation:  [0.8476492762565613, 0.9166666865348816]    Now ACC: 93.055\n",
            "5/5 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.86      0.93        22\n",
            "        calm       0.94      0.94      0.94        18\n",
            "     disgust       0.95      1.00      0.97        19\n",
            "        fear       0.73      1.00      0.84         8\n",
            "       happy       0.85      0.85      0.85        20\n",
            "     neutral       1.00      1.00      1.00         8\n",
            "         sad       0.89      0.94      0.92        18\n",
            "    surprise       0.93      0.87      0.90        31\n",
            "\n",
            "    accuracy                           0.92       144\n",
            "   macro avg       0.91      0.93      0.92       144\n",
            "weighted avg       0.92      0.92      0.92       144\n",
            "\n",
            "5/5 [==============================] - 2s 10ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 2s 12ms/step - loss: 0.9328 - accuracy: 0.8958\n",
            "7_Model evaluation:  [0.9328034520149231, 0.8958333134651184]    Now ACC: 92.55999999999999\n",
            "5/5 [==============================] - 2s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.89      0.89        19\n",
            "        calm       1.00      0.95      0.97        20\n",
            "     disgust       1.00      1.00      1.00        14\n",
            "        fear       0.90      0.96      0.93        28\n",
            "       happy       0.82      0.64      0.72        14\n",
            "     neutral       0.69      1.00      0.81        11\n",
            "         sad       0.95      0.87      0.91        23\n",
            "    surprise       0.86      0.80      0.83        15\n",
            "\n",
            "    accuracy                           0.90       144\n",
            "   macro avg       0.89      0.89      0.88       144\n",
            "weighted avg       0.90      0.90      0.90       144\n",
            "\n",
            "5/5 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 2s 12ms/step - loss: 0.9257 - accuracy: 0.9167\n",
            "8_Model evaluation:  [0.9256696701049805, 0.9166666865348816]    Now ACC: 92.4475\n",
            "5/5 [==============================] - 1s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.90      1.00      0.95        19\n",
            "        calm       0.96      0.96      0.96        25\n",
            "     disgust       1.00      0.92      0.96        13\n",
            "        fear       0.83      0.88      0.86        17\n",
            "       happy       0.94      0.80      0.86        20\n",
            "     neutral       0.75      0.90      0.82        10\n",
            "         sad       0.91      0.91      0.91        23\n",
            "    surprise       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.92       144\n",
            "   macro avg       0.91      0.91      0.91       144\n",
            "weighted avg       0.92      0.92      0.92       144\n",
            "\n",
            "5/5 [==============================] - 2s 11ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 3s 12ms/step - loss: 1.0318 - accuracy: 0.9097\n",
            "9_Model evaluation:  [1.0317704677581787, 0.9097222089767456]    Now ACC: 92.28444444444443\n",
            "5/5 [==============================] - 1s 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      1.00      1.00        18\n",
            "        calm       0.90      0.90      0.90        10\n",
            "     disgust       0.96      0.93      0.95        28\n",
            "        fear       1.00      0.95      0.98        21\n",
            "       happy       0.94      0.71      0.81        21\n",
            "     neutral       0.75      0.86      0.80         7\n",
            "         sad       0.91      0.95      0.93        22\n",
            "    surprise       0.73      0.94      0.82        17\n",
            "\n",
            "    accuracy                           0.91       144\n",
            "   macro avg       0.90      0.91      0.90       144\n",
            "weighted avg       0.92      0.91      0.91       144\n",
            "\n",
            "5/5 [==============================] - 1s 9ms/step\n",
            "Input Shape= (None, 215, 39)\n",
            "Temporal create succes!\n",
            "5/5 [==============================] - 2s 14ms/step - loss: 1.0372 - accuracy: 0.9028\n",
            "10_Model evaluation:  [1.0371534824371338, 0.9027777910232544]    Now ACC: 92.083\n",
            "5/5 [==============================] - 2s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.85      0.94      0.89        18\n",
            "        calm       0.71      0.91      0.80        11\n",
            "     disgust       0.96      1.00      0.98        25\n",
            "        fear       0.96      0.96      0.96        23\n",
            "       happy       1.00      0.86      0.92        21\n",
            "     neutral       0.58      0.88      0.70         8\n",
            "         sad       1.00      0.78      0.88        18\n",
            "    surprise       1.00      0.85      0.92        20\n",
            "\n",
            "    accuracy                           0.90       144\n",
            "   macro avg       0.88      0.90      0.88       144\n",
            "weighted avg       0.92      0.90      0.91       144\n",
            "\n",
            "5/5 [==============================] - 1s 8ms/step\n",
            "Average ACC: 0.9208333373069764\n"
          ]
        }
      ],
      "source": [
        "! python main.py --mode test --data RAVDE  --test_path ./Test_Models/RAVDE_46 --split_fold 10 --random_seed 46"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMfmG/rdTPQDQBLfDBUoqP8",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1XVQ3Nlfo9CpDlXDbZcpYF3iOhKoUSaFn",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
